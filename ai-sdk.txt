# https://ai-sdk.dev/ llms-full.txt

## AI SDK for TypeScript
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

The AI Toolkit for TypeScript

From the creators of Next.js, the AI SDK is a free open-source library that gives you the tools you need to build AI-powered products.

[Get Started](https://ai-sdk.dev/getting-started)

```
npm i ai
```

[Visit Playground](https://ai-sdk.dev/playground)

```
npm i ai
```

[Get Started](https://ai-sdk.dev/getting-started) [Visit Playground](https://ai-sdk.dev/playground)

### Trusted by builders at

[OpenAI\\
\\
Claude\\
\\
Hugging Face\\
\\
The next big thing\\
\\
Unified Provider API\\
\\
Switch between AI providers by changing a single line of code.](https://ai-sdk.dev/docs/foundations/providers-and-models) [Make a music player\\
\\
Blowin‚Äô in the Wind\\
\\
Bob Dylan\\
\\
Generative UI\\
\\
Create dynamic, AI-powered user interfaces that amaze your users.](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces) [Framework-agnostic\\
\\
Build with React, Next, Vue, Nuxt, SvelteKit, and more.](https://ai-sdk.dev/docs/getting-started) [Streaming AI Responses\\
\\
Don't let your users wait for AI responses. Send them instantly.](https://ai-sdk.dev/docs/advanced/why-streaming)

What builders say about the AI SDK

[![Sully's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2FSullyOmarr.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Sully\\
\\
@SullyOmarr\\
\\
the @aisdk is probably the best way to build an ai app right now\\
\\
you can go from idea -> working ai app in 15 mins.\\
\\
its made working with llms 10x more enjoyable ( and we ship faster)](https://x.com/SullyOmarr/status/1885049394342310335) [![Max Baines's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fmaxbaines.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Max Baines\\
\\
@maxbaines\\
\\
Hands down the @aisdk is by far the best SDK I have worked with, thats pretty much all things since jQuery.](https://x.com/maxbaines/status/1875207718618935302) [![Micky's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Frasmickyy.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Micky\\
\\
@rasmickyy\\
\\
vercel ai sdk is just sooo good it hurts man...\\
\\
can literally build ai features within any of my apps in mins](https://x.com/rasmickyy/status/1855398758554439824) [![morgan's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fmorganlinton.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
morgan\\
\\
@morganlinton\\
\\
The AI SDK is üî•üî•üî•](https://x.com/morganlinton/status/1884257150761066894) [![Tom Watkins's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Ftomwatkins1994.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Tom Watkins\\
\\
@TomWatkins1994\\
\\
the AI SDK is S tier software](https://x.com/TomWatkins1994/status/1829200829150339230)

[![EGOIST's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Flocalhost_5173.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
EGOIST\\
\\
@localhost\_5173\\
\\
Vercel AI SDK is so good, there's no reason to directly use npm/openai or npm/claude anymore](https://x.com/localhost_5173/status/1794004340375802108) [![sunil "yeah no" pai's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fthreepointone.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
sunil "yeah no" pai\\
\\
@threepointone\\
\\
vercel ai sdk is very good actually](https://x.com/threepointone/status/1818719331276276189)

[![Matt Pocock's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fmattpocockuk.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Matt Pocock\\
\\
@mattpocockuk\\
\\
Vercel's AI SDK is one of the first tools I reach for when I'm building an AI-powered feature in TypeScript.](https://x.com/mattpocockuk/status/1874822204824731717) [![Kyle Mistele üè¥‚Äç‚ò†Ô∏è's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2F0xblacklight.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Kyle Mistele üè¥‚Äç‚ò†Ô∏è\\
\\
@0xblacklight\\
\\
Vercel's @aisdk is insanely good. Docs are fantastic. Great abstractions where you want them, doesn't force unnecessary ones, and lets you get under the hood where appropriate. Solves the hard stuff (stream parsing, tool streaming, multi-turn tool execution, error handling and healing/recovery) without forcing you into dumb patterns\\
\\
It just works, it's fantastic software and delightful to use. The team ships insanely fast, and has turned PRs from me around in like 2 days, and frequently ships requested features in < 1w](https://x.com/0xblacklight/status/1866886257055342787) [![Ryan Carson's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fryancarson.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Ryan Carson\\
\\
@ryancarson\\
\\
I love @vercel and their @aisdk - so freaking easy to deploy.](https://x.com/ryancarson/status/1877170074538180811) [![Olivier's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fstonkyoli.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Olivier\\
\\
@StonkyOli\\
\\
Big fan of the AI SDK\\
\\
It has blown away my expectations since i started using it, way better than raw dogging oai](https://x.com/StonkyOli/status/1858922730181324938)

[![Pontus Abrahamsson's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fpontusab.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Pontus Abrahamsson\\
\\
@pontusab\\
\\
With the ai sdk available i'm always thinking: "How can I make this process as automatic as possible for the user?" because the barrier to implementing it is just a matter of minutes.](https://x.com/pontusab/status/1824398511099510791) [![ben's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fbenhylak.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
ben\\
\\
@benhylak\\
\\
@aisdk has made it possible to just call "generateObject" across any model provider, and it returns a properly typed json object.\\
\\
it's pure magic.](https://x.com/benhylak/status/1866931335291629995)

[![EGOIST's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Flocalhost_5173.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
EGOIST\\
\\
@localhost\_5173\\
\\
Vercel AI SDK is so good, there's no reason to directly use npm/openai or npm/claude anymore](https://x.com/localhost_5173/status/1794004340375802108) [![sunil "yeah no" pai's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fthreepointone.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
sunil "yeah no" pai\\
\\
@threepointone\\
\\
vercel ai sdk is very good actually](https://x.com/threepointone/status/1818719331276276189)

[![Pontus Abrahamsson's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fpontusab.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Pontus Abrahamsson\\
\\
@pontusab\\
\\
With the ai sdk available i'm always thinking: "How can I make this process as automatic as possible for the user?" because the barrier to implementing it is just a matter of minutes.](https://x.com/pontusab/status/1824398511099510791) [![ben's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fbenhylak.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
ben\\
\\
@benhylak\\
\\
@aisdk has made it possible to just call "generateObject" across any model provider, and it returns a properly typed json object.\\
\\
it's pure magic.](https://x.com/benhylak/status/1866931335291629995) [![sami's avatar](https://ai-sdk.dev/_next/image?url=%2Fimages%2Favatar%2Fsvmisvhn.jpg&w=96&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
sami\\
\\
@svmisvhn\\
\\
huge shoutout to @vercel for the ai sdk, one API for all LLMs is ü§Ø](https://x.com/svmisvhn/status/1808950039676342339)

FAQs

### Is the AI SDK free to use?

Yes, the AI SDK is free and open source.

### How do I get started?

Visit our [getting started page](https://ai-sdk.dev/getting-started) to learn how to install the AI SDK with your preferred framework.

### How can I contribute to the project?

We welcome contributions from the community! You can contribute by submitting bug reports, feature requests, or pull requests on our [GitHub repository](https://github.com/vercel/ai).

## Llama 3.1 Guide
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1\#get-started-with-llama-31)

The current generation of Llama models is 3.3. Please note that while this
guide focuses on Llama 3.1, the newer Llama 3.3 models are now available and
may offer improved capabilities. The concepts and integration techniques
described here remain applicable, though you may want to use the latest
generation models for optimal performance.

With the [release of Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/), there has never been a better time to start building AI applications.

The [AI SDK](https://ai-sdk.dev/) is a powerful TypeScript toolkit for building AI application with large language models (LLMs) like Llama 3.1 alongside popular frameworks like React, Next.js, Vue, Svelte, Node.js, and more

## [Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1\#llama-31)

The release of Meta's Llama 3.1 is an important moment in AI development. As the first state-of-the-art open weight AI model, Llama 3.1 is helping accelerate developers building AI apps. Available in 8B, 70B, and 405B sizes, these instruction-tuned models work well for tasks like dialogue generation, translation, reasoning, and code generation.

## [Benchmarks](https://ai-sdk.dev/cookbook/guides/llama-3_1\#benchmarks)

Llama 3.1 surpasses most available open-source chat models on common industry benchmarks and even outperforms some closed-source models, offering superior performance in language nuances, contextual understanding, and complex multi-step tasks. The models' refined post-training processes significantly improve response alignment, reduce false refusal rates, and enhance answer diversity, making Llama 3.1 a powerful and accessible tool for building generative AI applications.

![Llama 3.1 Benchmarks](https://ai-sdk.dev/images/llama-3_1-benchmarks.png)
Source: [Meta AI - Llama 3.1 Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)

## [Choosing Model Size](https://ai-sdk.dev/cookbook/guides/llama-3_1\#choosing-model-size)

Llama 3.1 includes a new 405B parameter model, becoming the largest open-source model available today. This model is designed to handle the most complex and demanding tasks.

When choosing between the different sizes of Llama 3.1 models (405B, 70B, 8B), consider the trade-off between performance and computational requirements. The 405B model offers the highest accuracy and capability for complex tasks but requires significant computational resources. The 70B model provides a good balance of performance and efficiency for most applications, while the 8B model is suitable for simpler tasks or resource-constrained environments where speed and lower computational overhead are priorities.

## [Getting Started with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1\#getting-started-with-the-ai-sdk)

The AI SDK is the TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js, and more. Integrating LLMs into applications is complicated and heavily dependent on the specific model provider you use.

The AI SDK abstracts away the differences between model providers, eliminates boilerplate code for building chatbots, and allows you to go beyond text output to generate rich, interactive components.

At the center of the AI SDK is [AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core/overview), which provides a unified API to call any LLM. The code snippet below is all you need to call Llama 3.1 (using [DeepInfra](https://deepinfra.com/)) with the AI SDK:

```code-block_code__yIKW2

import { deepinfra } from '@ai-sdk/deepinfra';

import { generateText } from 'ai';

const { text } = await generateText({

  model: deepinfra('meta-llama/Meta-Llama-3.1-405B-Instruct'),

  prompt: 'What is love?',

});
```

Llama 3.1 is available to use with many AI SDK providers including
[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra), [Amazon\\
Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock),
[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten) [Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks), and more.

AI SDK Core abstracts away the differences between model providers, allowing you to focus on building great applications. Prefer to use [Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)? The unified interface also means that you can easily switch between models by changing just two lines of code.

```code-block_code__yIKW2

import { generateText } from 'ai';

import { bedrock } from '@ai-sdk/amazon-bedrock';

const { text } = await generateText({

  model: bedrock('meta.llama3-1-405b-instruct-v1'),

  prompt: 'What is love?',

});
```

### [Streaming the Response](https://ai-sdk.dev/cookbook/guides/llama-3_1\#streaming-the-response)

To stream the model's response as it's being generated, update your code snippet to use the [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) function.

```code-block_code__yIKW2

import { streamText } from 'ai';

import { deepinfra } from '@ai-sdk/deepinfra';

const { textStream } = streamText({

  model: deepinfra('meta-llama/Meta-Llama-3.1-405B-Instruct'),

  prompt: 'What is love?',

});
```

### [Generating Structured Data](https://ai-sdk.dev/cookbook/guides/llama-3_1\#generating-structured-data)

While text generation can be useful, you might want to generate structured JSON data. For example, you might want to extract information from text, classify data, or generate synthetic data. AI SDK Core provides two functions ( [`generateObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object) and [`streamObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object)) to generate structured data, allowing you to constrain model outputs to a specific schema.

```code-block_code__yIKW2

import { generateObject } from 'ai';

import { deepinfra } from '@ai-sdk/deepinfra';

import { z } from 'zod';

const { object } = await generateObject({

  model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

  schema: z.object({

    recipe: z.object({

      name: z.string(),

      ingredients: z.array(z.object({ name: z.string(), amount: z.string() })),

      steps: z.array(z.string()),

    }),

  }),

  prompt: 'Generate a lasagna recipe.',

});
```

This code snippet will generate a type-safe recipe that conforms to the specified zod schema.

### [Tools](https://ai-sdk.dev/cookbook/guides/llama-3_1\#tools)

While LLMs have incredible generation capabilities, they struggle with discrete tasks (e.g. mathematics) and interacting with the outside world (e.g. getting the weather). The solution: tools, which are like programs that you provide to the model, which it can choose to call as necessary.

### [Using Tools with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1\#using-tools-with-the-ai-sdk)

The AI SDK supports tool usage across several of its functions, including [`generateText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text) and [`streamUI`](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/stream-ui). By passing one or more tools to the `tools` parameter, you can extend the capabilities of LLMs, allowing them to perform discrete tasks and interact with external systems.

Here's an example of how you can use a tool with the AI SDK and Llama 3.1:

```code-block_code__yIKW2

import { generateText, tool } from 'ai';

import { deepinfra } from '@ai-sdk/deepinfra';

import { z } from 'zod';

const { text } = await generateText({

  model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

  prompt: 'What is the weather like today?',

  tools: {

    getWeather: tool({

      description: 'Get the weather in a location',

      inputSchema: z.object({

        location: z.string().describe('The location to get the weather for'),

      }),

      execute: async ({ location }) => ({

        location,

        temperature: 72 + Math.floor(Math.random() * 21) - 10,

      }),

    }),

  },

});
```

In this example, the `getWeather` tool allows the model to fetch real-time weather data, enhancing its ability to provide accurate and up-to-date information.

### [Agents](https://ai-sdk.dev/cookbook/guides/llama-3_1\#agents)

Agents take your AI applications a step further by allowing models to execute multiple steps (i.e. tools) in a non-deterministic way, making decisions based on context and user input.

Agents use LLMs to choose the next step in a problem-solving process. They can reason at each step and make decisions based on the evolving context.

### [Implementing Agents with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1\#implementing-agents-with-the-ai-sdk)

The AI SDK supports agent implementation through the `maxSteps` parameter. This allows the model to make multiple decisions and tool calls in a single interaction.

Here's an example of an agent that solves math problems:

```code-block_code__yIKW2

import { generateText, tool } from 'ai';

import { deepinfra } from '@ai-sdk/deepinfra';

import * as mathjs from 'mathjs';

import { z } from 'zod';

const problem =

  'Calculate the profit for a day if revenue is $5000 and expenses are $3500.';

const { text: answer } = await generateText({

  model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

  system:

    'You are solving math problems. Reason step by step. Use the calculator when necessary.',

  prompt: problem,

  tools: {

    calculate: tool({

      description: 'A tool for evaluating mathematical expressions.',

      inputSchema: z.object({ expression: z.string() }),

      execute: async ({ expression }) => mathjs.evaluate(expression),

    }),

  },

  maxSteps: 5,

});
```

In this example, the agent can use the calculator tool multiple times if needed, reasoning through the problem step by step.

### [Building Interactive Interfaces](https://ai-sdk.dev/cookbook/guides/llama-3_1\#building-interactive-interfaces)

AI SDK Core can be paired with [AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview), another powerful component of the AI SDK, to streamline the process of building chat, completion, and assistant interfaces with popular frameworks like Next.js, Nuxt, and SvelteKit.

AI SDK UI provides robust abstractions that simplify the complex tasks of managing chat streams and UI updates on the frontend, enabling you to develop dynamic AI-driven interfaces more efficiently.

With four main hooks ‚Äî [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat), [`useCompletion`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-completion), and [`useObject`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-object) ‚Äî you can incorporate real-time chat capabilities, text completions, streamed JSON, and interactive assistant features into your app.

Let's explore building a chatbot with [Next.js](https://nextjs.org/), the AI SDK, and Llama 3.1 (via [DeepInfra](https://deepinfra.com/)):

app/api/chat/route.ts

```code-block_code__yIKW2

import { deepinfra } from '@ai-sdk/deepinfra';

import { convertToModelMessages, streamText } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages } = await req.json();

  const result = streamText({

    model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse();

}
```

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

export default function Page() {

  const { messages, input, handleInputChange, handleSubmit } = useChat();

  return (

    <>

      {messages.map(message => (

        <div key={message.id}>

          {message.role === 'user' ? 'User: ' : 'AI: '}

          {message.content}

        </div>

      ))}

      <form onSubmit={handleSubmit}>

        <input name="prompt" value={input} onChange={handleInputChange} />

        <button type="submit">Submit</button>

      </form>

    </>

  );

}
```

The useChat hook on your root page ( `app/page.tsx`) will make a request to your AI provider endpoint ( `app/api/chat/route.ts`) whenever the user submits a message. The messages are then streamed back in real-time and displayed in the chat UI.

This enables a seamless chat experience where the user can see the AI response as soon as it is available, without having to wait for the entire response to be received.

### [Going Beyond Text](https://ai-sdk.dev/cookbook/guides/llama-3_1\#going-beyond-text)

The AI SDK's React Server Components (RSC) API enables you to create rich, interactive interfaces that go beyond simple text generation. With the [`streamUI`](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/stream-ui) function, you can dynamically stream React components from the server to the client.

Let's dive into how you can leverage tools with [AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc/overview) to build a generative user interface with Next.js (App Router).

First, create a Server Action.

app/actions.tsx

```code-block_code__yIKW2

'use server';

import { streamUI } from '@ai-sdk/rsc';

import { deepinfra } from '@ai-sdk/deepinfra';

import { z } from 'zod';

export async function streamComponent() {

  const result = await streamUI({

    model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

    prompt: 'Get the weather for San Francisco',

    text: ({ content }) => <div>{content}</div>,

    tools: {

      getWeather: {

        description: 'Get the weather for a location',

        inputSchema: z.object({ location: z.string() }),

        generate: async function* ({ location }) {

          yield <div>loading...</div>;

          const weather = '25c'; // await getWeather(location);

          return (

            <div>

              the weather in {location} is {weather}.

            </div>

          );

        },

      },

    },

  });

  return result.value;

}
```

In this example, if the model decides to use the `getWeather` tool, it will first yield a `div` while fetching the weather data, then return a weather component with the fetched data (note: static data in this example). This allows for a more dynamic and responsive UI that can adapt based on the AI's decisions and external data.

On the frontend, you can call this Server Action like any other asynchronous function in your application. In this case, the function returns a regular React component.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useState } from 'react';

import { streamComponent } from './actions';

export default function Page() {

  const [component, setComponent] = useState<React.ReactNode>();

  return (

    <div>

      <form

        onSubmit={async e => {

          e.preventDefault();

          setComponent(await streamComponent());

        }}

      >

        <button>Stream Component</button>

      </form>

      <div>{component}</div>

    </div>

  );

}
```

To see AI SDK RSC in action, check out our open-source [Next.js Gemini Chatbot](https://gemini.vercel.ai/).

## [Migrate from OpenAI](https://ai-sdk.dev/cookbook/guides/llama-3_1\#migrate-from-openai)

One of the key advantages of the AI SDK is its unified API, which makes it incredibly easy to switch between different AI models and providers. This flexibility is particularly useful when you want to migrate from one model to another, such as moving from OpenAI's GPT models to Meta's Llama models hosted on DeepInfra.

Here's how simple the migration process can be:

**OpenAI Example:**

```code-block_code__yIKW2

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

const { text } = await generateText({

  model: openai('gpt-4.1'),

  prompt: 'What is love?',

});
```

**Llama on DeepInfra Example:**

```code-block_code__yIKW2

import { generateText } from 'ai';

import { deepinfra } from '@ai-sdk/deepinfra';

const { text } = await generateText({

  model: deepinfra('meta-llama/Meta-Llama-3.1-70B-Instruct'),

  prompt: 'What is love?',

});
```

Thanks to the unified API, the core structure of the code remains the same. The main differences are:

1. Creating a DeepInfra client
2. Changing the model name from `openai("gpt-4.1")` to `deepinfra("meta-llama/Meta-Llama-3.1-70B-Instruct")`.

With just these few changes, you've migrated from using OpenAI's GPT-4-Turbo to Meta's Llama 3.1 hosted on DeepInfra. The `generateText` function and its usage remain identical, showcasing the power of the AI SDK's unified API.

This feature allows you to easily experiment with different models, compare their performance, and choose the best one for your specific use case without having to rewrite large portions of your codebase.

## [Prompt Engineering and Fine-tuning](https://ai-sdk.dev/cookbook/guides/llama-3_1\#prompt-engineering-and-fine-tuning)

While the Llama 3.1 family of models are powerful out-of-the-box, their performance can be enhanced through effective prompt engineering and fine-tuning techniques.

### [Prompt Engineering](https://ai-sdk.dev/cookbook/guides/llama-3_1\#prompt-engineering)

Prompt engineering is the practice of crafting input prompts to elicit desired outputs from language models. It involves structuring and phrasing prompts in ways that guide the model towards producing more accurate, relevant, and coherent responses.

For more information on prompt engineering techniques (specific to Llama models), check out these resources:

- [Official Llama 3.1 Prompt Guide](https://llama.meta.com/docs/how-to-guides/prompting)
- [Prompt Engineering with Llama 3](https://github.com/amitsangani/Llama/blob/main/Llama_3_Prompt_Engineering.ipynb)
- [How to prompt Llama 3](https://huggingface.co/blog/llama3#how-to-prompt-llama-3)

### [Fine-tuning](https://ai-sdk.dev/cookbook/guides/llama-3_1\#fine-tuning)

Fine-tuning involves further training a pre-trained model on a specific dataset or task to customize its performance for particular use cases. This process allows you to adapt Llama 3.1 to your specific domain or application, potentially improving its accuracy and relevance for your needs.

To learn more about fine-tuning Llama models, check out these resources:

- [Official Fine-tuning Llama Guide](https://llama.meta.com/docs/how-to-guides/fine-tuning)
- [Fine-tuning and Inference with Llama 3](https://docs.inferless.com/how-to-guides/how-to-finetune--and-inference-llama3)
- [Fine-tuning Models with Fireworks AI](https://docs.fireworks.ai/fine-tuning/fine-tuning-models)
- [Fine-tuning Llama with Modal](https://modal.com/docs/examples/llm-finetuning)

## [Conclusion](https://ai-sdk.dev/cookbook/guides/llama-3_1\#conclusion)

The AI SDK offers a powerful and flexible way to integrate cutting-edge AI models like Llama 3.1 into your applications. With AI SDK Core, you can seamlessly switch between different AI models and providers by changing just two lines of code. This flexibility allows for quick experimentation and adaptation, reducing the time required to change models from days to minutes.

The AI SDK ensures that your application remains clean and modular, accelerating development and future-proofing against the rapidly evolving landscape.

Ready to get started? Here's how you can dive in:

1. Explore the documentation at [ai-sdk.dev/docs](https://ai-sdk.dev/docs) to understand the full capabilities of the AI SDK.
2. Check out practical examples at [ai-sdk.dev/examples](https://ai-sdk.dev/examples) to see the SDK in action and get inspired for your own projects.
3. Dive deeper with advanced guides on topics like Retrieval-Augmented Generation (RAG) and multi-modal chat at [ai-sdk.dev/docs/guides](https://ai-sdk.dev/docs/guides).
4. Check out ready-to-deploy AI templates at [vercel.com/templates?type=ai](https://vercel.com/templates?type=ai).

On this page

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1#get-started-with-llama-31)

[Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1#llama-31)

[Benchmarks](https://ai-sdk.dev/cookbook/guides/llama-3_1#benchmarks)

[Choosing Model Size](https://ai-sdk.dev/cookbook/guides/llama-3_1#choosing-model-size)

[Getting Started with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1#getting-started-with-the-ai-sdk)

[Streaming the Response](https://ai-sdk.dev/cookbook/guides/llama-3_1#streaming-the-response)

[Generating Structured Data](https://ai-sdk.dev/cookbook/guides/llama-3_1#generating-structured-data)

[Tools](https://ai-sdk.dev/cookbook/guides/llama-3_1#tools)

[Using Tools with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1#using-tools-with-the-ai-sdk)

[Agents](https://ai-sdk.dev/cookbook/guides/llama-3_1#agents)

[Implementing Agents with the AI SDK](https://ai-sdk.dev/cookbook/guides/llama-3_1#implementing-agents-with-the-ai-sdk)

[Building Interactive Interfaces](https://ai-sdk.dev/cookbook/guides/llama-3_1#building-interactive-interfaces)

[Going Beyond Text](https://ai-sdk.dev/cookbook/guides/llama-3_1#going-beyond-text)

[Migrate from OpenAI](https://ai-sdk.dev/cookbook/guides/llama-3_1#migrate-from-openai)

[Prompt Engineering and Fine-tuning](https://ai-sdk.dev/cookbook/guides/llama-3_1#prompt-engineering-and-fine-tuning)

[Prompt Engineering](https://ai-sdk.dev/cookbook/guides/llama-3_1#prompt-engineering)

[Fine-tuning](https://ai-sdk.dev/cookbook/guides/llama-3_1#fine-tuning)

[Conclusion](https://ai-sdk.dev/cookbook/guides/llama-3_1#conclusion)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## No Such Provider Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error\#ai_nosuchprovidererror)

This error occurs when a provider ID is not found.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error\#properties)

- `providerId`: The ID of the provider that was not found
- `availableProviders`: Array of available provider IDs
- `modelId`: The ID of the model
- `modelType`: The type of model
- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error\#checking-for-this-error)

You can check if an error is an instance of `AI_NoSuchProviderError` using:

```code-block_code__yIKW2

import { NoSuchProviderError } from 'ai';

if (NoSuchProviderError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error#ai_nosuchprovidererror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## RAG Chatbot Guide
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [RAG Agent Guide](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#rag-agent-guide)

In this guide, you will learn how to build a retrieval-augmented generation (RAG) agent.

Before we dive in, let's look at what RAG is, and why we would want to use it.

### [What is RAG?](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#what-is-rag)

RAG stands for retrieval augmented generation. In simple terms, RAG is the process of providing a Large Language Model (LLM) with specific information relevant to the prompt.

### [Why is RAG important?](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#why-is-rag-important)

While LLMs are powerful, the information they can reason on is restricted to the data they were trained on. This problem becomes apparent when asking an LLM for information outside of their training data, like proprietary data or common knowledge that has occurred after the model‚Äôs training cutoff. RAG solves this problem by fetching information relevant to the prompt and then passing that to the model as context.

To illustrate with a basic example, imagine asking the model for your favorite food:

```code-block_code__yIKW2

**input**

What is my favorite food?

**generation**

I don't have access to personal information about individuals, including their

favorite foods.
```

Not surprisingly, the model doesn‚Äôt know. But imagine, alongside your prompt, the model received some extra context:

```code-block_code__yIKW2

**input**

Respond to the user's prompt using only the provided context.

user prompt: 'What is my favorite food?'

context: user loves chicken nuggets

**generation**

Your favorite food is chicken nuggets!
```

Just like that, you have augmented the model‚Äôs generation by providing relevant information to the query. Assuming the model has the appropriate information, it is now highly likely to return an accurate response to the users query. But how does it retrieve the relevant information? The answer relies on a concept called embedding.

You could fetch any context for your RAG application (eg. Google search).
Embeddings and Vector Databases are just a specific retrieval approach to
achieve semantic search.

### [Embedding](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#embedding)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings) are a way to represent words, phrases, or images as vectors in a high-dimensional space. In this space, similar words are close to each other, and the distance between words can be used to measure their similarity.

In practice, this means that if you embedded the words `cat` and `dog`, you would expect them to be plotted close to each other in vector space. The process of calculating the similarity between two vectors is called ‚Äòcosine similarity‚Äô where a value of 1 would indicate high similarity and a value of -1 would indicate high opposition.

Don‚Äôt worry if this seems complicated. a high level understanding is all you
need to get started! For a more in-depth introduction to embeddings, check out
[this guide](https://jalammar.github.io/illustrated-word2vec/).

As mentioned above, embeddings are a way to represent the semantic meaning of **words and phrases**. The implication here is that the larger the input to your embedding, the lower quality the embedding will be. So how would you approach embedding content longer than a simple phrase?

### [Chunking](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#chunking)

Chunking refers to the process of breaking down a particular source material into smaller pieces. There are many different approaches to chunking and it‚Äôs worth experimenting as the most effective approach can differ by use case. A simple and common approach to chunking (and what you will be using in this guide) is separating written content by sentences.

Once your source material is appropriately chunked, you can embed each one and then store the embedding and the chunk together in a database. Embeddings can be stored in any database that supports vectors. For this tutorial, you will be using [Postgres](https://www.postgresql.org/) alongside the [pgvector](https://github.com/pgvector/pgvector) plugin.

![](https://ai-sdk.dev/_next/image?url=%2Fimages%2Frag-guide-1.png&w=1920&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)![](https://ai-sdk.dev/_next/image?url=%2Fimages%2Frag-guide-1-dark.png&w=1920&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

### [All Together Now](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#all-together-now)

Combining all of this together, RAG is the process of enabling the model to respond with information outside of it‚Äôs training data by embedding a users query, retrieving the relevant source material (chunks) with the highest semantic similarity, and then passing them alongside the initial query as context. Going back to the example where you ask the model for your favorite food, the prompt preparation process would look like this.

![](https://ai-sdk.dev/_next/image?url=%2Fimages%2Frag-guide-2.png&w=1920&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)![](https://ai-sdk.dev/_next/image?url=%2Fimages%2Frag-guide-2-dark.png&w=1920&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

By passing the appropriate context and refining the model‚Äôs objective, you are able to fully leverage its strengths as a reasoning machine.

Onto the project!

## [Project Setup](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#project-setup)

In this project, you will build a agent that will only respond with information that it has within its knowledge base. The agent will be able to both store and retrieve information. This project has many interesting use cases from customer support through to building your own second brain!

This project will use the following stack:

- [Next.js](https://nextjs.org/) 14 (App Router)
- [AI SDK](https://ai-sdk.dev/docs)
- [OpenAI](https://openai.com/)
- [Drizzle ORM](https://orm.drizzle.team/)
- [Postgres](https://www.postgresql.org/) with [pgvector](https://github.com/pgvector/pgvector)
- [shadcn-ui](https://ui.shadcn.com/) and [TailwindCSS](https://tailwindcss.com/) for styling

### [Clone Repo](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#clone-repo)

To reduce the scope of this guide, you will be starting with a [repository](https://github.com/vercel/ai-sdk-rag-starter) that already has a few things set up for you:

- Drizzle ORM ( `lib/db`) including an initial migration and a script to migrate ( `db:migrate`)
- a basic schema for the `resources` table (this will be for source material)
- a Server Action for creating a `resource`

To get started, clone the starter repository with the following command:

```
git clone https://github.com/vercel/ai-sdk-rag-starter
```

```
cd ai-sdk-rag-starter
```

First things first, run the following command to install the project‚Äôs dependencies:

```
pnpm install
```

### [Create Database](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#create-database)

You will need a Postgres database to complete this tutorial. If you don't have Postgres setup on your local machine you can:

- Create a free Postgres database with Vercel (recommended - see instructions below); or
- Follow [this guide](https://www.prisma.io/dataguide/postgresql/setting-up-a-local-postgresql-database) to set it up locally

#### [Setting up Postgres with Vercel](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#setting-up-postgres-with-vercel)

To set up a Postgres instance on your Vercel account:

01. Go to [Vercel.com](https://vercel.com/) and make sure you're logged in
02. Navigate to your team homepage
03. Click on the **Integrations** tab
04. Click **Browse Marketplace**
05. Look for the **Storage** option in the sidebar
06. Select the **Neon** option (recommended, but any other PostgreSQL database provider should work)
07. Click **Install**, then click **Install** again in the top right corner
08. On the "Get Started with Neon" page, click **Create Database** on the right
09. Select your region (e.g., Washington, D.C., U.S. East)
10. Turn off **Auth**
11. Click **Continue**
12. Name your database (you can use the default name or rename it to something like "RagTutorial")
13. Click **Create** in the bottom right corner
14. After seeing "Database created successfully", click **Done**
15. You'll be redirected to your database instance
16. In the Quick Start section, click **Show secrets**
17. Copy the full `DATABASE_URL` environment variable

### [Migrate Database](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#migrate-database)

Once you have a Postgres database, you need to add the connection string as an environment secret.

Make a copy of the `.env.example` file and rename it to `.env`.

```
cp .env.example .env
```

Open the new `.env` file. You should see an item called `DATABASE_URL`. Copy in your database connection string after the equals sign.

With that set up, you can now run your first database migration. Run the following command:

```
pnpm db:migrate
```

This will first add the `pgvector` extension to your database. Then it will create a new table for your `resources` schema that is defined in `lib/db/schema/resources.ts`. This schema has four columns: `id`, `content`, `createdAt`, and `updatedAt`.

If you experience an error with the migration, see the [troubleshooting\\
section](https://ai-sdk.dev/cookbook/guides/rag-chatbot#troubleshooting-migration-error) below.

### [OpenAI API Key](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#openai-api-key)

For this guide, you will need an OpenAI API key. To generate an API key, go to [platform.openai.com](http://platform.openai.com/).

Once you have your API key, paste it into your `.env` file ( `OPENAI_API_KEY`).

## [Build](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#build)

Let‚Äôs build a quick task list of what needs to be done:

1. Create a table in your database to store embeddings
2. Add logic to chunk and create embeddings when creating resources
3. Create an agent
4. Give the agent tools to query / create resources for it‚Äôs knowledge base

### [Create Embeddings Table](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#create-embeddings-table)

Currently, your application has one table ( `resources`) which has a column ( `content`) for storing content. Remember, each `resource` (source material) will have to be chunked, embedded, and then stored. Let‚Äôs create a table called `embeddings` to store these chunks.

Create a new file ( `lib/db/schema/embeddings.ts`) and add the following code:

lib/db/schema/embeddings.ts

```code-block_code__yIKW2

import { nanoid } from '@/lib/utils';

import { index, pgTable, text, varchar, vector } from 'drizzle-orm/pg-core';

import { resources } from './resources';

export const embeddings = pgTable(

  'embeddings',

  {

    id: varchar('id', { length: 191 })

      .primaryKey()

      .$defaultFn(() => nanoid()),

    resourceId: varchar('resource_id', { length: 191 }).references(

      () => resources.id,

      { onDelete: 'cascade' },

    ),

    content: text('content').notNull(),

    embedding: vector('embedding', { dimensions: 1536 }).notNull(),

  },

  table => ({

    embeddingIndex: index('embeddingIndex').using(

      'hnsw',

      table.embedding.op('vector_cosine_ops'),

    ),

  }),

);
```

This table has four columns:

- `id` \- unique identifier
- `resourceId` \- a foreign key relation to the full source material
- `content` \- the plain text chunk
- `embedding` \- the vector representation of the plain text chunk

To perform similarity search, you also need to include an¬†index ( [HNSW](https://github.com/pgvector/pgvector?tab=readme-ov-file#hnsw)¬†or¬†[IVFFlat](https://github.com/pgvector/pgvector?tab=readme-ov-file#ivfflat)) on this column for better performance.

To push this change to the database, run the following command:

```
pnpm db:push
```

### [Add Embedding Logic](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#add-embedding-logic)

Now that you have a table to store embeddings, it‚Äôs time to write the logic to create the embeddings.

Create a file with the following command:

```
mkdir lib/ai && touch lib/ai/embedding.ts
```

### [Generate Chunks](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#generate-chunks)

Remember, to create an embedding, you will start with a piece of source material (unknown length), break it down into smaller chunks, embed each chunk, and then save the chunk to the database. Let‚Äôs start by creating a function to break the source material into small chunks.

lib/ai/embedding.ts

```code-block_code__yIKW2

const generateChunks = (input: string): string[] => {

  return input

    .trim()

    .split('.')

    .filter(i => i !== '');

};
```

This function will take an input string and split it by periods, filtering out any empty items. This will return an array of strings. It is worth experimenting with different chunking techniques in your projects as the best technique will vary.

### [Install AI SDK](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#install-ai-sdk)

You will use the AI SDK to create embeddings. This will require two more dependencies, which you can install by running the following command:

```
pnpm add ai @ai-sdk/react @ai-sdk/openai
```

This will install the [AI SDK](https://ai-sdk.dev/docs), AI SDK's React hooks, and AI SDK's [OpenAI provider](https://ai-sdk.dev/providers/ai-sdk-providers/openai).

The AI SDK is designed to be a unified interface to interact with any large
language model. This means that you can change model and providers with just
one line of code! Learn more about [available providers](https://ai-sdk.dev/providers) and
[building custom providers](https://ai-sdk.dev/providers/community-providers/custom-providers)
in the [providers](https://ai-sdk.dev/providers) section.

### [Generate Embeddings](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#generate-embeddings)

Let‚Äôs add a function to generate embeddings. Copy the following code into your `lib/ai/embedding.ts` file.

lib/ai/embedding.ts

```code-block_code__yIKW2

import { embedMany } from 'ai';

import { openai } from '@ai-sdk/openai';

const embeddingModel = openai.embedding('text-embedding-ada-002');

const generateChunks = (input: string): string[] => {

  return input

    .trim()

    .split('.')

    .filter(i => i !== '');

};

export const generateEmbeddings = async (

  value: string,

): Promise<Array<{ embedding: number[]; content: string }>> => {

  const chunks = generateChunks(value);

  const { embeddings } = await embedMany({

    model: embeddingModel,

    values: chunks,

  });

  return embeddings.map((e, i) => ({ content: chunks[i], embedding: e }));

};
```

In this code, you first define the model you want to use for the embeddings. In this example, you are using OpenAI‚Äôs `text-embedding-ada-002` embedding model.

Next, you create an asynchronous function called `generateEmbeddings`. This function will take in the source material ( `value`) as an input and return a promise of an array of objects, each containing an embedding and content. Within the function, you first generate chunks for the input. Then, you pass those chunks to the [`embedMany`](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed-many) function imported from the AI SDK which will return embeddings of the chunks you passed in. Finally, you map over and return the embeddings in a format that is ready to save in the database.

### [Update Server Action](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#update-server-action)

Open the file at `lib/actions/resources.ts`. This file has one function, `createResource`, which, as the name implies, allows you to create a resource.

lib/actions/resources.ts

```code-block_code__yIKW2

'use server';

import {

  NewResourceParams,

  insertResourceSchema,

  resources,

} from '@/lib/db/schema/resources';

import { db } from '../db';

export const createResource = async (input: NewResourceParams) => {

  try {

    const { content } = insertResourceSchema.parse(input);

    const [resource] = await db

      .insert(resources)

      .values({ content })

      .returning();

    return 'Resource successfully created.';

  } catch (e) {

    if (e instanceof Error)

      return e.message.length > 0 ? e.message : 'Error, please try again.';

  }

};
```

This function is a [Server Action](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations#with-client-components), as denoted by the `‚Äúuse server‚Äù;` directive at the top of the file. This means that it can be called anywhere in your Next.js application. This function will take an input, run it through a [Zod](https://zod.dev/) schema to ensure it adheres to the correct schema, and then creates a new resource in the database. This is the ideal location to generate and store embeddings of the newly created resources.

Update the file with the following code:

lib/actions/resources.ts

```code-block_code__yIKW2

'use server';

import {

  NewResourceParams,

  insertResourceSchema,

  resources,

} from '@/lib/db/schema/resources';

import { db } from '../db';

import { generateEmbeddings } from '../ai/embedding';

import { embeddings as embeddingsTable } from '../db/schema/embeddings';

export const createResource = async (input: NewResourceParams) => {

  try {

    const { content } = insertResourceSchema.parse(input);

    const [resource] = await db

      .insert(resources)

      .values({ content })

      .returning();

    const embeddings = await generateEmbeddings(content);

    await db.insert(embeddingsTable).values(

      embeddings.map(embedding => ({

        resourceId: resource.id,

        ...embedding,

      })),

    );

    return 'Resource successfully created and embedded.';

  } catch (error) {

    return error instanceof Error && error.message.length > 0

      ? error.message

      : 'Error, please try again.';

  }

};
```

First, you call the `generateEmbeddings` function created in the previous step, passing in the source material ( `content`). Once you have your embeddings ( `e`) of the source material, you can save them to the database, passing the `resourceId` alongside each embedding.

### [Create Root Page](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#create-root-page)

Great! Let's build the frontend. The AI SDK‚Äôs [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat) hook allows you to easily create a conversational user interface for your agent.

Replace your root page ( `app/page.tsx`) with the following code.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat();

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      <div className="space-y-4">

        {messages.map(m => (

          <div key={m.id} className="whitespace-pre-wrap">

            <div>

              <div className="font-bold">{m.role}</div>

              {m.parts.map(part => {

                switch (part.type) {

                  case 'text':

                    return <p>{part.text}</p>;

                }

              })}

            </div>

          </div>

        ))}

      </div>

      <form

        onSubmit={e => {

          e.preventDefault();

          sendMessage({ text: input });

          setInput('');

        }}

      >

        <input

          className="fixed bottom-0 w-full max-w-md p-2 mb-8 border border-gray-300 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={e => setInput(e.currentTarget.value)}

        />

      </form>

    </div>

  );

}
```

The `useChat` hook enables the streaming of chat messages from your AI provider (you will be using OpenAI), manages the state for chat input, and updates the UI automatically as new messages are received.

Run the following command to start the Next.js dev server:

```
pnpm run dev
```

Head to [http://localhost:3000](http://localhost:3000/). You should see an empty screen with an input bar floating at the bottom. Try to send a message. The message shows up in the UI for a fraction of a second and then disappears. This is because you haven‚Äôt set up the corresponding API route to call the model! By default, `useChat` will send a POST request to the `/api/chat` endpoint with the `messages` as the request body.

You can customize the endpoint in the useChat configuration object

### [Create API Route](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#create-api-route)

In Next.js, you can create custom request handlers for a given route using [Route Handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers). Route Handlers are defined in a `route.ts` file and can export HTTP methods like `GET`, `POST`, `PUT`, `PATCH` etc.

Create a file at `app/api/chat/route.ts` by running the following command:

```
mkdir -p app/api/chat && touch app/api/chat/route.ts
```

Open the file and add the following code:

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText, UIMessage } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse();

}
```

In this code, you declare and export an asynchronous function called POST. You retrieve the `messages` from the request body and then pass them to the [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) function imported from the AI SDK, alongside the model you would like to use. Finally, you return the model‚Äôs response in `UIMessageStreamResponse` format.

Head back to the browser and try to send a message again. You should see a response from the model streamed directly in!

### [Refining your prompt](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#refining-your-prompt)

While you now have a working agent, it isn't doing anything special.

Let‚Äôs add system instructions to refine and restrict the model‚Äôs behavior. In this case, you want the model to only use information it has retrieved to generate responses. Update your route handler with the following code:

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText, UIMessage } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    system: `You are a helpful assistant. Check your knowledge base before answering any questions.

    Only respond to questions using information from tool calls.

    if no relevant information is found in the tool calls, respond, "Sorry, I don't know."`,

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse();

}
```

Head back to the browser and try to ask the model what your favorite food is. The model should now respond exactly as you instructed above (‚ÄúSorry, I don‚Äôt know‚Äù) given it doesn‚Äôt have any relevant information.

In its current form, your agent is now, well, useless. How do you give the model the ability to add and query information?

### [Using Tools](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#using-tools)

A [tool](https://ai-sdk.dev/docs/foundations/tools) is a function that can be called by the model to perform a specific task. You can think of a tool like a program you give to the model that it can run as and when it deems necessary.

Let‚Äôs see how you can create a tool to give the model the ability to create, embed and save a resource to your agents‚Äô knowledge base.

### [Add Resource Tool](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#add-resource-tool)

Update your route handler with the following code:

app/api/chat/route.ts

```code-block_code__yIKW2

import { createResource } from '@/lib/actions/resources';

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText, tool, UIMessage } from 'ai';

import { z } from 'zod';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    system: `You are a helpful assistant. Check your knowledge base before answering any questions.

    Only respond to questions using information from tool calls.

    if no relevant information is found in the tool calls, respond, "Sorry, I don't know."`,

    messages: convertToModelMessages(messages),

    tools: {

      addResource: tool({

        description: `add a resource to your knowledge base.

          If the user provides a random piece of knowledge unprompted, use this tool without asking for confirmation.`,

        inputSchema: z.object({

          content: z

            .string()

            .describe('the content or resource to add to the knowledge base'),

        }),

        execute: async ({ content }) => createResource({ content }),

      }),

    },

  });

  return result.toUIMessageStreamResponse();

}
```

In this code, you define a tool called `addResource`. This tool has three elements:

- **description**: description of the tool that will influence when the tool is picked.
- **inputSchema**:¬†[Zod schema](https://ai-sdk.dev/docs/foundations/tools#schema-specification-and-validation-with-zod)¬†that defines the input necessary for the tool to run.
- **execute**: An asynchronous function that is called with the arguments from the tool call.

In simple terms, on each generation, the model will decide whether it should call the tool. If it deems it should call the tool, it will extract the input and then append a new `message` to the `messages` array of type `tool-call`. The AI SDK will then run the `execute` function with the parameters provided by the `tool-call` message.

Head back to the browser and tell the model your favorite food. You should see an empty response in the UI. Did anything happen? Let‚Äôs see. Run the following command in a new terminal window.

```
pnpm db:studio
```

This will start Drizzle Studio where we can view the rows in our database. You should see a new row in both the `embeddings` and `resources` table with your favorite food!

Let‚Äôs make a few changes in the UI to communicate to the user when a tool has been called. Head back to your root page ( `app/page.tsx`) and add the following code:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat();

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      <div className="space-y-4">

        {messages.map(m => (

          <div key={m.id} className="whitespace-pre-wrap">

            <div>

              <div className="font-bold">{m.role}</div>

              {m.parts.map(part => {

                switch (part.type) {

                  case 'text':

                    return <p>{part.text}</p>;

                  case 'tool-addResource':

                  case 'tool-getInformation':

                    return (

                      <p>

                        call{part.state === 'output-available' ? 'ed' : 'ing'}{' '}

                        tool: {part.type}

                        <pre className="my-4 bg-zinc-100 p-2 rounded-sm">

                          {JSON.stringify(part.input, null, 2)}

                        </pre>

                      </p>

                    );

                }

              })}

            </div>

          </div>

        ))}

      </div>

      <form

        onSubmit={e => {

          e.preventDefault();

          sendMessage({ text: input });

          setInput('');

        }}

      >

        <input

          className="fixed bottom-0 w-full max-w-md p-2 mb-8 border border-gray-300 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={e => setInput(e.currentTarget.value)}

        />

      </form>

    </div>

  );

}
```

With this change, you now conditionally render the tool that has been called directly in the UI. Save the file and head back to browser. Tell the model your favorite movie. You should see which tool is called in place of the model‚Äôs typical text response.

Don't worry about the `tool-getInformation` tool case in the switch statement

- we'll add that tool in a later section.

### [Improving UX with Multi-Step Calls](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#improving-ux-with-multi-step-calls)

It would be nice if the model could summarize the action too. However, technically, once the model calls a tool, it has completed its generation as it ‚Äògenerated‚Äô a tool call. How could you achieve this desired behaviour?

The AI SDK has a feature called [`stopWhen`](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling#multi-step-calls) which allows stopping conditions when the model generates a tool call. If those stopping conditions haven't been hit, the AI SDK will automatically send tool call results back to the model!

Open your root page ( `api/chat/route.ts`) and add the following key to the `streamText` configuration object:

api/chat/route.ts

```code-block_code__yIKW2

import { createResource } from '@/lib/actions/resources';

import { openai } from '@ai-sdk/openai';

import {

  convertToModelMessages,

  streamText,

  tool,

  UIMessage,

  stepCountIs,

} from 'ai';

import { z } from 'zod';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    system: `You are a helpful assistant. Check your knowledge base before answering any questions.

    Only respond to questions using information from tool calls.

    if no relevant information is found in the tool calls, respond, "Sorry, I don't know."`,

    messages: convertToModelMessages(messages),

    stopWhen: stepCountIs(5),

    tools: {

      addResource: tool({

        description: `add a resource to your knowledge base.

          If the user provides a random piece of knowledge unprompted, use this tool without asking for confirmation.`,

        inputSchema: z.object({

          content: z

            .string()

            .describe('the content or resource to add to the knowledge base'),

        }),

        execute: async ({ content }) => createResource({ content }),

      }),

    },

  });

  return result.toUIMessageStreamResponse();

}
```

Head back to the browser and tell the model your favorite pizza topping (note: pineapple is not an option). You should see a follow-up response from the model confirming the action.

### [Retrieve Resource Tool](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#retrieve-resource-tool)

The model can now add and embed arbitrary information to your knowledge base. However, it still isn‚Äôt able to query it. Let‚Äôs create a new tool to allow the model to answer questions by finding relevant information in your knowledge base.

To find similar content, you will need to embed the users query, search the database for semantic similarities, then pass those items to the model as context alongside the query. To achieve this, let‚Äôs update your embedding logic file ( `lib/ai/embedding.ts`):

lib/ai/embedding.ts

```code-block_code__yIKW2

import { embed, embedMany } from 'ai';

import { openai } from '@ai-sdk/openai';

import { db } from '../db';

import { cosineDistance, desc, gt, sql } from 'drizzle-orm';

import { embeddings } from '../db/schema/embeddings';

const embeddingModel = openai.embedding('text-embedding-ada-002');

const generateChunks = (input: string): string[] => {

  return input

    .trim()

    .split('.')

    .filter(i => i !== '');

};

export const generateEmbeddings = async (

  value: string,

): Promise<Array<{ embedding: number[]; content: string }>> => {

  const chunks = generateChunks(value);

  const { embeddings } = await embedMany({

    model: embeddingModel,

    values: chunks,

  });

  return embeddings.map((e, i) => ({ content: chunks[i], embedding: e }));

};

export const generateEmbedding = async (value: string): Promise<number[]> => {

  const input = value.replaceAll('\\n', ' ');

  const { embedding } = await embed({

    model: embeddingModel,

    value: input,

  });

  return embedding;

};

export const findRelevantContent = async (userQuery: string) => {

  const userQueryEmbedded = await generateEmbedding(userQuery);

  const similarity = sql<number>`1 - (${cosineDistance(

    embeddings.embedding,

    userQueryEmbedded,

  )})`;

  const similarGuides = await db

    .select({ name: embeddings.content, similarity })

    .from(embeddings)

    .where(gt(similarity, 0.5))

    .orderBy(t => desc(t.similarity))

    .limit(4);

  return similarGuides;

};
```

In this code, you add two functions:

- `generateEmbedding`: generate a single embedding from an input string
- `findRelevantContent`: embeds the user‚Äôs query, searches the database for similar items, then returns relevant items

With that done, it‚Äôs onto the final step: creating the tool.

Go back to your route handler ( `api/chat/route.ts`) and add a new tool called `getInformation`:

api/chat/route.ts

```code-block_code__yIKW2

import { createResource } from '@/lib/actions/resources';

import { openai } from '@ai-sdk/openai';

import {

  convertToModelMessages,

  streamText,

  tool,

  UIMessage,

  stepCountIs,

} from 'ai';

import { z } from 'zod';

import { findRelevantContent } from '@/lib/ai/embedding';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

    stopWhen: stepCountIs(5),

    system: `You are a helpful assistant. Check your knowledge base before answering any questions.

    Only respond to questions using information from tool calls.

    if no relevant information is found in the tool calls, respond, "Sorry, I don't know."`,

    tools: {

      addResource: tool({

        description: `add a resource to your knowledge base.

          If the user provides a random piece of knowledge unprompted, use this tool without asking for confirmation.`,

        inputSchema: z.object({

          content: z

            .string()

            .describe('the content or resource to add to the knowledge base'),

        }),

        execute: async ({ content }) => createResource({ content }),

      }),

      getInformation: tool({

        description: `get information from your knowledge base to answer questions.`,

        inputSchema: z.object({

          question: z.string().describe('the users question'),

        }),

        execute: async ({ question }) => findRelevantContent(question),

      }),

    },

  });

  return result.toUIMessageStreamResponse();

}
```

Head back to the browser, refresh the page, and ask for your favorite food. You should see the model call the `getInformation` tool, and then use the relevant information to formulate a response!

## [Conclusion](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#conclusion)

Congratulations, you have successfully built an AI agent that can dynamically add and retrieve information to and from a knowledge base. Throughout this guide, you learned how to create and store embeddings, set up server actions to manage resources, and use tools to extend the capabilities of your agent.

## [Troubleshooting Migration Error](https://ai-sdk.dev/cookbook/guides/rag-chatbot\#troubleshooting-migration-error)

If you experience an error with the migration, open your migration file ( `lib/db/migrations/0000_yielding_bloodaxe.sql`), cut (copy and remove) the first line, and run it directly on your postgres instance. You should now be able to run the updated migration.

If you're using the Vercel setup above, you can run the command directly by either:

- Going to the Neon console and entering the command there, or
- Going back to the Vercel platform, navigating to the Quick Start section of your database, and finding the PSQL connection command (second tab). This will connect to your instance in the terminal where you can run the command directly.

[More info](https://github.com/vercel/ai-sdk-rag-starter/issues/1).

On this page

[RAG Agent Guide](https://ai-sdk.dev/cookbook/guides/rag-chatbot#rag-agent-guide)

[What is RAG?](https://ai-sdk.dev/cookbook/guides/rag-chatbot#what-is-rag)

[Why is RAG important?](https://ai-sdk.dev/cookbook/guides/rag-chatbot#why-is-rag-important)

[Embedding](https://ai-sdk.dev/cookbook/guides/rag-chatbot#embedding)

[Chunking](https://ai-sdk.dev/cookbook/guides/rag-chatbot#chunking)

[All Together Now](https://ai-sdk.dev/cookbook/guides/rag-chatbot#all-together-now)

[Project Setup](https://ai-sdk.dev/cookbook/guides/rag-chatbot#project-setup)

[Clone Repo](https://ai-sdk.dev/cookbook/guides/rag-chatbot#clone-repo)

[Create Database](https://ai-sdk.dev/cookbook/guides/rag-chatbot#create-database)

[Setting up Postgres with Vercel](https://ai-sdk.dev/cookbook/guides/rag-chatbot#setting-up-postgres-with-vercel)

[Migrate Database](https://ai-sdk.dev/cookbook/guides/rag-chatbot#migrate-database)

[OpenAI API Key](https://ai-sdk.dev/cookbook/guides/rag-chatbot#openai-api-key)

[Build](https://ai-sdk.dev/cookbook/guides/rag-chatbot#build)

[Create Embeddings Table](https://ai-sdk.dev/cookbook/guides/rag-chatbot#create-embeddings-table)

[Add Embedding Logic](https://ai-sdk.dev/cookbook/guides/rag-chatbot#add-embedding-logic)

[Generate Chunks](https://ai-sdk.dev/cookbook/guides/rag-chatbot#generate-chunks)

[Install AI SDK](https://ai-sdk.dev/cookbook/guides/rag-chatbot#install-ai-sdk)

[Generate Embeddings](https://ai-sdk.dev/cookbook/guides/rag-chatbot#generate-embeddings)

[Update Server Action](https://ai-sdk.dev/cookbook/guides/rag-chatbot#update-server-action)

[Create Root Page](https://ai-sdk.dev/cookbook/guides/rag-chatbot#create-root-page)

[Create API Route](https://ai-sdk.dev/cookbook/guides/rag-chatbot#create-api-route)

[Refining your prompt](https://ai-sdk.dev/cookbook/guides/rag-chatbot#refining-your-prompt)

[Using Tools](https://ai-sdk.dev/cookbook/guides/rag-chatbot#using-tools)

[Add Resource Tool](https://ai-sdk.dev/cookbook/guides/rag-chatbot#add-resource-tool)

[Improving UX with Multi-Step Calls](https://ai-sdk.dev/cookbook/guides/rag-chatbot#improving-ux-with-multi-step-calls)

[Retrieve Resource Tool](https://ai-sdk.dev/cookbook/guides/rag-chatbot#retrieve-resource-tool)

[Conclusion](https://ai-sdk.dev/cookbook/guides/rag-chatbot#conclusion)

[Troubleshooting Migration Error](https://ai-sdk.dev/cookbook/guides/rag-chatbot#troubleshooting-migration-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Claude 3 Haiku
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fvertex.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)VertexClaude 3 Haiku (Vertex)
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fvertex.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Vertex/Claude 3 Haiku (Vertex)

Claude 3 Haiku is Anthropic's fastest vision and text model for near-instant responses to simple queries, meant for seamless AI experiences mimicking human interactions.

Context

200,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$1.25 / million tokens

[Model Page](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude#claude-3-haiku) [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing#claude-models)

[Terms](https://cloud.google.com/terms) [Privacy](https://cloud.google.com/terms/cloud-privacy-notice) [Website](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Simulate Readable Stream
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[generateText](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text)

[streamText](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text)

[generateObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object)

[streamObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object)

[embed](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed)

[embedMany](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed-many)

[generateImage](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image)

[transcribe](https://ai-sdk.dev/docs/reference/ai-sdk-core/transcribe)

[generateSpeech](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-speech)

[tool](https://ai-sdk.dev/docs/reference/ai-sdk-core/tool)

[dynamicTool](https://ai-sdk.dev/docs/reference/ai-sdk-core/dynamic-tool)

[experimental\_createMCPClient](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-mcp-client)

[Experimental\_StdioMCPTransport](https://ai-sdk.dev/docs/reference/ai-sdk-core/mcp-stdio-transport)

[jsonSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/json-schema)

[zodSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/zod-schema)

[valibotSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/valibot-schema)

[ModelMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/model-message)

[UIMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/ui-message)

[createProviderRegistry](https://ai-sdk.dev/docs/reference/ai-sdk-core/provider-registry)

[customProvider](https://ai-sdk.dev/docs/reference/ai-sdk-core/custom-provider)

[cosineSimilarity](https://ai-sdk.dev/docs/reference/ai-sdk-core/cosine-similarity)

[wrapLanguageModel](https://ai-sdk.dev/docs/reference/ai-sdk-core/wrap-language-model)

[LanguageModelV2Middleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/language-model-v2-middleware)

[extractReasoningMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/extract-reasoning-middleware)

[simulateStreamingMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-streaming-middleware)

[defaultSettingsMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/default-settings-middleware)

[stepCountIs](https://ai-sdk.dev/docs/reference/ai-sdk-core/step-count-is)

[hasToolCall](https://ai-sdk.dev/docs/reference/ai-sdk-core/has-tool-call)

[simulateReadableStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream)

[smoothStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream)

[generateId](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-id)

[createIdGenerator](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-id-generator)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`simulateReadableStream()`](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#simulatereadablestream)

`simulateReadableStream` is a utility function that creates a ReadableStream which emits provided values sequentially with configurable delays. This is particularly useful for testing streaming functionality or simulating time-delayed data streams.

```code-block_code__yIKW2

import { simulateReadableStream } from 'ai';

const stream = simulateReadableStream({

  chunks: ['Hello', ' ', 'World'],

  initialDelayInMs: 100,

  chunkDelayInMs: 50,

});
```

## [Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#import)

```
import { simulateReadableStream } from "ai"
```

## [API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#parameters)

### chunks:

T\[\]

Array of values to be emitted by the stream

### initialDelayInMs?:

number \| null

Initial delay in milliseconds before emitting the first value. Defaults to 0. Set to null to skip the initial delay entirely.

### chunkDelayInMs?:

number \| null

Delay in milliseconds between emitting each value. Defaults to 0. Set to null to skip delays between chunks.

### [Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#returns)

Returns a `ReadableStream<T>` that:

- Emits each value from the provided `chunks` array sequentially
- Waits for `initialDelayInMs` before emitting the first value (if not `null`)
- Waits for `chunkDelayInMs` between emitting subsequent values (if not `null`)
- Closes automatically after all chunks have been emitted

### [Type Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#type-parameters)

- `T`: The type of values contained in the chunks array and emitted by the stream

## [Examples](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#examples)

### [Basic Usage](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#basic-usage)

```code-block_code__yIKW2

const stream = simulateReadableStream({

  chunks: ['Hello', ' ', 'World'],

});
```

### [With Delays](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#with-delays)

```code-block_code__yIKW2

const stream = simulateReadableStream({

  chunks: ['Hello', ' ', 'World'],

  initialDelayInMs: 1000, // Wait 1 second before first chunk

  chunkDelayInMs: 500, // Wait 0.5 seconds between chunks

});
```

### [Without Delays](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream\#without-delays)

```code-block_code__yIKW2

const stream = simulateReadableStream({

  chunks: ['Hello', ' ', 'World'],

  initialDelayInMs: null, // No initial delay

  chunkDelayInMs: null, // No delay between chunks

});
```

On this page

[simulateReadableStream()](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#simulatereadablestream)

[Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#import)

[API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#parameters)

[Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#returns)

[Type Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#type-parameters)

[Examples](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#examples)

[Basic Usage](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#basic-usage)

[With Delays](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#with-delays)

[Without Delays](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream#without-delays)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Core Overview
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

AI SDK Core

Copy markdown

# [AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core\#ai-sdk-core)

[Overview\\
\\
Learn about AI SDK Core and how to work with Large Language Models (LLMs).](https://ai-sdk.dev/docs/ai-sdk-core/overview) [Generating Text\\
\\
Learn how to generate text.](https://ai-sdk.dev/docs/ai-sdk-core/generating-text) [Generating Structured Data\\
\\
Learn how to generate structured data.](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data) [Tool Calling\\
\\
Learn how to do tool calling with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling) [Prompt Engineering\\
\\
Learn how to write prompts with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering) [Settings\\
\\
Learn how to set up settings for language models generations.](https://ai-sdk.dev/docs/ai-sdk-core/settings) [Embeddings\\
\\
Learn how to use embeddings with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/embeddings) [Image Generation\\
\\
Learn how to generate images with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/image-generation) [Transcription\\
\\
Learn how to transcribe audio with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/transcription) [Speech\\
\\
Learn how to generate speech with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/speech) [Provider Management\\
\\
Learn how to work with multiple providers.](https://ai-sdk.dev/docs/ai-sdk-core/provider-management) [Middleware\\
\\
Learn how to use middleware with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/middleware) [Error Handling\\
\\
Learn how to handle errors with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/error-handling) [Testing\\
\\
Learn how to test with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/testing) [Telemetry\\
\\
Learn how to use telemetry with AI SDK Core.](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

On this page

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core#ai-sdk-core)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Text Completion Guide
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#completion)

The `useCompletion` hook allows you to create a user interface to handle text completions in your application. It enables the streaming of text completions from your AI provider, manages the state for chat input, and updates the UI automatically as new messages are received.

The `useCompletion` hook is now part of the `@ai-sdk/react` package.

In this guide, you will learn how to use the `useCompletion` hook in your application to generate text completions and stream them in real-time to your users.

## [Example](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#example)

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useCompletion } from '@ai-sdk/react';

export default function Page() {

  const { completion, input, handleInputChange, handleSubmit } = useCompletion({

    api: '/api/completion',

  });

  return (

    <form onSubmit={handleSubmit}>

      <input

        name="prompt"

        value={input}

        onChange={handleInputChange}

        id="input"

      />

      <button type="submit">Submit</button>

      <div>{completion}</div>

    </form>

  );

}
```

app/api/completion/route.ts

```code-block_code__yIKW2

import { streamText } from 'ai';

import { openai } from '@ai-sdk/openai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { prompt }: { prompt: string } = await req.json();

  const result = streamText({

    model: openai('gpt-3.5-turbo'),

    prompt,

  });

  return result.toUIMessageStreamResponse();

}
```

In the `Page` component, the `useCompletion` hook will request to your AI provider endpoint whenever the user submits a message. The completion is then streamed back in real-time and displayed in the UI.

This enables a seamless text completion experience where the user can see the AI response as soon as it is available, without having to wait for the entire response to be received.

## [Customized UI](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#customized-ui)

`useCompletion` also provides ways to manage the prompt via code, show loading and error states, and update messages without being triggered by user interactions.

### [Loading and error states](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#loading-and-error-states)

To show a loading spinner while the chatbot is processing the user's message, you can use the `isLoading` state returned by the `useCompletion` hook:

```code-block_code__yIKW2

const { isLoading, ... } = useCompletion()

return(

  <>

    {isLoading ? <Spinner /> : null}

  </>

)
```

Similarly, the `error` state reflects the error object thrown during the fetch request. It can be used to display an error message, or show a toast notification:

```code-block_code__yIKW2

const { error, ... } = useCompletion()

useEffect(() => {

  if (error) {

    toast.error(error.message)

  }

}, [error])

// Or display the error message in the UI:

return (

  <>

    {error ? <div>{error.message}</div> : null}

  </>

)
```

### [Controlled input](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#controlled-input)

In the initial example, we have `handleSubmit` and `handleInputChange` callbacks that manage the input changes and form submissions. These are handy for common use cases, but you can also use uncontrolled APIs for more advanced scenarios such as form validation or customized components.

The following example demonstrates how to use more granular APIs like `setInput` with your custom input and submit button components:

```code-block_code__yIKW2

const { input, setInput } = useCompletion();

return (

  <>

    <MyCustomInput value={input} onChange={value => setInput(value)} />

  </>

);
```

### [Cancelation](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#cancelation)

It's also a common use case to abort the response message while it's still streaming back from the AI provider. You can do this by calling the `stop` function returned by the `useCompletion` hook.

```code-block_code__yIKW2

const { stop, isLoading, ... } = useCompletion()

return (

  <>

    <button onClick={stop} disabled={!isLoading}>Stop</button>

  </>

)
```

When the user clicks the "Stop" button, the fetch request will be aborted. This avoids consuming unnecessary resources and improves the UX of your application.

### [Throttling UI Updates](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#throttling-ui-updates)

This feature is currently only available for React.

By default, the `useCompletion` hook will trigger a render every time a new chunk is received.
You can throttle the UI updates with the `experimental_throttle` option.

page.tsx

```code-block_code__yIKW2

const { completion, ... } = useCompletion({

  // Throttle the completion and data updates to 50ms:

  experimental_throttle: 50

})
```

## [Event Callbacks](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#event-callbacks)

`useCompletion` also provides optional event callbacks that you can use to handle different stages of the chatbot lifecycle. These callbacks can be used to trigger additional actions, such as logging, analytics, or custom UI updates.

```code-block_code__yIKW2

const { ... } = useCompletion({

  onResponse: (response: Response) => {

    console.log('Received response from server:', response)

  },

  onFinish: (prompt: string, completion: string) => {

    console.log('Finished streaming completion:', completion)

  },

  onError: (error: Error) => {

    console.error('An error occurred:', error)

  },

})
```

It's worth noting that you can abort the processing by throwing an error in the `onResponse` callback. This will trigger the `onError` callback and stop the message from being appended to the chat UI. This can be useful for handling unexpected responses from the AI provider.

## [Configure Request Options](https://ai-sdk.dev/docs/ai-sdk-ui/completion\#configure-request-options)

By default, the `useCompletion` hook sends a HTTP POST request to the `/api/completion` endpoint with the prompt as part of the request body. You can customize the request by passing additional options to the `useCompletion` hook:

```code-block_code__yIKW2

const { messages, input, handleInputChange, handleSubmit } = useCompletion({

  api: '/api/custom-completion',

  headers: {

    Authorization: 'your_token',

  },

  body: {

    user_id: '123',

  },

  credentials: 'same-origin',

});
```

In this example, the `useCompletion` hook sends a POST request to the `/api/completion` endpoint with the specified headers, additional body fields, and credentials for that fetch request. On your server side, you can handle the request with these additional information.

On this page

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion#completion)

[Example](https://ai-sdk.dev/docs/ai-sdk-ui/completion#example)

[Customized UI](https://ai-sdk.dev/docs/ai-sdk-ui/completion#customized-ui)

[Loading and error states](https://ai-sdk.dev/docs/ai-sdk-ui/completion#loading-and-error-states)

[Controlled input](https://ai-sdk.dev/docs/ai-sdk-ui/completion#controlled-input)

[Cancelation](https://ai-sdk.dev/docs/ai-sdk-ui/completion#cancelation)

[Throttling UI Updates](https://ai-sdk.dev/docs/ai-sdk-ui/completion#throttling-ui-updates)

[Event Callbacks](https://ai-sdk.dev/docs/ai-sdk-ui/completion#event-callbacks)

[Configure Request Options](https://ai-sdk.dev/docs/ai-sdk-ui/completion#configure-request-options)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## OpenAI o3-mini Model
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIo3-mini (Low)
Pro

Synced

Drop Image

OpenAI/o3-mini (Low)

o3-mini with low reasoning effort - optimized for speed while maintaining solid reasoning capabilities.

Context

200,000 tokens

Input Pricing

$1.10 / million tokens

Output Pricing

$4.40 / million tokens

[Model Page](https://platform.openai.com/docs/models/o3-mini) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Chat Prompt Text Generation
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

[Generate Text](https://ai-sdk.dev/cookbook/rsc/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/rsc/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/stream-text-with-chat-prompt)

[Generate Object](https://ai-sdk.dev/cookbook/rsc/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/rsc/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/rsc/call-tools)

[Call Tools in Parallel](https://ai-sdk.dev/cookbook/rsc/call-tools-in-parallel)

[Save Messages To Database](https://ai-sdk.dev/cookbook/rsc/save-messages-to-database)

[Restore Messages From Database](https://ai-sdk.dev/cookbook/rsc/restore-messages-from-database)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/rsc/render-visual-interface-in-chat)

[Stream Updates to Visual Interfaces](https://ai-sdk.dev/cookbook/rsc/stream-updates-to-visual-interfaces)

[Record Token Usage after Streaming User Interfaces](https://ai-sdk.dev/cookbook/rsc/stream-ui-record-token-usage)

Copy markdown

# [Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt\#generate-text-with-chat-prompt)

Previously, we were able to generate text and objects using either a single message prompt, a system prompt, or a combination of both of them. However, there may be times when you want to generate text based on a series of messages.

A chat completion allows you to generate text based on a series of messages. This series of messages can be any series of interactions between any number of systems, but the most popular and relatable use case has been a series of messages that represent a conversation between a user and a model.

http://localhost:3000

User: How is it going?

Assistant: All good, how may I help you?

Why is the sky blue?

Send Message

## [Client](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt\#client)

Let's create a simple conversation between a user and a model, and place a button that will call `continueConversation`.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useState } from 'react';

import { Message, continueConversation } from './actions';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export default function Home() {

  const [conversation, setConversation] = useState<Message[]>([]);

  const [input, setInput] = useState<string>('');

  return (

    <div>

      <div>

        {conversation.map((message, index) => (

          <div key={index}>

            {message.role}: {message.content}

          </div>

        ))}

      </div>

      <div>

        <input

          type="text"

          value={input}

          onChange={event => {

            setInput(event.target.value);

          }}

        />

        <button

          onClick={async () => {

            const { messages } = await continueConversation([\
\
              ...conversation,\
\
              { role: 'user', content: input },\
\
            ]);

            setConversation(messages);

          }}

        >

          Send Message

        </button>

      </div>

    </div>

  );

}
```

## [Server](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt\#server)

Now, let's implement the `continueConversation` function that will insert the user's message into the conversation and generate a response.

app/actions.ts

```code-block_code__yIKW2

'use server';

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

export interface Message {

  role: 'user' | 'assistant';

  content: string;

}

export async function continueConversation(history: Message[]) {

  'use server';

  const { text } = await generateText({

    model: openai('gpt-3.5-turbo'),

    system: 'You are a friendly assistant!',

    messages: history,

  });

  return {

    messages: [\
\
      ...history,\
\
      {\
\
        role: 'assistant' as const,\
\
        content: text,\
\
      },\
\
    ],

  };

}
```

On this page

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt#generate-text-with-chat-prompt)

[Client](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt#client)

[Server](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt#server)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Migration Guide
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Versioning](https://ai-sdk.dev/docs/migration-guides/versioning)

[Migrate AI SDK 4.0 to 5.0](https://ai-sdk.dev/docs/migration-guides/migration-guide-5-0)

[Migrate AI SDK 4.1 to 4.2](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2)

[Migrate AI SDK 4.0 to 4.1](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-1)

[Migrate AI SDK 3.4 to 4.0](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-0)

[Migrate AI SDK 3.3 to 3.4](https://ai-sdk.dev/docs/migration-guides/migration-guide-3-4)

[Migrate AI SDK 3.2 to 3.3](https://ai-sdk.dev/docs/migration-guides/migration-guide-3-3)

[Migrate AI SDK 3.1 to 3.2](https://ai-sdk.dev/docs/migration-guides/migration-guide-3-2)

[Migrate AI SDK 3.0 to 3.1](https://ai-sdk.dev/docs/migration-guides/migration-guide-3-1)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Migrate AI SDK 4.1 to 4.2](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#migrate-ai-sdk-41-to-42)

Check out the [AI SDK 4.2 release blog\\
post](https://vercel.com/blog/ai-sdk-4-2) for more information about the
release.

This guide will help you upgrade to AI SDK 4.2:

## [Stable APIs](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#stable-apis)

The following APIs have been moved to stable and no longer have the `experimental_` prefix:

- `customProvider`
- `providerOptions` (renamed from `providerMetadata` for provider-specific inputs)
- `providerMetadata` (for provider-specific outputs)
- `toolCallStreaming` option for `streamText`

## [Dependency Versions](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#dependency-versions)

AI SDK requires a non-optional `zod` dependency with version `^3.23.8`.

## [UI Message Parts](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#ui-message-parts)

In AI SDK 4.2, we've redesigned how `useChat` handles model outputs with message parts and multiple steps.
This is a significant improvement that simplifies rendering complex, multi-modal AI responses in your UI.

### [What's Changed](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#whats-changed)

Assistant messages with tool calling now get combined into a single message with multiple parts, rather than creating separate messages for each step.
This change addresses two key developments in AI applications:

1. **Diverse Output Types**: Models now generate more than just text; they produce reasoning steps, sources, and tool calls.
2. **Interleaved Outputs**: In multi-step agent use-cases, these different output types are frequently interleaved.

### [Benefits of the New Approach](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#benefits-of-the-new-approach)

Previously, `useChat` stored different output types separately, which made it challenging to maintain the correct sequence in your UI when these elements were interleaved in a response,
and led to multiple consecutive assistant messages when there were tool calls. For example:

```code-block_code__yIKW2

message.content = "Final answer: 42";

message.reasoning = "First I'll calculate X, then Y...";

message.toolInvocations = [{toolName: "calculator", args: {...}}];
```

This structure was limiting. The new message parts approach replaces separate properties with an ordered array that preserves the exact sequence:

```code-block_code__yIKW2

message.parts = [\
\
  { type: "text", text: "Final answer: 42" },\
\
  { type: "reasoning", reasoning: "First I'll calculate X, then Y..." },\
\
  { type: "tool-invocation", toolInvocation: { toolName: "calculator", args: {...} } },\
\
];
```

### [Migration](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2\#migration)

Existing applications using the previous message format will need to update their UI components to handle the new `parts` array.
The fields from the previous format are still available for backward compatibility, but we recommend migrating to the new format for better support of multi-modal and multi-step interactions.

You can use the `useChat` hook with the new message parts as follows:

```code-block_code__yIKW2

function Chat() {

  const { messages } = useChat();

  return (

    <div>

      {messages.map(message =>

        message.parts.map((part, i) => {

          switch (part.type) {

            case 'text':

              return <p key={i}>{part.text}</p>;

            case 'source':

              return <p key={i}>{part.source.url}</p>;

            case 'reasoning':

              return <div key={i}>{part.reasoning}</div>;

            case 'tool-invocation':

              return <div key={i}>{part.toolInvocation.toolName}</div>;

            case 'file':

              return (

                <img

                  key={i}

                  src={`data:${part.mediaType};base64,${part.data}`}

                />

              );

          }

        }),

      )}

    </div>

  );

}
```

On this page

[Migrate AI SDK 4.1 to 4.2](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#migrate-ai-sdk-41-to-42)

[Stable APIs](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#stable-apis)

[Dependency Versions](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#dependency-versions)

[UI Message Parts](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#ui-message-parts)

[What's Changed](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#whats-changed)

[Benefits of the New Approach](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#benefits-of-the-new-approach)

[Migration](https://ai-sdk.dev/docs/migration-guides/migration-guide-4-2#migration)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Reasoning Component
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Copy markdown

# [Reasoning](https://ai-sdk.dev/elements/components/reasoning\#reasoning)

The `Reasoning` component displays AI reasoning content, automatically opening during streaming and closing when finished.

Thinking...

Let me think about this problem step by step.

First, I need to understand what the user is asking for.

They want a reasoning component that opens automatically when streaming begins and closes when streaming finishes. The component should be composable and follow existi

## [Installation](https://ai-sdk.dev/elements/components/reasoning\#installation)

ai-elementsshadcnManual

```
npx ai-elements@latest add reasoning
```

## [Usage](https://ai-sdk.dev/elements/components/reasoning\#usage)

```code-block_code__yIKW2

import {

  Reasoning,

  ReasoningContent,

  ReasoningTrigger,

} from '@/components/ai-elements/reasoning';
```

```code-block_code__yIKW2

<Reasoning className="w-full" isStreaming={false}>

  <ReasoningTrigger />

  <ReasoningContent>I need to computer the square of 2.</ReasoningContent>

</Reasoning>
```

## [Usage with AI SDK](https://ai-sdk.dev/elements/components/reasoning\#usage-with-ai-sdk)

Build a chatbot with reasoning using Deepseek R1.

Add the following component to your frontend:

app/page.tsx

```code-block_code__yIKW2

'use client';

import {

  Reasoning,

  ReasoningContent,

  ReasoningTrigger,

} from '@/components/ai-elements/reasoning';

import {

  Conversation,

  ConversationContent,

  ConversationScrollButton,

} from '@/components/ai-elements/conversation';

import {

  PromptInput,

  PromptInputTextarea,

  PromptInputSubmit,

} from '@/components/ai-elements/prompt-input';

import { Loader } from '@/components/ai-elements/loader';

import { Message, MessageContent } from '@/components/ai-elements/message';

import { useState } from 'react';

import { useChat } from '@ai-sdk/react';

import { Response } from @/components/ai-elements/response';

const ReasoningDemo = () => {

  const [input, setInput] = useState('');

  const { messages, sendMessage, status } = useChat();

  const handleSubmit = (e: React.FormEvent) => {

    e.preventDefault();

    sendMessage({ text: input });

    setInput('');

  };

  return (

    <div className="max-w-4xl mx-auto p-6 relative size-full rounded-lg border h-[600px]">

      <div className="flex flex-col h-full">

        <Conversation>

          <ConversationContent>

            {messages.map((message) => (

              <Message from={message.role} key={message.id}>

                <MessageContent>

                  {message.parts.map((part, i) => {

                    switch (part.type) {

                      case 'text':

                        return (

                          <Response key={`${message.id}-${i}`}>

                            {part.text}

                          </Response>

                        );

                      case 'reasoning':

                        return (

                          <Reasoning

                            key={`${message.id}-${i}`}

                            className="w-full"

                            isStreaming={status === 'streaming'}

                          >

                            <ReasoningTrigger />

                            <ReasoningContent>{part.text}</ReasoningContent>

                          </Reasoning>

                        );

                    }

                  })}

                </MessageContent>

              </Message>

            ))}

            {status === 'submitted' && <Loader />}

          </ConversationContent>

          <ConversationScrollButton />

        </Conversation>

        <PromptInput

          onSubmit={handleSubmit}

          className="mt-4 w-full max-w-2xl mx-auto relative"

        >

          <PromptInputTextarea

            value={input}

            placeholder="Say something..."

            onChange={(e) => setInput(e.currentTarget.value)}

            className="pr-12"

          />

          <PromptInputSubmit

            status={status === 'streaming' ? 'streaming' : 'ready'}

            disabled={!input.trim()}

            className="absolute bottom-1 right-1"

          />

        </PromptInput>

      </div>

    </div>

  );

};

export default ReasoningDemo;
```

Add the following route to your backend:

app/api/chat/route.ts

```code-block_code__yIKW2

import { streamText, UIMessage, convertToModelMessages } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { model, messages }: { messages: UIMessage[]; model: string } =

    await req.json();

  const result = streamText({

    model: 'deepseek/deepseek-r1',

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse({

    sendReasoning: true,

  });

}
```

## [Features](https://ai-sdk.dev/elements/components/reasoning\#features)

- Automatically opens when streaming content and closes when finished
- Manual toggle control for user interaction
- Smooth animations and transitions powered by Radix UI
- Visual streaming indicator with pulsing animation
- Composable architecture with separate trigger and content components
- Built with accessibility in mind including keyboard navigation
- Responsive design that works across different screen sizes
- Seamlessly integrates with both light and dark themes
- Built on top of shadcn/ui Collapsible primitives
- TypeScript support with proper type definitions

## [Props](https://ai-sdk.dev/elements/components/reasoning\#props)

### [`<Reasoning />`](https://ai-sdk.dev/elements/components/reasoning\#reasoning-)

### isStreaming?:

boolean

Whether the reasoning is currently streaming (auto-opens and closes the panel).

### \[...props\]?:

React.ComponentProps<typeof Collapsible>

Any other props are spread to the underlying Collapsible component.

### [`<ReasoningTrigger />`](https://ai-sdk.dev/elements/components/reasoning\#reasoningtrigger-)

### title?:

string

Optional title to display in the trigger (default: "Reasoning").

### \[...props\]?:

React.ComponentProps<typeof CollapsibleTrigger>

Any other props are spread to the underlying CollapsibleTrigger component.

### [`<ReasoningContent />`](https://ai-sdk.dev/elements/components/reasoning\#reasoningcontent-)

### \[...props\]?:

React.ComponentProps<typeof CollapsibleContent>

Any other props are spread to the underlying CollapsibleContent component.

On this page

[Reasoning](https://ai-sdk.dev/elements/components/reasoning#reasoning)

[Installation](https://ai-sdk.dev/elements/components/reasoning#installation)

[Usage](https://ai-sdk.dev/elements/components/reasoning#usage)

[Usage with AI SDK](https://ai-sdk.dev/elements/components/reasoning#usage-with-ai-sdk)

[Features](https://ai-sdk.dev/elements/components/reasoning#features)

[Props](https://ai-sdk.dev/elements/components/reasoning#props)

[<Reasoning />](https://ai-sdk.dev/elements/components/reasoning#reasoning-)

[<ReasoningTrigger />](https://ai-sdk.dev/elements/components/reasoning#reasoningtrigger-)

[<ReasoningContent />](https://ai-sdk.dev/elements/components/reasoning#reasoningcontent-)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Text Embedding Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Embed Text](https://ai-sdk.dev/cookbook/node/embed-text\#embed-text)

Text embeddings are numerical representations of text that capture semantic meaning, allowing machines to understand and process language in a mathematical way. These vector representations are crucial for many AI applications, as they enable tasks like semantic search, document similarity comparison, and content recommendation.

This example demonstrates how to convert text into embeddings using a text embedding model. The resulting embedding is a high-dimensional vector that represents the semantic meaning of the input text. For a more practical application of embeddings, check out our [RAG example](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation) which shows how embeddings can be used for document retrieval.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { embed } from 'ai';

import 'dotenv/config';

async function main() {

  const { embedding, usage } = await embed({

    model: openai.textEmbeddingModel('text-embedding-3-small'),

    value: 'sunny day at the beach',

  });

  console.log(embedding);

  console.log(usage);

}

main().catch(console.error);
```

On this page

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text#embed-text)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## useChat Error Handling
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

[Azure OpenAI Slow to Stream](https://ai-sdk.dev/docs/troubleshooting/azure-stream-slow)

[Client-Side Function Calls Not Invoked](https://ai-sdk.dev/docs/troubleshooting/client-side-function-calls-not-invoked)

[Server Actions in Client Components](https://ai-sdk.dev/docs/troubleshooting/server-actions-in-client-components)

[useChat/useCompletion stream output contains 0:... instead of text](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output)

[Streamable UI Errors](https://ai-sdk.dev/docs/troubleshooting/streamable-ui-errors)

[Tool Invocation Missing Result Error](https://ai-sdk.dev/docs/troubleshooting/tool-invocation-missing-result)

[Streaming Not Working When Deployed](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-deployed)

[Streaming Not Working When Proxied](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-proxied)

[Getting Timeouts When Deploying on Vercel](https://ai-sdk.dev/docs/troubleshooting/timeout-on-vercel)

[Unclosed Streams](https://ai-sdk.dev/docs/troubleshooting/unclosed-streams)

[useChat Failed to Parse Stream](https://ai-sdk.dev/docs/troubleshooting/use-chat-failed-to-parse-stream)

[Server Action Plain Objects Error](https://ai-sdk.dev/docs/troubleshooting/client-stream-error)

[useChat No Response](https://ai-sdk.dev/docs/troubleshooting/use-chat-tools-no-response)

[Custom headers, body, and credentials not working with useChat](https://ai-sdk.dev/docs/troubleshooting/use-chat-custom-request-options)

[useChat "An error occurred"](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred)

[Repeated assistant messages in useChat](https://ai-sdk.dev/docs/troubleshooting/repeated-assistant-messages)

[onFinish not called when stream is aborted](https://ai-sdk.dev/docs/troubleshooting/stream-abort-handling)

[streamText fails silently](https://ai-sdk.dev/docs/troubleshooting/stream-text-not-working)

[Streaming Status Shows But No Text Appears](https://ai-sdk.dev/docs/troubleshooting/streaming-status-delay)

[Model is not assignable to type "LanguageModelV1"](https://ai-sdk.dev/docs/troubleshooting/model-is-not-assignable-to-type)

[TypeScript error "Cannot find namespace 'JSX'"](https://ai-sdk.dev/docs/troubleshooting/typescript-cannot-find-namespace-jsx)

[React error "Maximum update depth exceeded"](https://ai-sdk.dev/docs/troubleshooting/react-maximum-update-depth-exceeded)

[Jest: cannot find module '@ai-sdk/rsc'](https://ai-sdk.dev/docs/troubleshooting/jest-cannot-find-module-ai-rsc)

Copy markdown

# [`useChat` "An error occurred"](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred\#usechat-an-error-occurred)

## [Issue](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred\#issue)

I am using [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat) and I get the error "An error occurred".

## [Background](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred\#background)

Error messages from `streamText` are masked by default when using `toDataStreamResponse` for security reasons (secure-by-default).
This prevents leaking sensitive information to the client.

## [Solution](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred\#solution)

To forward error details to the client or to log errors, use the `getErrorMessage` function when calling `toDataStreamResponse`.

```code-block_code__yIKW2

export function errorHandler(error: unknown) {

  if (error == null) {

    return 'unknown error';

  }

  if (typeof error === 'string') {

    return error;

  }

  if (error instanceof Error) {

    return error.message;

  }

  return JSON.stringify(error);

}
```

```code-block_code__yIKW2

const result = streamText({

  // ...

});

return result.toUIMessageStreamResponse({

  getErrorMessage: errorHandler,

});
```

In case you are using `createDataStreamResponse`, you can use the `onError` function when calling `toDataStreamResponse`:

```code-block_code__yIKW2

const response = createDataStreamResponse({

  // ...

  async execute(dataStream) {

    // ...

  },

  onError: errorHandler,

});
```

On this page

[useChat "An error occurred"](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred#usechat-an-error-occurred)

[Issue](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred#issue)

[Background](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred#background)

[Solution](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred#solution)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Cerebras Llama 3.1
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

CerebrasLlama 3.1 8B
Hobby

Synced

Drop Image

Cerebras/Llama 3.1 8B

Llama 3.1 8B brings powerful performance in a smaller, more efficient package. With improved multilingual support, tool use, and a 128K context length, it enables sophisticated use cases like interactive agents and compact coding assistants while remaining lightweight and accessible.

Context

128,000 tokens

Input Pricing

$0.10 / million tokens

Output Pricing

$0.10 / million tokens

[Model Page](https://inference-docs.cerebras.ai/introduction) [Pricing](https://inference-docs.cerebras.ai/support/pricing)

[Terms](https://www.cerebras.ai/terms-of-service) [Privacy](https://www.cerebras.ai/privacy-policy) [Website](https://inference-docs.cerebras.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AI Chat Examples
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Examples

Copy markdown

# [Examples](https://ai-sdk.dev/elements/examples\#examples)

This section provides practical examples of how to combine AI Elements‚Äîsuch as `Conversation`, `Message`, `Input`, and more‚Äîto build complete, interactive chat interfaces. By leveraging these building blocks, you can create sophisticated conversational experiences that are both user-friendly and highly customizable.

Explore the following examples to see how individual components work together in real-world scenarios. Each example demonstrates how to assemble elements into cohesive layouts, manage user input, display AI responses, and enhance conversations with features like suggestions, sources, and reasoning. Whether you're building a simple chatbot or a complex AI assistant, these examples will help you get started quickly and inspire your own interface designs.

On this page

[Examples](https://ai-sdk.dev/elements/examples#examples)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Multi-Step Text Streaming
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [streamText Multi-Step Agent](https://ai-sdk.dev/cookbook/next/stream-text-multistep\#streamtext-multi-step-agent)

You may want to have different steps in your stream where each step has different settings,
e.g. models, tools, or system prompts.

With `createUIMessageStream` and `sendFinish` / `sendStart` options when merging
into the `UIMessageStream`, you can control when the finish and start events are sent to the client,
allowing you to have different steps in a single assistant UI message.

## [Server](https://ai-sdk.dev/cookbook/next/stream-text-multistep\#server)

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import {

  convertToModelMessages,

  createUIMessageStream,

  createUIMessageStreamResponse,

  streamText,

  tool,

} from 'ai';

import { z } from 'zod';

export async function POST(req: Request) {

  const { messages } = await req.json();

  const stream = createUIMessageStream({

    execute: async ({ writer }) => {

      // step 1 example: forced tool call

      const result1 = streamText({

        model: openai('gpt-4o-mini'),

        system: 'Extract the user goal from the conversation.',

        messages,

        toolChoice: 'required', // force the model to call a tool

        tools: {

          extractGoal: tool({

            inputSchema: z.object({ goal: z.string() }),

            execute: async ({ goal }) => goal, // no-op extract tool

          }),

        },

      });

      // forward the initial result to the client without the finish event:

      writer.merge(result1.toUIMessageStream({ sendFinish: false }));

      // note: you can use any programming construct here, e.g. if-else, loops, etc.

      // workflow programming is normal programming with this approach.

      // example: continue stream with forced tool call from previous step

      const result2 = streamText({

        // different system prompt, different model, no tools:

        model: openai('gpt-4o'),

        system:

          'You are a helpful assistant with a different system prompt. Repeat the extract user goal in your answer.',

        // continue the workflow stream with the messages from the previous step:

        messages: [\
\
          ...convertToModelMessages(messages),\
\
          ...(await result1.response).messages,\
\
        ],

      });

      // forward the 2nd result to the client (incl. the finish event):

      writer.merge(result2.toUIMessageStream({ sendStart: false }));

    },

  });

  return createUIMessageStreamResponse({ stream });

}
```

## [Client](https://ai-sdk.dev/cookbook/next/stream-text-multistep\#client)

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat();

  return (

    <div>

      {messages?.map(message => (

        <div key={message.id}>

          <strong>{`${message.role}: `}</strong>

          {message.parts.map((part, index) => {

            switch (part.type) {

              case 'text':

                return <span key={index}>{part.text}</span>;

              case 'tool-extractGoal': {

                return <pre key={index}>{JSON.stringify(part, null, 2)}</pre>;

              }

            }

          })}

        </div>

      ))}

      <form

        onSubmit={e => {

          e.preventDefault();

          sendMessage({ text: input });

          setInput('');

        }}

      >

        <input value={input} onChange={e => setInput(e.currentTarget.value)} />

      </form>

    </div>

  );

}
```

On this page

[streamText Multi-Step Agent](https://ai-sdk.dev/cookbook/next/stream-text-multistep#streamtext-multi-step-agent)

[Server](https://ai-sdk.dev/cookbook/next/stream-text-multistep#server)

[Client](https://ai-sdk.dev/cookbook/next/stream-text-multistep#client)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Mutable AI State
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[streamUI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/stream-ui)

[createAI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-ai)

[createStreamableUI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-streamable-ui)

[createStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-streamable-value)

[readStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/read-streamable-value)

[getAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-ai-state)

[getMutableAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state)

[useAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ai-state)

[useActions](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-actions)

[useUIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state)

[useStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-streamable-value)

[render (Removed)](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/render)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`getMutableAIState`](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#getmutableaistate)

AI SDK RSC is currently experimental. We recommend using [AI SDK\\
UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview) for production. For guidance on migrating from
RSC to UI, see our [migration guide](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui).

Get a mutable copy of the AI state. You can use this to update the state in the server.

## [Import](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#import)

```
import { getMutableAIState } from "@ai-sdk/rsc"
```

## [API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#parameters)

### key?:

string

Returns the value of the specified key in the AI state, if it's an object.

### [Returns](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#returns)

The mutable AI state.

### [Methods](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#methods)

### update:

(newState: any) => void

Updates the AI state with the new state.

### done:

(newState: any) => void

Updates the AI state with the new state, marks it as finalized and closes the stream.

## [Examples](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state\#examples)

[Learn to persist and restore states AI and UI states in Next.js](https://ai-sdk.dev/examples/next-app/state-management/save-and-restore-states)

On this page

[getMutableAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#getmutableaistate)

[Import](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#import)

[API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#parameters)

[Returns](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#returns)

[Methods](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#methods)

[Examples](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state#examples)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## GPT-4.1 Nano Model
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIGPT-4.1 nano
Pro

Synced

Drop Image

OpenAI/GPT-4.1 nano

GPT-4.1 nano is the fastest, most cost-effective GPT 4.1 model.

Context

1,047,576 tokens

Input Pricing

$0.10 / million tokens

Output Pricing

$0.40 / million tokens

[Model Page](https://platform.openai.com/docs/models/gpt-4.1-nano) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Invalid Tool Arguments Error
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error\#ai_invalidtoolargumentserror)

This error occurs when invalid tool argument was provided.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error\#properties)

- `toolName`: The name of the tool with invalid arguments
- `toolArgs`: The invalid tool arguments
- `message`: The error message
- `cause`: The cause of the error

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error\#checking-for-this-error)

You can check if an error is an instance of `AI_InvalidToolArgumentsError` using:

```code-block_code__yIKW2

import { InvalidToolArgumentsError } from 'ai';

if (InvalidToolArgumentsError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error#ai_invalidtoolargumentserror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Speech Generation
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech\#speech)

Speech is an experimental feature.

The AI SDK provides the [`generateSpeech`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-speech)
function to generate speech from text using a speech model.

```code-block_code__yIKW2

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { openai } from '@ai-sdk/openai';

import { readFile } from 'fs/promises';

const audio = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  voice: 'alloy',

});
```

### [Language Setting](https://ai-sdk.dev/docs/ai-sdk-core/speech\#language-setting)

You can specify the language for speech generation (provider support varies):

```code-block_code__yIKW2

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { lmnt } from '@ai-sdk/lmnt';

const audio = await generateSpeech({

  model: lmnt.speech('aurora'),

  text: 'Hola, mundo!',

  language: 'es', // Spanish

});
```

To access the generated audio:

```code-block_code__yIKW2

const audio = audio.audioData; // audio data e.g. Uint8Array
```

## [Settings](https://ai-sdk.dev/docs/ai-sdk-core/speech\#settings)

### [Provider-Specific settings](https://ai-sdk.dev/docs/ai-sdk-core/speech\#provider-specific-settings)

You can set model-specific settings with the `providerOptions` parameter.

```code-block_code__yIKW2

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { openai } from '@ai-sdk/openai';

import { readFile } from 'fs/promises';

const audio = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  providerOptions: {

    openai: {

      // ...

    },

  },

});
```

### [Abort Signals and Timeouts](https://ai-sdk.dev/docs/ai-sdk-core/speech\#abort-signals-and-timeouts)

`generateSpeech` accepts an optional `abortSignal` parameter of
type [`AbortSignal`](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal)
that you can use to abort the speech generation process or set a timeout.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { readFile } from 'fs/promises';

const audio = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  abortSignal: AbortSignal.timeout(1000), // Abort after 1 second

});
```

### [Custom Headers](https://ai-sdk.dev/docs/ai-sdk-core/speech\#custom-headers)

`generateSpeech` accepts an optional `headers` parameter of type `Record<string, string>`
that you can use to add custom headers to the speech generation request.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { readFile } from 'fs/promises';

const audio = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  headers: { 'X-Custom-Header': 'custom-value' },

});
```

### [Warnings](https://ai-sdk.dev/docs/ai-sdk-core/speech\#warnings)

Warnings (e.g. unsupported parameters) are available on the `warnings` property.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { readFile } from 'fs/promises';

const audio = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

});

const warnings = audio.warnings;
```

### [Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/speech\#error-handling)

When `generateSpeech` cannot generate a valid audio, it throws a [`AI_NoAudioGeneratedError`](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error).

This error can arise for any the following reasons:

- The model failed to generate a response
- The model generated a response that could not be parsed

The error preserves the following information to help you log the issue:

- `responses`: Metadata about the speech model responses, including timestamp, model, and headers.
- `cause`: The cause of the error. You can use this for more detailed error handling.

```code-block_code__yIKW2

import {

  experimental_generateSpeech as generateSpeech,

  AI_NoAudioGeneratedError,

} from 'ai';

import { openai } from '@ai-sdk/openai';

import { readFile } from 'fs/promises';

try {

  await generateSpeech({

    model: openai.speech('tts-1'),

    text: 'Hello, world!',

  });

} catch (error) {

  if (AI_NoAudioGeneratedError.isInstance(error)) {

    console.log('AI_NoAudioGeneratedError');

    console.log('Cause:', error.cause);

    console.log('Responses:', error.responses);

  }

}
```

## [Speech Models](https://ai-sdk.dev/docs/ai-sdk-core/speech\#speech-models)

| Provider | Model |
| --- | --- |
| [OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai#speech-models) | `tts-1` |
| [OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai#speech-models) | `tts-1-hd` |
| [OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai#speech-models) | `gpt-4o-mini-tts` |
| [LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt#speech-models) | `aurora` |
| [LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt#speech-models) | `blizzard` |
| [Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume#speech-models) | `default` |

Above are a small subset of the speech models supported by the AI SDK providers. For more, see the respective provider documentation.

On this page

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech#speech)

[Language Setting](https://ai-sdk.dev/docs/ai-sdk-core/speech#language-setting)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/speech#settings)

[Provider-Specific settings](https://ai-sdk.dev/docs/ai-sdk-core/speech#provider-specific-settings)

[Abort Signals and Timeouts](https://ai-sdk.dev/docs/ai-sdk-core/speech#abort-signals-and-timeouts)

[Custom Headers](https://ai-sdk.dev/docs/ai-sdk-core/speech#custom-headers)

[Warnings](https://ai-sdk.dev/docs/ai-sdk-core/speech#warnings)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/speech#error-handling)

[Speech Models](https://ai-sdk.dev/docs/ai-sdk-core/speech#speech-models)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Deepgram Transcription API
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [Deepgram Provider](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram\#deepgram-provider)

The [Deepgram](https://deepgram.com/) provider contains language model support for the Deepgram transcription API.

## [Setup](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram\#setup)

The Deepgram provider is available in the `@ai-sdk/deepgram` module. You can install it with

pnpm

npm

yarn

bun

```
pnpm add @ai-sdk/deepgram
```

## [Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram\#provider-instance)

You can import the default provider instance `deepgram` from `@ai-sdk/deepgram`:

```code-block_code__yIKW2

import { deepgram } from '@ai-sdk/deepgram';
```

If you need a customized setup, you can import `createDeepgram` from `@ai-sdk/deepgram` and create a provider instance with your settings:

```code-block_code__yIKW2

import { createDeepgram } from '@ai-sdk/deepgram';

const deepgram = createDeepgram({

  // custom settings, e.g.

  fetch: customFetch,

});
```

You can use the following optional settings to customize the Deepgram provider instance:

- **apiKey** _string_

API key that is being sent using the `Authorization` header.
It defaults to the `DEEPGRAM_API_KEY` environment variable.

- **headers** _Record<string,string>_

Custom headers to include in the requests.

- **fetch** _(input: RequestInfo, init?: RequestInit) => Promise<Response>_

Custom [fetch](https://developer.mozilla.org/en-US/docs/Web/API/fetch) implementation.
Defaults to the global `fetch` function.
You can use it as a middleware to intercept requests,
or to provide a custom fetch implementation for e.g. testing.


## [Transcription Models](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram\#transcription-models)

You can create models that call the [Deepgram transcription API](https://developers.deepgram.com/docs/pre-recorded-audio)
using the `.transcription()` factory method.

The first argument is the model id e.g. `nova-3`.

```code-block_code__yIKW2

const model = deepgram.transcription('nova-3');
```

You can also pass additional provider-specific options using the `providerOptions` argument. For example, supplying the `summarize` option will enable summaries for sections of content.

```code-block_code__yIKW2

import { experimental_transcribe as transcribe } from 'ai';

import { deepgram } from '@ai-sdk/deepgram';

import { readFile } from 'fs/promises';

const result = await transcribe({

  model: deepgram.transcription('nova-3'),

  audio: await readFile('audio.mp3'),

  providerOptions: { deepgram: { summarize: true } },

});
```

The following provider options are available:

- **language** _string_

Language code for the audio.
Supports numerous ISO-639-1 and ISO-639-3 language codes.
Optional.

- **smartFormat** _boolean_

Whether to apply smart formatting to the transcription.
Optional.

- **punctuate** _boolean_

Whether to add punctuation to the transcription.
Optional.

- **paragraphs** _boolean_

Whether to format the transcription into paragraphs.
Optional.

- **summarize** _enum \| boolean_

Whether to generate a summary of the transcription.
Allowed values: `'v2'`, `false`.
Optional.

- **topics** _boolean_

Whether to detect topics in the transcription.
Optional.

- **intents** _boolean_

Whether to detect intents in the transcription.
Optional.

- **sentiment** _boolean_

Whether to perform sentiment analysis on the transcription.
Optional.

- **detectEntities** _boolean_

Whether to detect entities in the transcription.
Optional.

- **redact** _string \| array of strings_

Specifies what content to redact from the transcription.
Optional.

- **replace** _string_

Replacement string for redacted content.
Optional.

- **search** _string_

Search term to find in the transcription.
Optional.

- **keyterm** _string_

Key terms to identify in the transcription.
Optional.

- **diarize** _boolean_

Whether to identify different speakers in the transcription.
Defaults to `true`.
Optional.

- **utterances** _boolean_

Whether to segment the transcription into utterances.
Optional.

- **uttSplit** _number_

Threshold for splitting utterances.
Optional.

- **fillerWords** _boolean_

Whether to include filler words (um, uh, etc.) in the transcription.
Optional.


### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram\#model-capabilities)

| Model | Transcription | Duration | Segments | Language |
| --- | --- | --- | --- | --- |
| `nova-3` (\+ [variants](https://developers.deepgram.com/docs/models-languages-overview#nova-3)) |  |  |  |  |
| `nova-2` (\+ [variants](https://developers.deepgram.com/docs/models-languages-overview#nova-2)) |  |  |  |  |
| `nova` (\+ [variants](https://developers.deepgram.com/docs/models-languages-overview#nova)) |  |  |  |  |
| `enhanced` (\+ [variants](https://developers.deepgram.com/docs/models-languages-overview#enhanced)) |  |  |  |  |
| `base` (\+ [variants](https://developers.deepgram.com/docs/models-languages-overview#base)) |  |  |  |  |

On this page

[Deepgram Provider](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram#deepgram-provider)

[Setup](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram#setup)

[Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram#provider-instance)

[Transcription Models](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram#transcription-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram#model-capabilities)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Claude Model Overview
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

Anthropicclaude-1
Pro

Drop Image

Anthropic/claude-1

An older version of Anthropic's Claude model that excels at a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction. It is good for complex reasoning, creativity, thoughtful dialogue, coding, and detailed content creation.

Context

100,000 tokens

Input Pricing

$11.02 / million tokens

Output Pricing

$32.62 / million tokens

[Model Page](https://docs.anthropic.com/en/docs/about-claude/models#legacy-models) [Pricing](https://www.anthropic.com/pricing#anthropic-api)

[Terms](https://www.anthropic.com/legal/commercial-terms) [Privacy](https://privacy.anthropic.com/en/) [Website](https://www.anthropic.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## MetaLlama 4 Scout
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fmeta.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)MetaLlama 4 Scout 17B 16E Instruct
Hobby

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fmeta.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Meta/Llama 4 Scout 17B 16E Instruct

Precise context understanding with efficient reasoning capabilities

Context

1,000,000 tokens

Input Pricing

$0.13 / million tokens

Output Pricing

$0.50 / million tokens

[Model Page](https://www.baseten.co/library/llama-4-scout/) [Pricing](https://www.baseten.co/pricing/)

[Terms](https://www.baseten.co/terms-and-conditions/) [Privacy](https://www.baseten.co/privacy-policy/) [Website](https://www.baseten.co/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Authentication in AI SDK
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Overview](https://ai-sdk.dev/docs/ai-sdk-rsc/overview)

[Streaming React Components](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-react-components)

[Managing Generative UI State](https://ai-sdk.dev/docs/ai-sdk-rsc/generative-ui-state)

[Saving and Restoring States](https://ai-sdk.dev/docs/ai-sdk-rsc/saving-and-restoring-states)

[Multistep Interfaces](https://ai-sdk.dev/docs/ai-sdk-rsc/multistep-interfaces)

[Streaming Values](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-values)

[Handling Loading State](https://ai-sdk.dev/docs/ai-sdk-rsc/loading-state)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling)

[Handling Authentication](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication)

[Migrating from RSC to UI](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Authentication](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication\#authentication)

AI SDK RSC is currently experimental. We recommend using [AI SDK\\
UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview) for production. For guidance on migrating from
RSC to UI, see our [migration guide](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui).

The RSC API makes extensive use of [`Server Actions`](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations) to power streaming values and UI from the server.

Server Actions are exposed as public, unprotected endpoints. As a result, you should treat Server Actions as you would public-facing API endpoints and ensure that the user is authorized to perform the action before returning any data.

app/actions.tsx

```code-block_code__yIKW2

'use server';

import { cookies } from 'next/headers';

import { createStremableUI } from '@ai-sdk/rsc';

import { validateToken } from '../utils/auth';

export const getWeather = async () => {

  const token = cookies().get('token');

  if (!token || !validateToken(token)) {

    return {

      error: 'This action requires authentication',

    };

  }

  const streamableDisplay = createStreamableUI(null);

  streamableDisplay.update(<Skeleton />);

  streamableDisplay.done(<Weather />);

  return {

    display: streamableDisplay.value,

  };

};
```

On this page

[Authentication](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication#authentication)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Fastify AI SDK Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify\#fastify)

You can use the AI SDK in a [Fastify](https://fastify.dev/) server to generate and stream text and objects to the client.

## [Examples](https://ai-sdk.dev/cookbook/api-servers/fastify\#examples)

The examples start a simple HTTP server that listens on port 8080. You can e.g. test it using `curl`:

```code-block_code__yIKW2

curl -X POST http://localhost:8080
```

The examples use the OpenAI `gpt-4o` model. Ensure that the OpenAI API key is
set in the `OPENAI_API_KEY` environment variable.

**Full example**: [github.com/vercel/ai/examples/fastify](https://github.com/vercel/ai/tree/main/examples/fastify)

### [Data Stream](https://ai-sdk.dev/cookbook/api-servers/fastify\#data-stream)

You can use the `toDataStream` method to get a data stream from the result and then pipe it to the response.

index.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

import Fastify from 'fastify';

const fastify = Fastify({ logger: true });

fastify.post('/', async function (request, reply) {

  const result = streamText({

    model: openai('gpt-4o'),

    prompt: 'Invent a new holiday and describe its traditions.',

  });

  // Mark the response as a v1 data stream:

  reply.header('X-Vercel-AI-Data-Stream', 'v1');

  reply.header('Content-Type', 'text/plain; charset=utf-8');

  return reply.send(result.toDataStream({ data }));

});

fastify.listen({ port: 8080 });
```

### [Sending Custom Data](https://ai-sdk.dev/cookbook/api-servers/fastify\#sending-custom-data)

`createDataStream` can be used to send custom data to the client.

index.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { createDataStream, streamText } from 'ai';

import Fastify from 'fastify';

const fastify = Fastify({ logger: true });

fastify.post('/stream-data', async function (request, reply) {

  // immediately start streaming the response

  const dataStream = createDataStream({

    execute: async dataStreamWriter => {

      dataStreamWriter.writeData('initialized call');

      const result = streamText({

        model: openai('gpt-4o'),

        prompt: 'Invent a new holiday and describe its traditions.',

      });

      result.mergeIntoDataStream(dataStreamWriter);

    },

    onError: error => {

      // Error messages are masked by default for security reasons.

      // If you want to expose the error message to the client, you can do so here:

      return error instanceof Error ? error.message : String(error);

    },

  });

  // Mark the response as a v1 data stream:

  reply.header('X-Vercel-AI-Data-Stream', 'v1');

  reply.header('Content-Type', 'text/plain; charset=utf-8');

  return reply.send(dataStream);

});

fastify.listen({ port: 8080 });
```

### [Text Stream](https://ai-sdk.dev/cookbook/api-servers/fastify\#text-stream)

You can use the `textStream` property to get a text stream from the result and then pipe it to the response.

index.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

import Fastify from 'fastify';

const fastify = Fastify({ logger: true });

fastify.post('/', async function (request, reply) {

  const result = streamText({

    model: openai('gpt-4o'),

    prompt: 'Invent a new holiday and describe its traditions.',

  });

  reply.header('Content-Type', 'text/plain; charset=utf-8');

  return reply.send(result.textStream);

});

fastify.listen({ port: 8080 });
```

## [Troubleshooting](https://ai-sdk.dev/cookbook/api-servers/fastify\#troubleshooting)

- Streaming not working when [proxied](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-proxied)

On this page

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify#fastify)

[Examples](https://ai-sdk.dev/cookbook/api-servers/fastify#examples)

[Data Stream](https://ai-sdk.dev/cookbook/api-servers/fastify#data-stream)

[Sending Custom Data](https://ai-sdk.dev/cookbook/api-servers/fastify#sending-custom-data)

[Text Stream](https://ai-sdk.dev/cookbook/api-servers/fastify#text-stream)

[Troubleshooting](https://ai-sdk.dev/cookbook/api-servers/fastify#troubleshooting)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Invalid Argument Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error\#ai_invalidargumenterror)

This error occurs when an invalid argument was provided.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error\#properties)

- `parameter`: The name of the parameter that is invalid
- `value`: The invalid value
- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error\#checking-for-this-error)

You can check if an error is an instance of `AI_InvalidArgumentError` using:

```code-block_code__yIKW2

import { InvalidArgumentError } from 'ai';

if (InvalidArgumentError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error#ai_invalidargumenterror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI No Content Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error\#ai_nocontentgeneratederror)

This error occurs when the AI provider fails to generate content.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error\#properties)

- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error\#checking-for-this-error)

You can check if an error is an instance of `AI_NoContentGeneratedError` using:

```code-block_code__yIKW2

import { NoContentGeneratedError } from 'ai';

if (NoContentGeneratedError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error#ai_nocontentgeneratederror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Models Playground
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fgroq.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)GroqQWQ-32B

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fgroq.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Groq/QWQ-32B

Qwen QWQ-32B is a powerful large language model with strong reasoning capabilities and versatile applications across various tasks. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context

32,768 tokens

Input Pricing

$0.29 / million tokens

Output Pricing

$0.39 / million tokens

[Model Page](https://console.groq.com/docs/model/qwen-qwq-32b) [Pricing](https://wow.groq.com/)

[Terms](https://console.groq.com/docs/terms-of-sale) [Privacy](https://groq.com/privacy-policy) [Website](https://groq.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AzureGPT-4.1 Nano
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

AzureGPT-4.1 nano
Pro

Synced

Drop Image

OpenAI/GPT-4.1 nano

GPT-4.1 nano is the fastest, most cost-effective GPT 4.1 model.

Context

1,047,576 tokens

Input Pricing

$0.10 / million tokens

Output Pricing

$0.40 / million tokens

[Model Page](https://platform.openai.com/docs/models/gpt-4.1-nano) [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service)

[Terms](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/code-of-conduct) [Privacy](https://privacy.microsoft.com/en-us/privacystatement) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Image Generation Tool
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt\#generate-image-with-chat-prompt)

When building a chatbot, you may want to allow the user to generate an image. This can be done by creating a tool that generates an image using the [`experimental_generateImage`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#generateimage) function from the AI SDK.

## [Server](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt\#server)

Let's create an endpoint at `/api/chat` that generates the assistant's response based on the conversation history. You will also define a tool called `generateImage` that will generate an image based on the assistant's response.

tools/get-weather.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { experimental_generateImage, tool } from 'ai';

import z from 'zod';

export const generateImage = tool({

  description: 'Generate an image',

  inputSchema: z.object({

    prompt: z.string().describe('The prompt to generate the image from'),

  }),

  execute: async ({ prompt }) => {

    const { image } = await experimental_generateImage({

      model: openai.imageModel('dall-e-3'),

      prompt,

    });

    // in production, save this image to blob storage and return a URL

    return { image: image.base64, prompt };

  },

});
```

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import {

  convertToModelMessages,

  type InferUITools,

  stepCountIs,

  streamText,

  type UIMessage,

} from 'ai';

import { generateImage } from '@/tools/get-weather';

const tools = {

  generateImage,

};

export type ChatTools = InferUITools<typeof tools>;

export async function POST(request: Request) {

  const { messages }: { messages: UIMessage[] } = await request.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

    stopWhen: stepCountIs(5),

    tools,

  });

  return result.toUIMessageStreamResponse();

}
```

In production, you should save the generated image to a blob storage and
return a URL instead of the base64 image data. If you don't, the base64 image
data will be sent to the model which may cause the generation to fail.

## [Client](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt\#client)

Let's create a simple chat interface with `useChat`. You will call the `/api/chat` endpoint to generate the assistant's response. If the assistant's response contains a `generateImage` tool invocation, you will display the tool result (the image in base64 format and the prompt) using the Next `Image` component.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { DefaultChatTransport, type UIMessage } from 'ai';

import Image from 'next/image';

import { type FormEvent, useState } from 'react';

import type { ChatTools } from './api/chat/route';

type ChatMessage = UIMessage<never, never, ChatTools>;

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat<ChatMessage>({

    transport: new DefaultChatTransport({

      api: '/api/chat',

    }),

  });

  const handleInputChange = (event: React.ChangeEvent<HTMLInputElement>) => {

    setInput(event.target.value);

  };

  const handleSubmit = async (event: FormEvent<HTMLFormElement>) => {

    event.preventDefault();

    sendMessage({

      parts: [{ type: 'text', text: input }],

    });

    setInput('');

  };

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      <div className="space-y-4">

        {messages.map(message => (

          <div key={message.id} className="whitespace-pre-wrap">

            <div key={message.id}>

              <div className="font-bold">{message.role}</div>

              {message.parts.map((part, partIndex) => {

                const { type } = part;

                if (type === 'text') {

                  return (

                    <div key={`${message.id}-part-${partIndex}`}>

                      {part.text}

                    </div>

                  );

                }

                if (type === 'tool-generateImage') {

                  const { state, toolCallId } = part;

                  if (state === 'input-available') {

                    return (

                      <div key={`${message.id}-part-${partIndex}`}>

                        Generating image...

                      </div>

                    );

                  }

                  if (state === 'output-available') {

                    const { input, output } = part;

                    return (

                      <Image

                        key={toolCallId}

                        src={`data:image/png;base64,${output.image}`}

                        alt={input.prompt}

                        height={400}

                        width={400}

                      />

                    );

                  }

                }

              })}

            </div>

          </div>

        ))}

      </div>

      <form onSubmit={handleSubmit}>

        <input

          className="fixed bottom-0 w-full max-w-md p-2 mb-8 border border-gray-300 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={handleInputChange}

        />

      </form>

    </div>

  );

}
```

On this page

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt#generate-image-with-chat-prompt)

[Server](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt#server)

[Client](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt#client)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Streaming Custom Data
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#streaming-custom-data)

It is often useful to send additional data alongside the model's response.
For example, you may want to send status information, the message ids after storing them,
or references to content that the language model is referring to.

The AI SDK provides several helpers that allows you to stream additional data to the client
and attach it to the `UIMessage` parts array:

- `createUIMessageStream`: creates a data stream
- `createUIMessageStreamResponse`: creates a response object that streams data
- `pipeUIMessageStreamToResponse`: pipes a data stream to a server response object

The data is streamed as part of the response stream using Server-Sent Events.

## [Setting Up Type-Safe Data Streaming](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#setting-up-type-safe-data-streaming)

First, define your custom message type with data part schemas for type safety:

ai/types.ts

```code-block_code__yIKW2

import { UIMessage } from 'ai';

// Define your custom message type with data part schemas

export type MyUIMessage = UIMessage<

  never, // metadata type

  {

    weather: {

      city: string;

      weather?: string;

      status: 'loading' | 'success';

    };

    notification: {

      message: string;

      level: 'info' | 'warning' | 'error';

    };

  } // data parts type

>;
```

## [Streaming Data from the Server](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#streaming-data-from-the-server)

In your server-side route handler, you can create a `UIMessageStream` and then pass it to `createUIMessageStreamResponse`:

route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import {

  createUIMessageStream,

  createUIMessageStreamResponse,

  streamText,

  convertToModelMessages,

} from 'ai';

import { MyUIMessage } from '@/ai/types';

export async function POST(req: Request) {

  const { messages } = await req.json();

  const stream = createUIMessageStream<MyUIMessage>({

    execute: ({ writer }) => {

      // 1. Send initial status (transient - won't be added to message history)

      writer.write({

        type: 'data-notification',

        data: { message: 'Processing your request...', level: 'info' },

        transient: true, // This part won't be added to message history

      });

      // 2. Send sources (useful for RAG use cases)

      writer.write({

        type: 'source',

        value: {

          type: 'source',

          sourceType: 'url',

          id: 'source-1',

          url: 'https://weather.com',

          title: 'Weather Data Source',

        },

      });

      // 3. Send data parts with loading state

      writer.write({

        type: 'data-weather',

        id: 'weather-1',

        data: { city: 'San Francisco', status: 'loading' },

      });

      const result = streamText({

        model: openai('gpt-4.1'),

        messages: convertToModelMessages(messages),

        onFinish() {

          // 4. Update the same data part (reconciliation)

          writer.write({

            type: 'data-weather',

            id: 'weather-1', // Same ID = update existing part

            data: {

              city: 'San Francisco',

              weather: 'sunny',

              status: 'success',

            },

          });

          // 5. Send completion notification (transient)

          writer.write({

            type: 'data-notification',

            data: { message: 'Request completed', level: 'info' },

            transient: true, // Won't be added to message history

          });

        },

      });

      writer.merge(result.toUIMessageStream());

    },

  });

  return createUIMessageStreamResponse({ stream });

}
```

You can also send stream data from custom backends, e.g. Python / FastAPI,
using the [UI Message Stream\\
Protocol](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#ui-message-stream-protocol).

## [Types of Streamable Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#types-of-streamable-data)

### [Data Parts (Persistent)](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#data-parts-persistent)

Regular data parts are added to the message history and appear in `message.parts`:

```code-block_code__yIKW2

writer.write({

  type: 'data-weather',

  id: 'weather-1', // Optional: enables reconciliation

  data: { city: 'San Francisco', status: 'loading' },

});
```

### [Sources](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#sources)

Sources are useful for RAG implementations where you want to show which documents or URLs were referenced:

```code-block_code__yIKW2

writer.write({

  type: 'source',

  value: {

    type: 'source',

    sourceType: 'url',

    id: 'source-1',

    url: 'https://example.com',

    title: 'Example Source',

  },

});
```

### [Transient Data Parts (Ephemeral)](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#transient-data-parts-ephemeral)

Transient parts are sent to the client but not added to the message history. They are only accessible via the `onData` useChat handler:

```code-block_code__yIKW2

// server

writer.write({

  type: 'data-notification',

  data: { message: 'Processing...', level: 'info' },

  transient: true, // Won't be added to message history

});

// client

const [notification, setNotification] = useState();

const { messages } = useChat({

  onData: ({ data, type }) => {

    if (type === 'data-notification') {

      setNotification({ message: data.message, level: data.level });

    }

  },

});
```

## [Data Part Reconciliation](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#data-part-reconciliation)

When you write to a data part with the same ID, the client automatically reconciles and updates that part. This enables powerful dynamic experiences like:

- **Collaborative artifacts** \- Update code, documents, or designs in real-time
- **Progressive data loading** \- Show loading states that transform into final results
- **Live status updates** \- Update progress bars, counters, or status indicators
- **Interactive components** \- Build UI elements that evolve based on user interaction

The reconciliation happens automatically - simply use the same `id` when writing to the stream.

## [Processing Data on the Client](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#processing-data-on-the-client)

### [Using the onData Callback](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#using-the-ondata-callback)

The `onData` callback is essential for handling streaming data, especially transient parts:

page.tsx

```code-block_code__yIKW2

import { useChat } from '@ai-sdk/react';

import { MyUIMessage } from '@/ai/types';

const { messages } = useChat<MyUIMessage>({

  api: '/api/chat',

  onData: dataPart => {

    // Handle all data parts as they arrive (including transient parts)

    console.log('Received data part:', dataPart);

    // Handle different data part types

    if (dataPart.type === 'data-weather') {

      console.log('Weather update:', dataPart.data);

    }

    // Handle transient notifications (ONLY available here, not in message.parts)

    if (dataPart.type === 'data-notification') {

      showToast(dataPart.data.message, dataPart.data.level);

    }

  },

});
```

**Important:** Transient data parts are **only** available through the `onData` callback. They will not appear in the `message.parts` array since they're not added to message history.

### [Rendering Persistent Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#rendering-persistent-data-parts)

You can filter and render data parts from the message parts array:

page.tsx

```code-block_code__yIKW2

const result = (

  <>

    {messages?.map(message => (

      <div key={message.id}>

        {/* Render weather data parts */}

        {message.parts

          .filter(part => part.type === 'data-weather')

          .map((part, index) => (

            <div key={index} className="weather-widget">

              {part.data.status === 'loading' ? (

                <>Getting weather for {part.data.city}...</>

              ) : (

                <>

                  Weather in {part.data.city}: {part.data.weather}

                </>

              )}

            </div>

          ))}

        {/* Render text content */}

        {message.parts

          .filter(part => part.type === 'text')

          .map((part, index) => (

            <div key={index}>{part.text}</div>

          ))}

        {/* Render sources */}

        {message.parts

          .filter(part => part.type === 'source')

          .map((part, index) => (

            <div key={index} className="source">

              Source: <a href={part.url}>{part.title}</a>

            </div>

          ))}

      </div>

    ))}

  </>

);
```

### [Complete Example](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#complete-example)

page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

import { MyUIMessage } from '@/ai/types';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat<MyUIMessage>({

    api: '/api/chat',

    onData: dataPart => {

      // Handle transient notifications

      if (dataPart.type === 'data-notification') {

        console.log('Notification:', dataPart.data.message);

      }

    },

  });

  const handleSubmit = (e: React.FormEvent) => {

    e.preventDefault();

    sendMessage({ text: input });

    setInput('');

  };

  return (

    <>

      {messages?.map(message => (

        <div key={message.id}>

          {message.role === 'user' ? 'User: ' : 'AI: '}

          {/* Render weather data */}

          {message.parts

            .filter(part => part.type === 'data-weather')

            .map((part, index) => (

              <span key={index} className="weather-update">

                {part.data.status === 'loading' ? (

                  <>Getting weather for {part.data.city}...</>

                ) : (

                  <>

                    Weather in {part.data.city}: {part.data.weather}

                  </>

                )}

              </span>

            ))}

          {/* Render text content */}

          {message.parts

            .filter(part => part.type === 'text')

            .map((part, index) => (

              <div key={index}>{part.text}</div>

            ))}

        </div>

      ))}

      <form onSubmit={handleSubmit}>

        <input

          value={input}

          onChange={e => setInput(e.target.value)}

          placeholder="Ask about the weather..."

        />

        <button type="submit">Send</button>

      </form>

    </>

  );

}
```

## [Use Cases](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#use-cases)

- **RAG Applications** \- Stream sources and retrieved documents
- **Real-time Status** \- Show loading states and progress updates
- **Collaborative Tools** \- Stream live updates to shared artifacts
- **Analytics** \- Send usage data without cluttering message history
- **Notifications** \- Display temporary alerts and status messages

## [Message Metadata vs Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#message-metadata-vs-data-parts)

Both [message metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata) and data parts allow you to send additional information alongside messages, but they serve different purposes:

### [Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#message-metadata)

Message metadata is best for **message-level information** that describes the message as a whole:

- Attached at the message level via `message.metadata`
- Sent using the `messageMetadata` callback in `toUIMessageStreamResponse`
- Ideal for: timestamps, model info, token usage, user context
- Type-safe with custom metadata types

```code-block_code__yIKW2

// Server: Send metadata about the message

return result.toUIMessageStreamResponse({

  messageMetadata: ({ part }) => {

    if (part.type === 'finish') {

      return {

        model: part.response.modelId,

        totalTokens: part.totalUsage.totalTokens,

        createdAt: Date.now(),

      };

    }

  },

});
```

### [Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data\#data-parts)

Data parts are best for streaming **dynamic arbitrary data**:

- Added to the message parts array via `message.parts`
- Streamed using `createUIMessageStream` and `writer.write()`
- Can be reconciled/updated using the same ID
- Support transient parts that don't persist
- Ideal for: dynamic content, loading states, interactive components

```code-block_code__yIKW2

// Server: Stream data as part of message content

writer.write({

  type: 'data-weather',

  id: 'weather-1',

  data: { city: 'San Francisco', status: 'loading' },

});
```

For more details on message metadata, see the [Message Metadata documentation](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata).

On this page

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#streaming-custom-data)

[Setting Up Type-Safe Data Streaming](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#setting-up-type-safe-data-streaming)

[Streaming Data from the Server](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#streaming-data-from-the-server)

[Types of Streamable Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#types-of-streamable-data)

[Data Parts (Persistent)](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#data-parts-persistent)

[Sources](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#sources)

[Transient Data Parts (Ephemeral)](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#transient-data-parts-ephemeral)

[Data Part Reconciliation](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#data-part-reconciliation)

[Processing Data on the Client](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#processing-data-on-the-client)

[Using the onData Callback](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#using-the-ondata-callback)

[Rendering Persistent Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#rendering-persistent-data-parts)

[Complete Example](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#complete-example)

[Use Cases](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#use-cases)

[Message Metadata vs Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#message-metadata-vs-data-parts)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#message-metadata)

[Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#data-parts)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Code Llama AI Model
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fmeta.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)Metacodellama-34b-instruct
Pro

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fmeta.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Meta/codellama-34b-instruct

Code Llama is a 34 billion parameter open source model by Meta fine-tuned for instruction following purposes served by Perplexity.

Context

16,384 tokens

Input Pricing

$0.35 / million tokens

Output Pricing

$1.40 / million tokens

[Model Page](https://blog.perplexity.ai/blog/introducing-pplx-online-llms?utm_source=labs&utm_medium=labs&utm_campaign=online-llms) [Pricing](https://docs.perplexity.ai/docs/pricing)

[Terms](https://www.perplexity.ai/terms) [Privacy](https://www.perplexity.ai/privacy) [Website](https://perplexity.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Mixedbread AI Provider
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [Mixedbread Provider](https://ai-sdk.dev/providers/community-providers/mixedbread\#mixedbread-provider)

This community provider is not yet compatible with AI SDK 5. It uses the
deprecated `.embedding()` method instead of the standard
`.textEmbeddingModel()` method. Please wait for the provider to be updated or
consider using an [AI SDK 5 compatible provider](https://ai-sdk.dev/providers/ai-sdk-providers).

[patelvivekdev/mixedbread-ai-provider](https://github.com/patelvivekdev/mixedbread-ai-provider) is a community provider that uses [Mixedbread](https://www.mixedbread.ai/) to provide Embedding support for the AI SDK.

## [Setup](https://ai-sdk.dev/providers/community-providers/mixedbread\#setup)

The Mixedbread provider is available in the `mixedbread-ai-provider` module. You can install it with

pnpm

npm

yarn

bun

```
pnpm add mixedbread-ai-provider
```

## [Provider Instance](https://ai-sdk.dev/providers/community-providers/mixedbread\#provider-instance)

You can import the default provider instance `mixedbread ` from `mixedbread-ai-provider`:

```code-block_code__yIKW2

import { mixedbread } from 'mixedbread-ai-provider';
```

If you need a customized setup, you can import `createMixedbread` from `mixedbread-ai-provider` and create a provider instance with your settings:

```code-block_code__yIKW2

import { createMixedbread } from 'mixedbread-ai-provider';

const mixedbread = createMixedbread({

  baseURL: 'https://api.mixedbread.ai/v1',

  apiKey: process.env.MIXEDBREAD_API_KEY,

});
```

You can use the following optional settings to customize the Mixedbread provider instance:

- **baseURL** _string_

The base URL of the Mixedbread API

- **headers** _Record<string,string>_

Custom headers to include in the requests.


## [Embedding Models](https://ai-sdk.dev/providers/community-providers/mixedbread\#embedding-models)

You can create models that call the [Mixedbread embeddings API](https://www.mixedbread.ai/api-reference/endpoints/embeddings)
using the `.embedding()` factory method.

```code-block_code__yIKW2

import { mixedbread } from 'mixedbread-ai-provider';

const embeddingModel = mixedbread.embedding(

  'mixedbread-ai/mxbai-embed-large-v1',

);
```

### [Model Capabilities](https://ai-sdk.dev/providers/community-providers/mixedbread\#model-capabilities)

| Model | Default Dimensions | Context Length | Custom Dimensions |
| --- | --- | --- | --- |
| `mxbai-embed-large-v1` | 1024 | 512 |  |
| `deepset-mxbai-embed-de-large-v1` | 1024 | 512 |  |

The table above lists popular models. Please see the [Mixedbread\\
docs](https://www.mixedbread.ai/docs/embeddings/models) for a full list of
available models.

### [Add settings to the model](https://ai-sdk.dev/providers/community-providers/mixedbread\#add-settings-to-the-model)

The settings object should contain the settings you want to add to the model.

```code-block_code__yIKW2

import { mixedbread } from 'mixedbread-ai-provider';

const embeddingModel = mixedbread.embedding(

  'mixedbread-ai/mxbai-embed-large-v1',

  {

    prompt: 'Generate embeddings for text', // Max 256 characters

    dimensions: 512, // Max 1024 for embed-large-v1

  },

);
```

On this page

[Mixedbread Provider](https://ai-sdk.dev/providers/community-providers/mixedbread#mixedbread-provider)

[Setup](https://ai-sdk.dev/providers/community-providers/mixedbread#setup)

[Provider Instance](https://ai-sdk.dev/providers/community-providers/mixedbread#provider-instance)

[Embedding Models](https://ai-sdk.dev/providers/community-providers/mixedbread#embedding-models)

[Model Capabilities](https://ai-sdk.dev/providers/community-providers/mixedbread#model-capabilities)

[Add settings to the model](https://ai-sdk.dev/providers/community-providers/mixedbread#add-settings-to-the-model)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Error Handling Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling\#error-handling)

### [Error Helper Object](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling\#error-helper-object)

Each AI SDK UI hook also returns an [error](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#error) object that you can use to render the error in your UI.
You can use the error object to show an error message, disable the submit button, or show a retry button.

We recommend showing a generic error message to the user, such as "Something
went wrong." This is a good practice to avoid leaking information from the
server.

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage, error, regenerate } = useChat();

  const handleSubmit = (e: React.FormEvent) => {

    e.preventDefault();

    sendMessage({ text: input });

    setInput('');

  };

  return (

    <div>

      {messages.map(m => (

        <div key={m.id}>

          {m.role}:{' '}

          {m.parts

            .filter(part => part.type === 'text')

            .map(part => part.text)

            .join('')}

        </div>

      ))}

      {error && (

        <>

          <div>An error occurred.</div>

          <button type="button" onClick={() => regenerate()}>

            Retry

          </button>

        </>

      )}

      <form onSubmit={handleSubmit}>

        <input

          value={input}

          onChange={e => setInput(e.target.value)}

          disabled={error != null}

        />

      </form>

    </div>

  );

}
```

#### [Alternative: replace last message](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling\#alternative-replace-last-message)

Alternatively you can write a custom submit handler that replaces the last message when an error is present.

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { sendMessage, error, messages, setMessages } = useChat();

  function customSubmit(event: React.FormEvent<HTMLFormElement>) {

    event.preventDefault();

    if (error != null) {

      setMessages(messages.slice(0, -1)); // remove last message

    }

    sendMessage({ text: input });

    setInput('');

  }

  return (

    <div>

      {messages.map(m => (

        <div key={m.id}>

          {m.role}:{' '}

          {m.parts

            .filter(part => part.type === 'text')

            .map(part => part.text)

            .join('')}

        </div>

      ))}

      {error && <div>An error occurred.</div>}

      <form onSubmit={customSubmit}>

        <input value={input} onChange={e => setInput(e.target.value)} />

      </form>

    </div>

  );

}
```

### [Error Handling Callback](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling\#error-handling-callback)

Errors can be processed by passing an [`onError`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#on-error) callback function as an option to the [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat) or [`useCompletion`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-completion) hooks.
The callback function receives an error object as an argument.

```code-block_code__yIKW2

import { useChat } from '@ai-sdk/react';

export default function Page() {

  const {

    /* ... */

  } = useChat({

    // handle error:

    onError: error => {

      console.error(error);

    },

  });

}
```

### [Injecting Errors for Testing](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling\#injecting-errors-for-testing)

You might want to create errors for testing.
You can easily do so by throwing an error in your route handler:

```code-block_code__yIKW2

export async function POST(req: Request) {

  throw new Error('This is a test error');

}
```

On this page

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling#error-handling)

[Error Helper Object](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling#error-helper-object)

[Alternative: replace last message](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling#alternative-replace-last-message)

[Error Handling Callback](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling#error-handling-callback)

[Injecting Errors for Testing](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling#injecting-errors-for-testing)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Nest.js AI SDK Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest\#nestjs)

You can use the AI SDK in a [Nest.js](https://nestjs.com/) server to generate and stream text and objects to the client.

## [Examples](https://ai-sdk.dev/cookbook/api-servers/nest\#examples)

The examples show how to implement a Nest.js controller that uses the AI SDK to stream text and objects to the client.

**Full example**: [github.com/vercel/ai/examples/nest](https://github.com/vercel/ai/tree/main/examples/nest)

### [Data Stream](https://ai-sdk.dev/cookbook/api-servers/nest\#data-stream)

You can use the `pipeDataStreamToResponse` method to get a data stream from the result and then pipe it to the response.

app.controller.ts

```code-block_code__yIKW2

import { Controller, Post, Res } from '@nestjs/common';

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

import { Response } from 'express';

@Controller()

export class AppController {

  @Post()

  async example(@Res() res: Response) {

    const result = streamText({

      model: openai('gpt-4o'),

      prompt: 'Invent a new holiday and describe its traditions.',

    });

    result.pipeDataStreamToResponse(res);

  }

}
```

### [Sending Custom Data](https://ai-sdk.dev/cookbook/api-servers/nest\#sending-custom-data)

`pipeDataStreamToResponse` can be used to send custom data to the client.

app.controller.ts

```code-block_code__yIKW2

import { Controller, Post, Res } from '@nestjs/common';

import { openai } from '@ai-sdk/openai';

import { pipeDataStreamToResponse, streamText } from 'ai';

import { Response } from 'express';

@Controller()

export class AppController {

  @Post('/stream-data')

  async streamData(@Res() res: Response) {

    pipeDataStreamToResponse(res, {

      execute: async dataStreamWriter => {

        dataStreamWriter.writeData('initialized call');

        const result = streamText({

          model: openai('gpt-4o'),

          prompt: 'Invent a new holiday and describe its traditions.',

        });

        result.mergeIntoDataStream(dataStreamWriter);

      },

      onError: error => {

        // Error messages are masked by default for security reasons.

        // If you want to expose the error message to the client, you can do so here:

        return error instanceof Error ? error.message : String(error);

      },

    });

  }

}
```

### [Text Stream](https://ai-sdk.dev/cookbook/api-servers/nest\#text-stream)

You can use the `pipeTextStreamToResponse` method to get a text stream from the result and then pipe it to the response.

app.controller.ts

```code-block_code__yIKW2

import { Controller, Post, Res } from '@nestjs/common';

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

import { Response } from 'express';

@Controller()

export class AppController {

  @Post()

  async example(@Res() res: Response) {

    const result = streamText({

      model: openai('gpt-4o'),

      prompt: 'Invent a new holiday and describe its traditions.',

    });

    result.pipeTextStreamToResponse(res);

  }

}
```

## [Troubleshooting](https://ai-sdk.dev/cookbook/api-servers/nest\#troubleshooting)

- Streaming not working when [proxied](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-proxied)

On this page

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest#nestjs)

[Examples](https://ai-sdk.dev/cookbook/api-servers/nest#examples)

[Data Stream](https://ai-sdk.dev/cookbook/api-servers/nest#data-stream)

[Sending Custom Data](https://ai-sdk.dev/cookbook/api-servers/nest#sending-custom-data)

[Text Stream](https://ai-sdk.dev/cookbook/api-servers/nest#text-stream)

[Troubleshooting](https://ai-sdk.dev/cookbook/api-servers/nest#troubleshooting)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Tool Component
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Copy markdown

# [Tool](https://ai-sdk.dev/elements/components/tool\#tool)

The `Tool` component displays a collapsible interface for showing/hiding tool details. It is designed to take the `ToolUIPart` type from the AI SDK and display it in a collapsible interface.

tool-database\_queryCompleted

## [Installation](https://ai-sdk.dev/elements/components/tool\#installation)

ai-elementsshadcnManual

```
npx ai-elements@latest add tool
```

## [Usage](https://ai-sdk.dev/elements/components/tool\#usage)

```code-block_code__yIKW2

import {

  Tool,

  ToolContent,

  ToolHeader,

  ToolOutput,

  ToolInput,

} from '@/components/ai-elements/tool';
```

```code-block_code__yIKW2

<Tool>

  <ToolHeader type="tool-call" state={'output-available' as const} />

  <ToolContent>

    <ToolInput input="Input to tool call" />

    <ToolOutput errorText="Error" output="Output from tool call" />

  </ToolContent>

</Tool>
```

## [Usage in AI SDK](https://ai-sdk.dev/elements/components/tool\#usage-in-ai-sdk)

Build a simple stateful weather app that renders the last message in a tool using [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat).

Add the following component to your frontend:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { DefaultChatTransport, type ToolUIPart } from 'ai';

import { Button } from '@/components/ui/button';

import { Response } from '@/components/ai-elements/response';

import {

  Tool,

  ToolContent,

  ToolHeader,

  ToolInput,

  ToolOutput,

} from '@/components/ai-elements/tool';

type WeatherToolInput = {

  location: string;

  units: 'celsius' | 'fahrenheit';

};

type WeatherToolOutput = {

  location: string;

  temperature: string;

  conditions: string;

  humidity: string;

  windSpeed: string;

  lastUpdated: string;

};

type WeatherToolUIPart = ToolUIPart<{

  fetch_weather_data: {

    input: WeatherToolInput;

    output: WeatherToolOutput;

  };

}>;

const Example = () => {

  const { messages, sendMessage, status } = useChat({

    transport: new DefaultChatTransport({

      api: '/api/weather',

    }),

  });

  const handleWeatherClick = () => {

    sendMessage({ text: 'Get weather data for San Francisco in fahrenheit' });

  };

  const latestMessage = messages[messages.length - 1];

  const weatherTool = latestMessage?.parts?.find(

    (part) => part.type === 'tool-fetch_weather_data',

  ) as WeatherToolUIPart | undefined;

  return (

    <div className="max-w-4xl mx-auto p-6 relative size-full rounded-lg border h-[600px]">

      <div className="flex flex-col h-full">

        <div className="space-y-4">

          <Button onClick={handleWeatherClick} disabled={status !== 'ready'}>

            Get Weather for San Francisco

          </Button>

          {weatherTool && (

            <Tool defaultOpen={true}>

              <ToolHeader type="fetch_weather_data" state={weatherTool.state} />

              <ToolContent>

                <ToolInput input={weatherTool.input} />

                <ToolOutput

                  output={

                    <Response>

                      {formatWeatherResult(weatherTool.output)}

                    </Response>

                  }

                  errorText={weatherTool.errorText}

                />

              </ToolContent>

            </Tool>

          )}

        </div>

      </div>

    </div>

  );

};

function formatWeatherResult(result: WeatherToolOutput): string {

  return `**Weather for ${result.location}**

**Temperature:** ${result.temperature}

**Conditions:** ${result.conditions}

**Humidity:** ${result.humidity}

**Wind Speed:** ${result.windSpeed}

*Last updated: ${result.lastUpdated}*`;

}

export default Example;
```

Add the following route to your backend:

app/api/weather/route.tsx

```code-block_code__yIKW2

import { streamText, UIMessage, convertToModelMessages } from 'ai';

import { z } from 'zod';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: 'openai/gpt-4o',

    messages: convertToModelMessages(messages),

    tools: {

      fetch_weather_data: {

        description: 'Fetch weather information for a specific location',

        parameters: z.object({

          location: z

            .string()

            .describe('The city or location to get weather for'),

          units: z

            .enum(['celsius', 'fahrenheit'])

            .default('celsius')

            .describe('Temperature units'),

        }),

        inputSchema: z.object({

          location: z.string(),

          units: z.enum(['celsius', 'fahrenheit']).default('celsius'),

        }),

        execute: async ({ location, units }) => {

          await new Promise((resolve) => setTimeout(resolve, 1500));

          const temp =

            units === 'celsius'

              ? Math.floor(Math.random() * 35) + 5

              : Math.floor(Math.random() * 63) + 41;

          return {

            location,

            temperature: `${temp}¬∞${units === 'celsius' ? 'C' : 'F'}`,

            conditions: 'Sunny',

            humidity: `12%`,

            windSpeed: `35 ${units === 'celsius' ? 'km/h' : 'mph'}`,

            lastUpdated: new Date().toLocaleString(),

          };

        },

      },

    },

  });

  return result.toUIMessageStreamResponse();

}
```

## [Features](https://ai-sdk.dev/elements/components/tool\#features)

- Collapsible interface for showing/hiding tool details
- Visual status indicators with icons and badges
- Support for multiple tool execution states (pending, running, completed, error)
- Formatted parameter display with JSON syntax highlighting
- Result and error handling with appropriate styling
- Composable structure for flexible layouts
- Accessible keyboard navigation and screen reader support
- Consistent styling that matches your design system
- Auto-opens completed tools by default for better UX

## [Examples](https://ai-sdk.dev/elements/components/tool\#examples)

### [Input Streaming (Pending)](https://ai-sdk.dev/elements/components/tool\#input-streaming-pending)

Shows a tool in its initial state while parameters are being processed.

tool-web\_searchPending

### [Input Available (Running)](https://ai-sdk.dev/elements/components/tool\#input-available-running)

Shows a tool that's actively executing with its parameters.

tool-image\_generationRunning

### [Output Available (Completed)](https://ai-sdk.dev/elements/components/tool\#output-available-completed)

Shows a completed tool with successful results. Opens by default to show the results. In this instance, the output is a JSON object, so we can use the `CodeBlock` component to display it.

tool-database\_queryCompleted

### [Output Error](https://ai-sdk.dev/elements/components/tool\#output-error)

Shows a tool that encountered an error during execution. Opens by default to display the error.

tool-api\_requestError

## [Props](https://ai-sdk.dev/elements/components/tool\#props)

### [`<Tool />`](https://ai-sdk.dev/elements/components/tool\#tool-)

### \[...props\]?:

React.ComponentProps<typeof Collapsible>

Any other props are spread to the root Collapsible component.

### [`<ToolHeader />`](https://ai-sdk.dev/elements/components/tool\#toolheader-)

### type:

ToolUIPart\["type"\]

The type/name of the tool.

### state:

ToolUIPart\["state"\]

The current state of the tool (input-streaming, input-available, output-available, or output-error).

### className?:

string

Additional CSS classes to apply to the header.

### \[...props\]?:

React.ComponentProps<typeof CollapsibleTrigger>

Any other props are spread to the CollapsibleTrigger.

### [`<ToolContent />`](https://ai-sdk.dev/elements/components/tool\#toolcontent-)

### \[...props\]?:

React.ComponentProps<typeof CollapsibleContent>

Any other props are spread to the CollapsibleContent.

### [`<ToolInput />`](https://ai-sdk.dev/elements/components/tool\#toolinput-)

### input:

ToolUIPart\["input"\]

The input parameters passed to the tool, displayed as formatted JSON.

### \[...props\]?:

React.ComponentProps<"div">

Any other props are spread to the underlying div.

### [`<ToolOutput />`](https://ai-sdk.dev/elements/components/tool\#tooloutput-)

### output:

React.ReactNode

The output/result of the tool execution.

### errorText:

ToolUIPart\["errorText"\]

An error message if the tool execution failed.

### \[...props\]?:

React.ComponentProps<"div">

Any other props are spread to the underlying div.

On this page

[Tool](https://ai-sdk.dev/elements/components/tool#tool)

[Installation](https://ai-sdk.dev/elements/components/tool#installation)

[Usage](https://ai-sdk.dev/elements/components/tool#usage)

[Usage in AI SDK](https://ai-sdk.dev/elements/components/tool#usage-in-ai-sdk)

[Features](https://ai-sdk.dev/elements/components/tool#features)

[Examples](https://ai-sdk.dev/elements/components/tool#examples)

[Input Streaming (Pending)](https://ai-sdk.dev/elements/components/tool#input-streaming-pending)

[Input Available (Running)](https://ai-sdk.dev/elements/components/tool#input-available-running)

[Output Available (Completed)](https://ai-sdk.dev/elements/components/tool#output-available-completed)

[Output Error](https://ai-sdk.dev/elements/components/tool#output-error)

[Props](https://ai-sdk.dev/elements/components/tool#props)

[<Tool />](https://ai-sdk.dev/elements/components/tool#tool-)

[<ToolHeader />](https://ai-sdk.dev/elements/components/tool#toolheader-)

[<ToolContent />](https://ai-sdk.dev/elements/components/tool#toolcontent-)

[<ToolInput />](https://ai-sdk.dev/elements/components/tool#toolinput-)

[<ToolOutput />](https://ai-sdk.dev/elements/components/tool#tooloutput-)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Groq Llama 3.3 Model
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fgroq.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)GroqLlama 3.3 70B Versatile
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fgroq.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Groq/Llama 3.3 70B Versatile

The Meta Llama 3.3 multilingual model is a pretrained and instruction tuned generative model with 70B parameters. Optimized for multilingual dialogue use cases, it outperforms many of the available open source and closed chat models on common industry benchmarks. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context

128,000 tokens

Input Pricing

$0.59 / million tokens

Output Pricing

$0.79 / million tokens

[Model Page](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md) [Pricing](https://wow.groq.com/)

[Terms](https://console.groq.com/docs/terms-of-sale) [Privacy](https://groq.com/privacy-policy) [Website](https://groq.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Caching Middleware Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware\#caching-middleware)

This example is not yet updated to v5.

Let's create a simple chat interface that uses [`LanguageModelMiddleware`](https://ai-sdk.dev/docs/ai-sdk-core/middleware) to cache the assistant's responses in fast KV storage.

## [Client](https://ai-sdk.dev/cookbook/next/caching-middleware\#client)

Let's create a simple chat interface that allows users to send messages to the assistant and receive responses. You will integrate the `useChat` hook from `@ai-sdk/react` to stream responses.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

export default function Chat() {

  const { messages, input, handleInputChange, handleSubmit, error } = useChat();

  if (error) return <div>{error.message}</div>;

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      <div className="space-y-4">

        {messages.map(m => (

          <div key={m.id} className="whitespace-pre-wrap">

            <div>

              <div className="font-bold">{m.role}</div>

              {m.toolInvocations ? (

                <pre>{JSON.stringify(m.toolInvocations, null, 2)}</pre>

              ) : (

                <p>{m.content}</p>

              )}

            </div>

          </div>

        ))}

      </div>

      <form onSubmit={handleSubmit}>

        <input

          className="fixed bottom-0 w-full max-w-md p-2 mb-8 border border-gray-300 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={handleInputChange}

        />

      </form>

    </div>

  );

}
```

## [Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware\#middleware)

Next, you will create a `LanguageModelMiddleware` that caches the assistant's responses in KV storage.
`LanguageModelMiddleware` has two methods: `wrapGenerate` and `wrapStream`.
`wrapGenerate` is called when using [`generateText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text) and [`generateObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object), while `wrapStream` is called when using [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) and [`streamObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object).

For `wrapGenerate`, you can cache the response directly.
Instead, for `wrapStream`, you cache an array of the stream parts, which can then be used with [`simulateReadableStream`](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream) function to create a simulated `ReadableStream` that returns the cached response.
In this way, the cached response is returned chunk-by-chunk as if it were being generated by the model.
You can control the initial delay and delay between chunks by adjusting the `initialDelayInMs` and `chunkDelayInMs` parameters of `simulateReadableStream`.

ai/middleware.ts

```code-block_code__yIKW2

import { Redis } from '@upstash/redis';

import {

  type LanguageModelV1,

  type LanguageModelV2Middleware,

  type LanguageModelV1StreamPart,

  simulateReadableStream,

} from 'ai';

const redis = new Redis({

  url: process.env.KV_URL,

  token: process.env.KV_TOKEN,

});

export const cacheMiddleware: LanguageModelV2Middleware = {

  wrapGenerate: async ({ doGenerate, params }) => {

    const cacheKey = JSON.stringify(params);

    const cached = (await redis.get(cacheKey)) as Awaited<

      ReturnType<LanguageModelV1['doGenerate']>

    > | null;

    if (cached !== null) {

      return {

        ...cached,

        response: {

          ...cached.response,

          timestamp: cached?.response?.timestamp

            ? new Date(cached?.response?.timestamp)

            : undefined,

        },

      };

    }

    const result = await doGenerate();

    redis.set(cacheKey, result);

    return result;

  },

  wrapStream: async ({ doStream, params }) => {

    const cacheKey = JSON.stringify(params);

    // Check if the result is in the cache

    const cached = await redis.get(cacheKey);

    // If cached, return a simulated ReadableStream that yields the cached result

    if (cached !== null) {

      // Format the timestamps in the cached response

      const formattedChunks = (cached as LanguageModelV1StreamPart[]).map(p => {

        if (p.type === 'response-metadata' && p.timestamp) {

          return { ...p, timestamp: new Date(p.timestamp) };

        } else return p;

      });

      return {

        stream: simulateReadableStream({

          initialDelayInMs: 0,

          chunkDelayInMs: 10,

          chunks: formattedChunks,

        }),

      };

    }

    // If not cached, proceed with streaming

    const { stream, ...rest } = await doStream();

    const fullResponse: LanguageModelV1StreamPart[] = [];

    const transformStream = new TransformStream<

      LanguageModelV1StreamPart,

      LanguageModelV1StreamPart

    >({

      transform(chunk, controller) {

        fullResponse.push(chunk);

        controller.enqueue(chunk);

      },

      flush() {

        // Store the full response in the cache after streaming is complete

        redis.set(cacheKey, fullResponse);

      },

    });

    return {

      stream: stream.pipeThrough(transformStream),

      ...rest,

    };

  },

};
```

This example uses `@upstash/redis` to store and retrieve the assistant's
responses but you can use any KV storage provider you would like.

## [Server](https://ai-sdk.dev/cookbook/next/caching-middleware\#server)

Finally, you will create an API route for `api/chat` to handle the assistant's messages and responses. You can use your cache middleware by wrapping the model with `wrapLanguageModel` and passing the middleware as an argument.

app/api/chat/route.ts

```code-block_code__yIKW2

import { cacheMiddleware } from '@/ai/middleware';

import { openai } from '@ai-sdk/openai';

import { wrapLanguageModel, streamText, tool } from 'ai';

import { z } from 'zod';

const wrappedModel = wrapLanguageModel({

  model: openai('gpt-4o-mini'),

  middleware: cacheMiddleware,

});

export async function POST(req: Request) {

  const { messages } = await req.json();

  const result = streamText({

    model: wrappedModel,

    messages,

    tools: {

      weather: tool({

        description: 'Get the weather in a location',

        inputSchema: z.object({

          location: z.string().describe('The location to get the weather for'),

        }),

        execute: async ({ location }) => ({

          location,

          temperature: 72 + Math.floor(Math.random() * 21) - 10,

        }),

      }),

    },

  });

  return result.toUIMessageStreamResponse();

}
```

On this page

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware#caching-middleware)

[Client](https://ai-sdk.dev/cookbook/next/caching-middleware#client)

[Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware#middleware)

[Server](https://ai-sdk.dev/cookbook/next/caching-middleware#server)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Models Playground
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

MoonshotAI
BasetenKimi K2
Hobby

Synced

Drop Image

MoonshotAI

Moonshot AI/Kimi K2

State of the art language model for agentic and coding tasks

Context

131,072 tokens

Input Pricing

$0.60 / million tokens

Output Pricing

$2.50 / million tokens

[Model Page](https://www.baseten.co/library/kimi-v2/) [Pricing](https://www.baseten.co/pricing/)

[Terms](https://www.baseten.co/terms-and-conditions/) [Privacy](https://www.baseten.co/privacy-policy/) [Website](https://www.baseten.co/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## No Audio Generated Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error\#ai_noaudiogeneratederror)

This error occurs when no audio could be generated from the input.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error\#properties)

- `responses`: Array of responses
- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error\#checking-for-this-error)

You can check if an error is an instance of `AI_NoAudioGeneratedError` using:

```code-block_code__yIKW2

import { NoAudioGeneratedError } from 'ai';

if (NoAudioGeneratedError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error#ai_noaudiogeneratederror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Manage UI State
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[streamUI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/stream-ui)

[createAI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-ai)

[createStreamableUI](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-streamable-ui)

[createStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-streamable-value)

[readStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/read-streamable-value)

[getAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-ai-state)

[getMutableAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/get-mutable-ai-state)

[useAIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ai-state)

[useActions](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-actions)

[useUIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state)

[useStreamableValue](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-streamable-value)

[render (Removed)](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/render)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`useUIState`](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state\#useuistate)

AI SDK RSC is currently experimental. We recommend using [AI SDK\\
UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview) for production. For guidance on migrating from
RSC to UI, see our [migration guide](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui).

It is a hook that enables you to read and update the UI State. The state is client-side and can contain functions, React nodes, and other data. UIState is the visual representation of the AI state.

## [Import](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state\#import)

```
import { useUIState } from "@ai-sdk/rsc"
```

## [API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state\#api-signature)

### [Returns](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state\#returns)

Similar to useState, it is an array, where the first element is the current UI state and the second element is the function that updates the state.

## [Examples](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state\#examples)

[Learn to manage AI and UI states in Next.js](https://ai-sdk.dev/examples/next-app/state-management/ai-ui-states)

On this page

[useUIState](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state#useuistate)

[Import](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state#import)

[API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state#api-signature)

[Returns](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state#returns)

[Examples](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/use-ui-state#examples)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## GPT-4.5 Guide
# 500

## Internal Server Error.

## Stream Protocols Overview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#stream-protocols)

AI SDK UI functions such as `useChat` and `useCompletion` support both text streams and data streams.
The stream protocol defines how the data is streamed to the frontend on top of the HTTP protocol.

This page describes both protocols and how to use them in the backend and frontend.

You can use this information to develop custom backends and frontends for your use case, e.g.,
to provide compatible API endpoints that are implemented in a different language such as Python.

For instance, here's an example using [FastAPI](https://github.com/vercel/ai/tree/main/examples/next-fastapi) as a backend.

## [Text Stream Protocol](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-stream-protocol)

A text stream contains chunks in plain text, that are streamed to the frontend.
Each chunk is then appended together to form a full text response.

Text streams are supported by `useChat`, `useCompletion`, and `useObject`.
When you use `useChat` or `useCompletion`, you need to enable text streaming
by setting the `streamProtocol` options to `text`.

You can generate text streams with `streamText` in the backend.
When you call `toTextStreamResponse()` on the result object,
a streaming HTTP response is returned.

Text streams only support basic text data. If you need to stream other types
of data such as tool calls, use data streams.

### [Text Stream Example](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-stream-example)

Here is a Next.js example that uses the text stream protocol:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { TextStreamChatTransport } from 'ai';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat({

    transport: new TextStreamChatTransport({ api: '/api/chat' }),

  });

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      {messages.map(message => (

        <div key={message.id} className="whitespace-pre-wrap">

          {message.role === 'user' ? 'User: ' : 'AI: '}

          {message.parts.map((part, i) => {

            switch (part.type) {

              case 'text':

                return <div key={`${message.id}-${i}`}>{part.text}</div>;

            }

          })}

        </div>

      ))}

      <form

        onSubmit={e => {

          e.preventDefault();

          sendMessage({ text: input });

          setInput('');

        }}

      >

        <input

          className="fixed dark:bg-zinc-900 bottom-0 w-full max-w-md p-2 mb-8 border border-zinc-300 dark:border-zinc-800 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={e => setInput(e.currentTarget.value)}

        />

      </form>

    </div>

  );

}
```

app/api/chat/route.ts

```code-block_code__yIKW2

import { streamText, UIMessage, convertToModelMessages } from 'ai';

import { openai } from '@ai-sdk/openai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

  });

  return result.toTextStreamResponse();

}
```

## [Data Stream Protocol](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#data-stream-protocol)

A data stream follows a special protocol that the AI SDK provides to send information to the frontend.

The data stream protocol uses Server-Sent Events (SSE) format for improved standardization, keep-alive through ping, reconnect capabilities, and better cache handling.

When you provide data streams from a custom backend, you need to set the
`x-vercel-ai-ui-message-stream` header to `v1`.

The following stream parts are currently supported:

### [Message Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#message-start-part)

Indicates the beginning of a new message with metadata.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"start","messageId":"..."}
```

### [Text Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-parts)

Text content is streamed using a start/delta/end pattern with unique IDs for each text block.

#### [Text Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-start-part)

Indicates the beginning of a text block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"text-start","id":"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d"}
```

#### [Text Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-delta-part)

Contains incremental text content for the text block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"text-delta","id":"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d","delta":"Hello"}
```

#### [Text End Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#text-end-part)

Indicates the completion of a text block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"text-end","id":"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d"}
```

### [Reasoning Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#reasoning-parts)

Reasoning content is streamed using a start/delta/end pattern with unique IDs for each reasoning block.

#### [Reasoning Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#reasoning-start-part)

Indicates the beginning of a reasoning block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"reasoning-start","id":"reasoning_123"}
```

#### [Reasoning Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#reasoning-delta-part)

Contains incremental reasoning content for the reasoning block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"reasoning-delta","id":"reasoning_123","delta":"This is some reasoning"}
```

#### [Reasoning End Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#reasoning-end-part)

Indicates the completion of a reasoning block.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"reasoning-end","id":"reasoning_123"}
```

### [Source Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#source-parts)

Source parts provide references to external content sources.

#### [Source URL Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#source-url-part)

References to external URLs.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"source-url","sourceId":"https://example.com","url":"https://example.com"}
```

#### [Source Document Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#source-document-part)

References to documents or files.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"source-document","sourceId":"https://example.com","mediaType":"file","title":"Title"}
```

### [File Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#file-part)

The file parts contain references to files with their media type.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"file","url":"https://example.com/file.png","mediaType":"image/png"}
```

### [Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#data-parts)

Custom data parts allow streaming of arbitrary structured data with type-specific handling.

Format: Server-Sent Event with JSON object where the type includes a custom suffix

Example:

```code-block_code__yIKW2

data: {"type":"data-weather","data":{"location":"SF","temperature":100}}
```

The `data-*` type pattern allows you to define custom data types that your frontend can handle specifically.

### [Error Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#error-part)

The error parts are appended to the message as they are received.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"error","errorText":"error message"}
```

### [Tool Input Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#tool-input-start-part)

Indicates the beginning of tool input streaming.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"tool-input-start","toolCallId":"call_fJdQDqnXeGxTmr4E3YPSR7Ar","toolName":"getWeatherInformation"}
```

### [Tool Input Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#tool-input-delta-part)

Incremental chunks of tool input as it's being generated.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"tool-input-delta","toolCallId":"call_fJdQDqnXeGxTmr4E3YPSR7Ar","inputTextDelta":"San Francisco"}
```

### [Tool Input Available Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#tool-input-available-part)

Indicates that tool input is complete and ready for execution.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"tool-input-available","toolCallId":"call_fJdQDqnXeGxTmr4E3YPSR7Ar","toolName":"getWeatherInformation","input":{"city":"San Francisco"}}
```

### [Tool Output Available Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#tool-output-available-part)

Contains the result of tool execution.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"tool-output-available","toolCallId":"call_fJdQDqnXeGxTmr4E3YPSR7Ar","output":{"city":"San Francisco","weather":"sunny"}}
```

### [Start Step Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#start-step-part)

A part indicating the start of a step.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"start-step"}
```

### [Finish Step Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#finish-step-part)

A part indicating that a step (i.e., one LLM API call in the backend) has been completed.

This part is necessary to correctly process multiple stitched assistant calls, e.g. when calling tools in the backend, and using steps in `useChat` at the same time.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"finish-step"}
```

### [Finish Message Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#finish-message-part)

A part indicating the completion of a message.

Format: Server-Sent Event with JSON object

Example:

```code-block_code__yIKW2

data: {"type":"finish"}
```

### [Stream Termination](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#stream-termination)

The stream ends with a special `[DONE]` marker.

Format: Server-Sent Event with literal `[DONE]`

Example:

```code-block_code__yIKW2

data: [DONE]
```

The data stream protocol is supported
by `useChat` and `useCompletion` on the frontend and used by default.
`useCompletion` only supports the `text` and `data` stream parts.

On the backend, you can use `toUIMessageStreamResponse()` from the `streamText` result object to return a streaming HTTP response.

### [UI Message Stream Example](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol\#ui-message-stream-example)

Here is a Next.js example that uses the UI message stream protocol:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { useState } from 'react';

export default function Chat() {

  const [input, setInput] = useState('');

  const { messages, sendMessage } = useChat();

  return (

    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">

      {messages.map(message => (

        <div key={message.id} className="whitespace-pre-wrap">

          {message.role === 'user' ? 'User: ' : 'AI: '}

          {message.parts.map((part, i) => {

            switch (part.type) {

              case 'text':

                return <div key={`${message.id}-${i}`}>{part.text}</div>;

            }

          })}

        </div>

      ))}

      <form

        onSubmit={e => {

          e.preventDefault();

          sendMessage({ text: input });

          setInput('');

        }}

      >

        <input

          className="fixed dark:bg-zinc-900 bottom-0 w-full max-w-md p-2 mb-8 border border-zinc-300 dark:border-zinc-800 rounded shadow-xl"

          value={input}

          placeholder="Say something..."

          onChange={e => setInput(e.currentTarget.value)}

        />

      </form>

    </div>

  );

}
```

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText, UIMessage, convertToModelMessages } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse();

}
```

On this page

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#stream-protocols)

[Text Stream Protocol](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-stream-protocol)

[Text Stream Example](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-stream-example)

[Data Stream Protocol](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#data-stream-protocol)

[Message Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#message-start-part)

[Text Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-parts)

[Text Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-start-part)

[Text Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-delta-part)

[Text End Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#text-end-part)

[Reasoning Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#reasoning-parts)

[Reasoning Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#reasoning-start-part)

[Reasoning Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#reasoning-delta-part)

[Reasoning End Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#reasoning-end-part)

[Source Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#source-parts)

[Source URL Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#source-url-part)

[Source Document Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#source-document-part)

[File Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#file-part)

[Data Parts](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#data-parts)

[Error Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#error-part)

[Tool Input Start Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#tool-input-start-part)

[Tool Input Delta Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#tool-input-delta-part)

[Tool Input Available Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#tool-input-available-part)

[Tool Output Available Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#tool-output-available-part)

[Start Step Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#start-step-part)

[Finish Step Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#finish-step-part)

[Finish Message Part](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#finish-message-part)

[Stream Termination](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#stream-termination)

[UI Message Stream Example](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol#ui-message-stream-example)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Mistral Large Overview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

MistralMistral Large
Pro

Synced

Drop Image

Mistral/Mistral Large

Mistral Large is ideal for complex tasks that require large reasoning capabilities or are highly specialized - like Synthetic Text Generation, Code Generation, RAG, or Agents.

Context

32,000 tokens

Input Pricing

$2.00 / million tokens

Output Pricing

$6.00 / million tokens

[Model Page](https://mistral.ai/news/mistral-large/) [Pricing](https://docs.mistral.ai/platform/pricing/)

[Terms](https://mistral.ai/terms) [Privacy](https://mistral.ai/terms#privacy-policy) [Website](https://mistral.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Google Gemini 1.5
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

GoogleGemini 1.5 Flash 002

Synced

Drop Image

Google/Gemini 1.5 Flash 002

Gemini 1.5 Flash is the latest model of the Gemini family. It's a multimodal model that supports up to 1 million tokens. It is optimized for speed and efficiency.

Context

1,000,000 tokens

Input Pricing

$0.08 / million tokens

Output Pricing

$0.30 / million tokens

[Model Page](https://deepmind.google/technologies/gemini/flash/) [Pricing](https://ai.google.dev/pricing)

[Terms](https://policies.google.com/terms/generative-ai) [Privacy](https://policies.google.com/privacy) [Website](https://deepmind.google/technologies/gemini/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Smooth Text Streaming
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[generateText](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text)

[streamText](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text)

[generateObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object)

[streamObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object)

[embed](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed)

[embedMany](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed-many)

[generateImage](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image)

[transcribe](https://ai-sdk.dev/docs/reference/ai-sdk-core/transcribe)

[generateSpeech](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-speech)

[tool](https://ai-sdk.dev/docs/reference/ai-sdk-core/tool)

[dynamicTool](https://ai-sdk.dev/docs/reference/ai-sdk-core/dynamic-tool)

[experimental\_createMCPClient](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-mcp-client)

[Experimental\_StdioMCPTransport](https://ai-sdk.dev/docs/reference/ai-sdk-core/mcp-stdio-transport)

[jsonSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/json-schema)

[zodSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/zod-schema)

[valibotSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/valibot-schema)

[ModelMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/model-message)

[UIMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/ui-message)

[createProviderRegistry](https://ai-sdk.dev/docs/reference/ai-sdk-core/provider-registry)

[customProvider](https://ai-sdk.dev/docs/reference/ai-sdk-core/custom-provider)

[cosineSimilarity](https://ai-sdk.dev/docs/reference/ai-sdk-core/cosine-similarity)

[wrapLanguageModel](https://ai-sdk.dev/docs/reference/ai-sdk-core/wrap-language-model)

[LanguageModelV2Middleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/language-model-v2-middleware)

[extractReasoningMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/extract-reasoning-middleware)

[simulateStreamingMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-streaming-middleware)

[defaultSettingsMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/default-settings-middleware)

[stepCountIs](https://ai-sdk.dev/docs/reference/ai-sdk-core/step-count-is)

[hasToolCall](https://ai-sdk.dev/docs/reference/ai-sdk-core/has-tool-call)

[simulateReadableStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream)

[smoothStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream)

[generateId](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-id)

[createIdGenerator](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-id-generator)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`smoothStream()`](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#smoothstream)

`smoothStream` is a utility function that creates a TransformStream
for the `streamText` `transform` option
to smooth out text streaming by buffering and releasing complete words with configurable delays.
This creates a more natural reading experience when streaming text responses.

```code-block_code__yIKW2

import { smoothStream, streamText } from 'ai';

const result = streamText({

  model,

  prompt,

  experimental_transform: smoothStream({

    delayInMs: 20, // optional: defaults to 10ms

    chunking: 'line', // optional: defaults to 'word'

  }),

});
```

## [Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#import)

```
import { smoothStream } from "ai"
```

## [API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#parameters)

### delayInMs?:

number \| null

The delay in milliseconds between outputting each chunk. Defaults to 10ms. Set to \`null\` to disable delays.

### chunking?:

"word" \| "line" \| RegExp \| (buffer: string) => string \| undefined \| null

Controls how the text is chunked for streaming. Use "word" to stream word by word (default), "line" to stream line by line, or provide a custom callback or RegExp pattern for custom chunking.

#### [Word chunking caveats with non-latin languages](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#word-chunking-caveats-with-non-latin-languages)

The word based chunking **does not work well** with the following languages that do not delimit words with spaces:

For these languages we recommend using a custom regex, like the following:

- Chinese - `/[\u4E00-\u9FFF]|\S+\s+/`
- Japanese - `/[\u3040-\u309F\u30A0-\u30FF]|\S+\s+/`

Japanese example

```code-block_code__yIKW2

import { smoothStream, streamText } from 'ai';

const result = streamText({

  model: 'openai/gpt-4.1',

  prompt: 'Your prompt here',

  experimental_transform: smoothStream({

    chunking: /[\u3040-\u309F\u30A0-\u30FF]|\S+\s+/,

  }),

});
```

Chinese example

```code-block_code__yIKW2

import { smoothStream, streamText } from 'ai';

const result = streamText({

  model: 'openai/gpt-4.1',

  prompt: 'Your prompt here',

  experimental_transform: smoothStream({

    chunking: /[\u4E00-\u9FFF]|\S+\s+/,

  }),

});
```

For these languages you could pass your own language aware chunking function:

- Vietnamese
- Thai
- Javanese (Aksara Jawa)

#### [Regex based chunking](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#regex-based-chunking)

To use regex based chunking, pass a `RegExp` to the `chunking` option.

```code-block_code__yIKW2

// To split on underscores:

smoothStream({

  chunking: /_+/,

});

// Also can do it like this, same behavior

smoothStream({

  chunking: /[^_]*_/,

});
```

#### [Custom callback chunking](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#custom-callback-chunking)

To use a custom callback for chunking, pass a function to the `chunking` option.

```code-block_code__yIKW2

smoothStream({

  chunking: text => {

    const findString = 'some string';

    const index = text.indexOf(findString);

    if (index === -1) {

      return null;

    }

    return text.slice(0, index) + findString;

  },

});
```

### [Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream\#returns)

Returns a `TransformStream` that:

- Buffers incoming text chunks
- Releases text when the chunking pattern is encountered
- Adds configurable delays between chunks for smooth output
- Passes through non-text chunks (like step-finish events) immediately

On this page

[smoothStream()](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#smoothstream)

[Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#import)

[API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#parameters)

[Word chunking caveats with non-latin languages](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#word-chunking-caveats-with-non-latin-languages)

[Regex based chunking](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#regex-based-chunking)

[Custom callback chunking](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#custom-callback-chunking)

[Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream#returns)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Web Preview Component
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Copy markdown

# [WebPreview](https://ai-sdk.dev/elements/components/web-preview\#webpreview)

The `WebPreview` component provides a flexible way to showcase the result of a generated UI component, along with its source code. It is designed for documentation and demo purposes, allowing users to interact with live examples and view the underlying implementation.

v0

Console

## [Installation](https://ai-sdk.dev/elements/components/web-preview\#installation)

ai-elementsshadcnManual

```
npx ai-elements@latest add web-preview
```

## [Usage](https://ai-sdk.dev/elements/components/web-preview\#usage)

```code-block_code__yIKW2

import {

  WebPreview,

  WebPreviewNavigation,

  WebPreviewUrl,

  WebPreviewBody,

} from '@/components/ai-elements/web-preview';
```

```code-block_code__yIKW2

<WebPreview defaultUrl="https://ai-sdk.dev" style={{ height: '400px' }}>

  <WebPreviewNavigation>

    <WebPreviewUrl src="https://ai-sdk.dev" />

  </WebPreviewNavigation>

  <WebPreviewBody src="https://ai-sdk.dev" />

</WebPreview>
```

## [Usage with AI SDK](https://ai-sdk.dev/elements/components/web-preview\#usage-with-ai-sdk)

Build a simple v0 clone using the [v0 Platform API](https://v0.dev/docs/api/platform).

Install the `v0-sdk` package:

pnpm

npm

yarn

```
pnpm add v0-sdk
```

Add the following component to your frontend:

app/page.tsx

```code-block_code__yIKW2

'use client';

import {

  WebPreview,

  WebPreviewBody,

  WebPreviewNavigation,

  WebPreviewUrl,

} from '@/components/ai-elements/web-preview';

import { useState } from 'react';

import {

  Input,

  PromptInputTextarea,

  PromptInputSubmit,

} from '@/components/ai-elements/prompt-input';

import { Loader } from '../ai-elements/loader';

const WebPreviewDemo = () => {

  const [previewUrl, setPreviewUrl] = useState('');

  const [prompt, setPrompt] = useState('');

  const [isGenerating, setIsGenerating] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {

    e.preventDefault();

    if (!prompt.trim()) return;

    setPrompt('');

    setIsGenerating(true);

    try {

      const response = await fetch('/api/v0', {

        method: 'POST',

        headers: { 'Content-Type': 'application/json' },

        body: JSON.stringify({ prompt }),

      });

      const data = await response.json();

      setPreviewUrl(data.demo || '/');

      console.log('Generation finished:', data);

    } catch (error) {

      console.error('Generation failed:', error);

    } finally {

      setIsGenerating(false);

    }

  };

  return (

    <div className="max-w-4xl mx-auto p-6 relative size-full rounded-lg border h-[600px]">

      <div className="flex flex-col h-full">

        <div className="flex-1 mb-4">

          {isGenerating ? (

            <div className="flex flex-col items-center justify-center h-full">

              <Loader />

              <p className="mt-4 text-muted-foreground">

                Generating app, this may take a few seconds...

              </p>

            </div>

          ) : previewUrl ? (

            <WebPreview defaultUrl={previewUrl}>

              <WebPreviewNavigation>

                <WebPreviewUrl />

              </WebPreviewNavigation>

              <WebPreviewBody src={previewUrl} />

            </WebPreview>

          ) : (

            <div className="flex items-center justify-center h-full text-muted-foreground">

              Your generated app will appear here

            </div>

          )}

        </div>

        <Input

          onSubmit={handleSubmit}

          className="w-full max-w-2xl mx-auto relative"

        >

          <PromptInputTextarea

            value={prompt}

            placeholder="Describe the app you want to build..."

            onChange={(e) => setPrompt(e.currentTarget.value)}

            className="pr-12 min-h-[60px]"

          />

          <PromptInputSubmit

            status={isGenerating ? 'streaming' : 'ready'}

            disabled={!prompt.trim()}

            className="absolute bottom-1 right-1"

          />

        </Input>

      </div>

    </div>

  );

};

export default WebPreviewDemo;
```

Add the following route to your backend:

app/api/v0/route.ts

```code-block_code__yIKW2

import { v0 } from 'v0-sdk';

export async function POST(req: Request) {

  const { prompt }: { prompt: string } = await req.json();

  const result = await v0.chats.create({

    system: 'You are an expert coder',

    message: prompt,

    modelConfiguration: {

      modelId: 'v0-1.5-sm',

      imageGenerations: false,

      thinking: false,

    },

  });

  return Response.json({

    demo: result.demo,

    webUrl: result.webUrl,

  });

}
```

## [Features](https://ai-sdk.dev/elements/components/web-preview\#features)

- Live preview of UI components
- Composable architecture with dedicated sub-components
- Responsive design modes (Desktop, Tablet, Mobile)
- Navigation controls with back/forward functionality
- URL input and example selector
- Full screen mode support
- Console logging with timestamps
- Context-based state management
- Consistent styling with the design system
- Easy integration into documentation pages

## [Props](https://ai-sdk.dev/elements/components/web-preview\#props)

### [`<WebPreview />`](https://ai-sdk.dev/elements/components/web-preview\#webpreview-)

### defaultUrl?:

string

The initial URL to load in the preview (default: empty string).

### onUrlChange?:

(url: string) => void

Callback fired when the URL changes.

### \[...props\]?:

React.HTMLAttributes<HTMLDivElement>

Any other props are spread to the root div.

### [`<WebPreviewNavigation />`](https://ai-sdk.dev/elements/components/web-preview\#webpreviewnavigation-)

### \[...props\]?:

React.HTMLAttributes<HTMLDivElement>

Any other props are spread to the navigation container.

### [`<WebPreviewNavigationButton />`](https://ai-sdk.dev/elements/components/web-preview\#webpreviewnavigationbutton-)

### tooltip?:

string

Tooltip text to display on hover.

### \[...props\]?:

React.ComponentProps<typeof Button>

Any other props are spread to the underlying shadcn/ui Button component.

### [`<WebPreviewUrl />`](https://ai-sdk.dev/elements/components/web-preview\#webpreviewurl-)

### \[...props\]?:

React.ComponentProps<typeof Input>

Any other props are spread to the underlying shadcn/ui Input component.

### [`<WebPreviewBody />`](https://ai-sdk.dev/elements/components/web-preview\#webpreviewbody-)

### loading?:

React.ReactNode

Optional loading indicator to display over the preview.

### \[...props\]?:

React.IframeHTMLAttributes<HTMLIFrameElement>

Any other props are spread to the underlying iframe.

### [`<WebPreviewConsole />`](https://ai-sdk.dev/elements/components/web-preview\#webpreviewconsole-)

### logs?:

Array<{ level: "log" \| "warn" \| "error"; message: string; timestamp: Date }>

Console log entries to display in the console panel.

### \[...props\]?:

React.HTMLAttributes<HTMLDivElement>

Any other props are spread to the root div.

On this page

[WebPreview](https://ai-sdk.dev/elements/components/web-preview#webpreview)

[Installation](https://ai-sdk.dev/elements/components/web-preview#installation)

[Usage](https://ai-sdk.dev/elements/components/web-preview#usage)

[Usage with AI SDK](https://ai-sdk.dev/elements/components/web-preview#usage-with-ai-sdk)

[Features](https://ai-sdk.dev/elements/components/web-preview#features)

[Props](https://ai-sdk.dev/elements/components/web-preview#props)

[<WebPreview />](https://ai-sdk.dev/elements/components/web-preview#webpreview-)

[<WebPreviewNavigation />](https://ai-sdk.dev/elements/components/web-preview#webpreviewnavigation-)

[<WebPreviewNavigationButton />](https://ai-sdk.dev/elements/components/web-preview#webpreviewnavigationbutton-)

[<WebPreviewUrl />](https://ai-sdk.dev/elements/components/web-preview#webpreviewurl-)

[<WebPreviewBody />](https://ai-sdk.dev/elements/components/web-preview#webpreviewbody-)

[<WebPreviewConsole />](https://ai-sdk.dev/elements/components/web-preview#webpreviewconsole-)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Amazon Nova Micro
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonNova Micro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Nova Micro

A text-only model that delivers the lowest latency responses at very low cost.

Context

128,000 tokens

Input Pricing

$0.04 / million tokens

Output Pricing

$0.14 / million tokens

[Model Page](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/ai/generative-ai/nova)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Braintrust Observability
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [Braintrust Observability](https://ai-sdk.dev/providers/observability/braintrust\#braintrust-observability)

Braintrust is an end-to-end platform for building AI applications. When building with the AI SDK, you can integrate Braintrust to [log](https://www.braintrust.dev/docs/guides/logging), monitor, and take action on real-world interactions.

## [Setup](https://ai-sdk.dev/providers/observability/braintrust\#setup)

Braintrust natively supports OpenTelemetry and works out of the box with the AI SDK, either via Next.js or Node.js.

### [Next.js](https://ai-sdk.dev/providers/observability/braintrust\#nextjs)

If you are using Next.js, you can use the Braintrust exporter with `@vercel/otel` for the cleanest setup:

```code-block_code__yIKW2

import { registerOTel } from '@vercel/otel';

import { BraintrustExporter } from 'braintrust';

// In your instrumentation.ts file

export function register() {

  registerOTel({

    serviceName: 'my-braintrust-app',

    traceExporter: new BraintrustExporter({

      parent: 'project_name:your-project-name',

      filterAISpans: true, // Only send AI-related spans

    }),

  });

}
```

Or set the following environment variables in your app's `.env` file, with your API key and project ID:

```code-block_code__yIKW2

OTEL_EXPORTER_OTLP_ENDPOINT=https://api.braintrust.dev/otel

OTEL_EXPORTER_OTLP_HEADERS="Authorization=Bearer <Your API Key>, x-bt-parent=project_id:<Your Project ID>"
```

Traced LLM calls will appear under the Braintrust project or experiment provided in the `x-bt-parent` header.

When you call the AI SDK, make sure to set `experimental_telemetry`:

```code-block_code__yIKW2

const result = await generateText({

  model: openai('gpt-4o-mini'),

  prompt: 'What is 2 + 2?',

  experimental_telemetry: {

    isEnabled: true,

    metadata: {

      query: 'weather',

      location: 'San Francisco',

    },

  },

});
```

The integration supports streaming functions like `streamText`. Each streamed call will produce `ai.streamText` spans in Braintrust.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

export async function POST(req: Request) {

  const { prompt } = await req.json();

  const result = await streamText({

    model: openai('gpt-4o-mini'),

    prompt,

    experimental_telemetry: { isEnabled: true },

  });

  return result.toDataStreamResponse();

}
```

### [Node.js](https://ai-sdk.dev/providers/observability/braintrust\#nodejs)

If you are using Node.js without a framework, you must configure the `NodeSDK` directly. In this case, it's more straightforward to use the `BraintrustSpanProcessor`.

First, install the necessary dependencies:

```code-block_code__yIKW2

npm install ai @ai-sdk/openai braintrust @opentelemetry/sdk-node @opentelemetry/sdk-trace-base zod
```

Then, set up the OpenTelemetry SDK:

```code-block_code__yIKW2

import { NodeSDK } from '@opentelemetry/sdk-node';

import { generateText, tool } from 'ai';

import { openai } from '@ai-sdk/openai';

import { z } from 'zod';

import { BraintrustSpanProcessor } from 'braintrust';

const sdk = new NodeSDK({

  spanProcessors: [\
\
    new BraintrustSpanProcessor({\
\
      parent: 'project_name:your-project-name',\
\
      filterAISpans: true,\
\
    }),\
\
  ],

});

sdk.start();

async function main() {

  const result = await generateText({

    model: openai('gpt-4o-mini'),

    messages: [\
\
      {\
\
        role: 'user',\
\
        content: 'What are my orders and where are they? My user ID is 123',\
\
      },\
\
    ],

    tools: {

      listOrders: tool({

        description: 'list all orders',

        parameters: z.object({ userId: z.string() }),

        execute: async ({ userId }) =>

          `User ${userId} has the following orders: 1`,

      }),

      viewTrackingInformation: tool({

        description: 'view tracking information for a specific order',

        parameters: z.object({ orderId: z.string() }),

        execute: async ({ orderId }) =>

          `Here is the tracking information for ${orderId}`,

      }),

    },

    experimental_telemetry: {

      isEnabled: true,

      functionId: 'my-awesome-function',

      metadata: {

        something: 'custom',

        someOtherThing: 'other-value',

      },

    },

    maxSteps: 10,

  });

  await sdk.shutdown();

}

main().catch(console.error);
```

## [Resources](https://ai-sdk.dev/providers/observability/braintrust\#resources)

To see a step-by-step example, check out the Braintrust [cookbook](https://www.braintrust.dev/docs/cookbook/recipes/OTEL-logging).

After you log your application in Braintrust, explore other workflows like:

- Adding [tools](https://www.braintrust.dev/docs/guides/functions/tools) to your library and using them in [experiments](https://www.braintrust.dev/docs/guides/evals) and the [playground](https://www.braintrust.dev/docs/guides/playground)
- Creating [custom scorers](https://www.braintrust.dev/docs/guides/functions/scorers) to assess the quality of your LLM calls
- Adding your logs to a [dataset](https://www.braintrust.dev/docs/guides/datasets) and running evaluations comparing models and prompts

On this page

[Braintrust Observability](https://ai-sdk.dev/providers/observability/braintrust#braintrust-observability)

[Setup](https://ai-sdk.dev/providers/observability/braintrust#setup)

[Next.js](https://ai-sdk.dev/providers/observability/braintrust#nextjs)

[Node.js](https://ai-sdk.dev/providers/observability/braintrust#nodejs)

[Resources](https://ai-sdk.dev/providers/observability/braintrust#resources)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Error Handling Guide
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Overview](https://ai-sdk.dev/docs/ai-sdk-rsc/overview)

[Streaming React Components](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-react-components)

[Managing Generative UI State](https://ai-sdk.dev/docs/ai-sdk-rsc/generative-ui-state)

[Saving and Restoring States](https://ai-sdk.dev/docs/ai-sdk-rsc/saving-and-restoring-states)

[Multistep Interfaces](https://ai-sdk.dev/docs/ai-sdk-rsc/multistep-interfaces)

[Streaming Values](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-values)

[Handling Loading State](https://ai-sdk.dev/docs/ai-sdk-rsc/loading-state)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling)

[Handling Authentication](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication)

[Migrating from RSC to UI](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Error Handling](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling\#error-handling)

AI SDK RSC is currently experimental. We recommend using [AI SDK\\
UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview) for production. For guidance on migrating from
RSC to UI, see our [migration guide](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui).

Two categories of errors can occur when working with the RSC API: errors while streaming user interfaces and errors while streaming other values.

## [Handling UI Errors](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling\#handling-ui-errors)

To handle errors while generating UI, the [`streamableUI`](https://ai-sdk.dev/docs/reference/ai-sdk-rsc/create-streamable-ui) object exposes an `error()` method.

app/actions.tsx

```code-block_code__yIKW2

'use server';

import { createStreamableUI } from '@ai-sdk/rsc';

export async function getStreamedUI() {

  const ui = createStreamableUI();

  (async () => {

    ui.update(<div>loading</div>);

    const data = await fetchData();

    ui.done(<div>{data}</div>);

  })().catch(e => {

    ui.error(<div>Error: {e.message}</div>);

  });

  return ui.value;

}
```

With this method, you can catch any error with the stream, and return relevant UI. On the client, you can also use a [React Error Boundary](https://react.dev/reference/react/Component#catching-rendering-errors-with-an-error-boundary) to wrap the streamed component and catch any additional errors.

app/page.tsx

```code-block_code__yIKW2

import { getStreamedUI } from '@/actions';

import { useState } from 'react';

import { ErrorBoundary } from './ErrorBoundary';

export default function Page() {

  const [streamedUI, setStreamedUI] = useState(null);

  return (

    <div>

      <button

        onClick={async () => {

          const newUI = await getStreamedUI();

          setStreamedUI(newUI);

        }}

      >

        What does the new UI look like?

      </button>

      <ErrorBoundary>{streamedUI}</ErrorBoundary>

    </div>

  );

}
```

## [Handling Other Errors](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling\#handling-other-errors)

To handle other errors while streaming, you can return an error object that the receiver can use to determine why the failure occurred.

app/actions.tsx

```code-block_code__yIKW2

'use server';

import { createStreamableValue } from '@ai-sdk/rsc';

import { fetchData, emptyData } from '../utils/data';

export const getStreamedData = async () => {

  const streamableData = createStreamableValue<string>(emptyData);

  try {

    (() => {

      const data1 = await fetchData();

      streamableData.update(data1);

      const data2 = await fetchData();

      streamableData.update(data2);

      const data3 = await fetchData();

      streamableData.done(data3);

    })();

    return { data: streamableData.value };

  } catch (e) {

    return { error: e.message };

  }

};
```

On this page

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling#error-handling)

[Handling UI Errors](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling#handling-ui-errors)

[Handling Other Errors](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling#handling-other-errors)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Advanced AI SDK Concepts
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Prompt Engineering](https://ai-sdk.dev/docs/advanced/prompt-engineering)

[Stopping Streams](https://ai-sdk.dev/docs/advanced/stopping-streams)

[Backpressure](https://ai-sdk.dev/docs/advanced/backpressure)

[Caching](https://ai-sdk.dev/docs/advanced/caching)

[Multiple Streamables](https://ai-sdk.dev/docs/advanced/multiple-streamables)

[Rate Limiting](https://ai-sdk.dev/docs/advanced/rate-limiting)

[Rendering UI with Language Models](https://ai-sdk.dev/docs/advanced/rendering-ui-with-language-models)

[Language Models as Routers](https://ai-sdk.dev/docs/advanced/model-as-router)

[Multistep Interfaces](https://ai-sdk.dev/docs/advanced/multistep-interfaces)

[Sequential Generations](https://ai-sdk.dev/docs/advanced/sequential-generations)

[Vercel Deployment Guide](https://ai-sdk.dev/docs/advanced/vercel-deployment-guide)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Advanced

Copy markdown

# [Advanced](https://ai-sdk.dev/docs/advanced\#advanced)

This section covers advanced topics and concepts for the AI SDK and RSC API. Working with LLMs often requires a different mental model compared to traditional software development.

After these concepts, you should have a better understanding of the paradigms behind the AI SDK and RSC API, and how to use them to build more AI applications.

On this page

[Advanced](https://ai-sdk.dev/docs/advanced#advanced)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## OpenAI GPT-4.5 Preview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIGPT-4.5 Preview
Pro

Synced

Drop Image

OpenAI/GPT-4.5 Preview

GPT-4.5 from OpenAI is a research preview of their largest and most knowledgeable model yet, building on GPT-4o with expanded pre-training and broader general-purpose capabilities. It demonstrates more natural interactions, stronger alignment with user intent, and improved emotional intelligence, making it well-suited for writing, programming, and practical problem-solving with reduced hallucinations.

Context

128,000 tokens

Input Pricing

$75.00 / million tokens

Output Pricing

$150.00 / million tokens

[Model Page](https://platform.openai.com/docs/models#gpt-4-5) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## OpenAI Provider Overview
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [OpenAI Provider](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#openai-provider)

The [OpenAI](https://openai.com/) provider contains language model support for the OpenAI responses, chat, and completion APIs, as well as embedding model support for the OpenAI embeddings API.

## [Setup](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#setup)

The OpenAI provider is available in the `@ai-sdk/openai` module. You can install it with

pnpm

npm

yarn

bun

```
pnpm add @ai-sdk/openai
```

## [Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#provider-instance)

You can import the default provider instance `openai` from `@ai-sdk/openai`:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';
```

If you need a customized setup, you can import `createOpenAI` from `@ai-sdk/openai` and create a provider instance with your settings:

```code-block_code__yIKW2

import { createOpenAI } from '@ai-sdk/openai';

const openai = createOpenAI({

  // custom settings, e.g.

  headers: {

    'header-name': 'header-value',

  },

});
```

You can use the following optional settings to customize the OpenAI provider instance:

- **baseURL** _string_

Use a different URL prefix for API calls, e.g. to use proxy servers.
The default prefix is `https://api.openai.com/v1`.

- **apiKey** _string_

API key that is being sent using the `Authorization` header.
It defaults to the `OPENAI_API_KEY` environment variable.

- **name** _string_

The provider name. You can set this when using OpenAI compatible providers
to change the model provider property. Defaults to `openai`.

- **organization** _string_

OpenAI Organization.

- **project** _string_

OpenAI project.

- **headers** _Record<string,string>_

Custom headers to include in the requests.

- **fetch** _(input: RequestInfo, init?: RequestInit) => Promise<Response>_

Custom [fetch](https://developer.mozilla.org/en-US/docs/Web/API/fetch) implementation.
Defaults to the global `fetch` function.
You can use it as a middleware to intercept requests,
or to provide a custom fetch implementation for e.g. testing.


## [Language Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#language-models)

The OpenAI provider instance is a function that you can invoke to create a language model:

```code-block_code__yIKW2

const model = openai('gpt-5');
```

It automatically selects the correct API based on the model id.
You can also pass additional settings in the second argument:

```code-block_code__yIKW2

const model = openai('gpt-5', {

  // additional settings

});
```

The available options depend on the API that's automatically chosen for the model (see below).
If you want to explicitly select a specific model API, you can use `.chat` or `.completion`.

### [Example](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#example)

You can use OpenAI language models to generate text with the `generateText` function:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const { text } = await generateText({

  model: openai('gpt-5'),

  prompt: 'Write a vegetarian lasagna recipe for 4 people.',

});
```

OpenAI language models can also be used in the `streamText`, `generateObject`, and `streamObject` functions
(see [AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)).

### [Chat Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#chat-models)

You can create models that call the [OpenAI chat API](https://platform.openai.com/docs/api-reference/chat) using the `.chat()` factory method.
The first argument is the model id, e.g. `gpt-4`.
The OpenAI chat models support tool calls and some have multi-modal capabilities.

```code-block_code__yIKW2

const model = openai.chat('gpt-5');
```

OpenAI chat models support also some model specific provider options that are not part of the [standard call settings](https://ai-sdk.dev/docs/ai-sdk-core/settings).
You can pass them in the `providerOptions` argument:

```code-block_code__yIKW2

const model = openai.chat('gpt-5');

await generateText({

  model,

  providerOptions: {

    openai: {

      logitBias: {

        // optional likelihood for specific tokens

        '50256': -100,

      },

      user: 'test-user', // optional unique user identifier

    },

  },

});
```

The following optional provider options are available for OpenAI chat models:

- **logitBias** _Record<number, number>_

Modifies the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in
the GPT tokenizer) to an associated bias value from -100 to 100. You
can use this tokenizer tool to convert text to token IDs. Mathematically,
the bias is added to the logits generated by the model prior to sampling.
The exact effect will vary per model, but values between -1 and 1 should
decrease or increase likelihood of selection; values like -100 or 100
should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the token from being generated.

- **logprobs** _boolean \| number_

Return the log probabilities of the tokens. Including logprobs will increase
the response size and can slow down response times. However, it can
be useful to better understand how the model is behaving.

Setting to true will return the log probabilities of the tokens that
were generated.

Setting to a number will return the log probabilities of the top n
tokens that were generated.

- **parallelToolCalls** _boolean_

Whether to enable parallel function calling during tool use. Defaults to `true`.

- **user** _string_

A unique identifier representing your end-user, which can help OpenAI to
monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

- **reasoningEffort** _'minimal' \| 'low' \| 'medium' \| 'high'_

Reasoning effort for reasoning models. Defaults to `medium`. If you use
`providerOptions` to set the `reasoningEffort` option, this
model setting will be ignored.

- **structuredOutputs** _boolean_

Whether to use [structured outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai#structured-outputs).
Defaults to `true`.

When enabled, tool calls and object generation will be strict and follow the provided schema.

- **maxCompletionTokens** _number_

Maximum number of completion tokens to generate. Useful for reasoning models.

- **store** _boolean_

Whether to enable persistence in Responses API.

- **metadata** _Record<string, string>_

Metadata to associate with the request.

- **prediction** _Record<string, any>_

Parameters for prediction mode.

- **serviceTier** _'auto' \| 'flex'_

Service tier for the request. Set to 'flex' for 50% cheaper processing
at the cost of increased latency. Only available for o3, o4-mini, and gpt-5 models.
Defaults to 'auto'.

- **strictJsonSchema** _boolean_

Whether to use strict JSON schema validation.
Defaults to `false`.

- **textVerbosity** _'low' \| 'medium' \| 'high'_

Controls the verbosity of the model's responses. Lower values will result in more concise responses, while higher values will result in more verbose responses.

- **promptCacheKey** _string_

A cache key for manual prompt caching control. Used by OpenAI to cache responses for similar requests to optimize your cache hit rates.

- **safetyIdentifier** _string_

A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user.


#### [Reasoning](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#reasoning)

OpenAI has introduced the `o1`, `o3`, and `o4` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).
Currently, `o4-mini`, `o3`, `o3-mini`, and `o1` are available via both the chat and responses APIs. The
models `codex-mini-latest` and `computer-use-preview` are available only via the [responses API](https://ai-sdk.dev/providers/ai-sdk-providers/openai#responses-models).

Reasoning models currently only generate text, have several limitations, and are only supported using `generateText` and `streamText`.

They support additional settings and response metadata:

- You can use `providerOptions` to set
  - the `reasoningEffort` option (or alternatively the `reasoningEffort` model setting), which determines the amount of reasoning the model performs.
- You can use response `providerMetadata` to access the number of reasoning tokens that the model generated.


```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const { text, usage, providerMetadata } = await generateText({

  model: openai('gpt-5'),

  prompt: 'Invent a new holiday and describe its traditions.',

  providerOptions: {

    openai: {

      reasoningEffort: 'low',

    },

  },

});

console.log(text);

console.log('Usage:', {

  ...usage,

  reasoningTokens: providerMetadata?.openai?.reasoningTokens,

});
```

System messages are automatically converted to OpenAI developer messages for
reasoning models when supported.

Reasoning models require additional runtime inference to complete their
reasoning phase before generating a response. This introduces longer latency
compared to other models.

`maxOutputTokens` is automatically mapped to `max_completion_tokens` for
reasoning models.

#### [Structured Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#structured-outputs)

Structured outputs are enabled by default.
You can disable them by setting the `structuredOutputs` option to `false`.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateObject } from 'ai';

import { z } from 'zod';

const result = await generateObject({

  model: openai('gpt-4o-2024-08-06'),

  providerOptions: {

    openai: {

      structuredOutputs: false,

    },

  },

  schemaName: 'recipe',

  schemaDescription: 'A recipe for lasagna.',

  schema: z.object({

    name: z.string(),

    ingredients: z.array(

      z.object({

        name: z.string(),

        amount: z.string(),

      }),

    ),

    steps: z.array(z.string()),

  }),

  prompt: 'Generate a lasagna recipe.',

});

console.log(JSON.stringify(result.object, null, 2));
```

OpenAI structured outputs have several
[limitations](https://openai.com/index/introducing-structured-outputs-in-the-api),
in particular around the [supported schemas](https://platform.openai.com/docs/guides/structured-outputs/supported-schemas),
and are therefore opt-in.

For example, optional schema properties are not supported.
You need to change Zod `.nullish()` and `.optional()` to `.nullable()`.

#### [Logprobs](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#logprobs)

OpenAI provides logprobs information for completion/chat models.
You can access it in the `providerMetadata` object.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai('gpt-5'),

  prompt: 'Write a vegetarian lasagna recipe for 4 people.',

  providerOptions: {

    openai: {

      // this can also be a number,

      // refer to logprobs provider options section for more

      logprobs: true,

    },

  },

});

const openaiMetadata = (await result.providerMetadata)?.openai;

const logprobs = openaiMetadata?.logprobs;
```

#### [Image Support](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#image-support)

The OpenAI Chat API supports Image inputs for appropriate models.
You can pass Image files as part of the message content using the 'image' type:

```code-block_code__yIKW2

const result = await generateText({

  model: openai('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'Please describe the image.',\
\
        },\
\
        {\
\
          type: 'image',\
\
          image: fs.readFileSync('./data/image.png'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

The model will have access to the image and will respond to questions about it.
The image should be passed using the `image` field.

You can also pass the URL of an image.

```code-block_code__yIKW2

{

  type: 'image',

  image: 'https://sample.edu/image.png',

}
```

#### [PDF support](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#pdf-support)

The OpenAI Chat API supports reading PDF files.
You can pass PDF files as part of the message content using the `file` type:

```code-block_code__yIKW2

const result = await generateText({

  model: openai('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'What is an embedding model?',\
\
        },\
\
        {\
\
          type: 'file',\
\
          data: fs.readFileSync('./data/ai.pdf'),\
\
          mediaType: 'application/pdf',\
\
          filename: 'ai.pdf', // optional\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

The model will have access to the contents of the PDF file and
respond to questions about it.
The PDF file should be passed using the `data` field,
and the `mediaType` should be set to `'application/pdf'`.

You can also pass a file-id from the OpenAI Files API.

```code-block_code__yIKW2

{

  type: 'file',

  data: 'file-8EFBcWHsQxZV7YGezBC1fq',

  mediaType: 'application/pdf',

}
```

You can also pass the URL of a PDF.

```code-block_code__yIKW2

{

  type: 'file',

  data: 'https://sample.edu/example.pdf',

  mediaType: 'application/pdf',

  filename: 'ai.pdf', // optional

}
```

#### [Predicted Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#predicted-outputs)

OpenAI supports [predicted outputs](https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs) for `gpt-4o` and `gpt-4o-mini`.
Predicted outputs help you reduce latency by allowing you to specify a base text that the model should modify.
You can enable predicted outputs by adding the `prediction` option to the `providerOptions.openai` object:

```code-block_code__yIKW2

const result = streamText({

  model: openai('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: 'Replace the Username property with an Email property.',\
\
    },\
\
    {\
\
      role: 'user',\
\
      content: existingCode,\
\
    },\
\
  ],

  providerOptions: {

    openai: {

      prediction: {

        type: 'content',

        content: existingCode,

      },

    },

  },

});
```

OpenAI provides usage information for predicted outputs ( `acceptedPredictionTokens` and `rejectedPredictionTokens`).
You can access it in the `providerMetadata` object.

```code-block_code__yIKW2

const openaiMetadata = (await result.providerMetadata)?.openai;

const acceptedPredictionTokens = openaiMetadata?.acceptedPredictionTokens;

const rejectedPredictionTokens = openaiMetadata?.rejectedPredictionTokens;
```

OpenAI Predicted Outputs have several
[limitations](https://platform.openai.com/docs/guides/predicted-outputs#limitations),
e.g. unsupported API parameters and no tool calling support.

#### [Image Detail](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#image-detail)

You can use the `openai` provider option to set the [image input detail](https://platform.openai.com/docs/guides/images-vision?api-mode=responses#specify-image-input-detail-level) to `high`, `low`, or `auto`:

```code-block_code__yIKW2

const result = await generateText({

  model: openai('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'Describe the image in detail.' },\
\
        {\
\
          type: 'image',\
\
          image:\
\
            'https://github.com/vercel/ai/blob/main/examples/ai-core/data/comic-cat.png?raw=true',\
\
          // OpenAI specific options - image detail:\
\
          providerOptions: {\
\
            openai: { imageDetail: 'low' },\
\
          },\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

Because the `UIMessage` type (used by AI SDK UI hooks like `useChat`) does not
support the `providerOptions` property, you can use `convertToModelMessages`
first before passing the messages to functions like `generateText` or
`streamText`. For more details on `providerOptions` usage, see
[here](https://ai-sdk.dev/docs/foundations/prompts#provider-options).

#### [Distillation](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#distillation)

OpenAI supports model distillation for some models.
If you want to store a generation for use in the distillation process, you can add the `store` option to the `providerOptions.openai` object.
This will save the generation to the OpenAI platform for later use in distillation.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

import 'dotenv/config';

async function main() {

  const { text, usage } = await generateText({

    model: openai('gpt-4o-mini'),

    prompt: 'Who worked on the original macintosh?',

    providerOptions: {

      openai: {

        store: true,

        metadata: {

          custom: 'value',

        },

      },

    },

  });

  console.log(text);

  console.log();

  console.log('Usage:', usage);

}

main().catch(console.error);
```

#### [Prompt Caching](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#prompt-caching)

OpenAI has introduced [Prompt Caching](https://platform.openai.com/docs/guides/prompt-caching) for supported models
including `gpt-4o` and `gpt-4o-mini`.

- Prompt caching is automatically enabled for these models, when the prompt is 1024 tokens or longer. It does
not need to be explicitly enabled.
- You can use response `providerMetadata` to access the number of prompt tokens that were a cache hit.
- Note that caching behavior is dependent on load on OpenAI's infrastructure. Prompt prefixes generally remain in the
cache following 5-10 minutes of inactivity before they are evicted, but during off-peak periods they may persist for up
to an hour.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const { text, usage, providerMetadata } = await generateText({

  model: openai('gpt-4o-mini'),

  prompt: `A 1024-token or longer prompt...`,

});

console.log(`usage:`, {

  ...usage,

  cachedPromptTokens: providerMetadata?.openai?.cachedPromptTokens,

});
```

To improve cache hit rates, you can manually control caching using the `promptCacheKey` option:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const { text, usage, providerMetadata } = await generateText({

  model: openai('gpt-5'),

  prompt: `A 1024-token or longer prompt...`,

  providerOptions: {

    openai: {

      promptCacheKey: 'my-custom-cache-key-123',

    },

  },

});

console.log(`usage:`, {

  ...usage,

  cachedPromptTokens: providerMetadata?.openai?.cachedPromptTokens,

});
```

#### [Audio Input](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#audio-input)

With the `gpt-4o-audio-preview` model, you can pass audio files to the model.

The `gpt-4o-audio-preview` model is currently in preview and requires at least
some audio inputs. It will not work with non-audio data.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai('gpt-4o-audio-preview'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'What is the audio saying?' },\
\
        {\
\
          type: 'file',\
\
          mediaType: 'audio/mpeg',\
\
          data: fs.readFileSync('./data/galileo.mp3'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

### [Responses Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#responses-models)

You can use the OpenAI responses API with the `openai.responses(modelId)` factory method.

```code-block_code__yIKW2

const model = openai.responses('gpt-5');
```

Further configuration can be done using OpenAI provider options.
You can validate the provider options using the `OpenAIResponsesProviderOptions` type.

```code-block_code__yIKW2

import { openai, OpenAIResponsesProviderOptions } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-5'),

  providerOptions: {

    openai: {

      parallelToolCalls: false,

      store: false,

      user: 'user_123',

      // ...

    } satisfies OpenAIResponsesProviderOptions,

  },

  // ...

});
```

The following provider options are available:

- **parallelToolCalls** _boolean_
Whether to use parallel tool calls. Defaults to `true`.

- **store** _boolean_

Whether to store the generation. Defaults to `true`.

When using reasoning models (o1, o3, o4-mini) with multi-step tool calls and `store: false`,
include `['reasoning.encrypted_content']` in the `include` option to ensure reasoning
content is available across conversation steps.

- **metadata** _Record<string, string>_
Additional metadata to store with the generation.

- **previousResponseId** _string_
The ID of the previous response. You can use it to continue a conversation. Defaults to `undefined`.

- **instructions** _string_
Instructions for the model.
They can be used to change the system or developer message when continuing a conversation using the `previousResponseId` option.
Defaults to `undefined`.

- **user** _string_
A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Defaults to `undefined`.

- **reasoningEffort** _'minimal' \| 'low' \| 'medium' \| 'high'_
Reasoning effort for reasoning models. Defaults to `medium`. If you use `providerOptions` to set the `reasoningEffort` option, this model setting will be ignored.

- **reasoningSummary** _'auto' \| 'detailed'_
Controls whether the model returns its reasoning process. Set to `'auto'` for a condensed summary, `'detailed'` for more comprehensive reasoning. Defaults to `undefined` (no reasoning summaries). When enabled, reasoning summaries appear in the stream as events with type `'reasoning'` and in non-streaming responses within the `reasoning` field.

- **strictJsonSchema** _boolean_
Whether to use strict JSON schema validation. Defaults to `false`.

- **serviceTier** _'auto' \| 'flex' \| 'priority'_
Service tier for the request. Set to 'flex' for 50% cheaper processing
at the cost of increased latency (available for o3, o4-mini, and gpt-5 models).
Set to 'priority' for faster processing with Enterprise access (available for gpt-4, gpt-5, gpt-5-mini, o3, o4-mini; gpt-5-nano is not supported).
Defaults to 'auto'.

- **textVerbosity** _'low' \| 'medium' \| 'high'_
Controls the verbosity of the model's response. Lower values result in more concise responses,
while higher values result in more verbose responses. Defaults to `'medium'`.

- **include** _Array<string>_
Specifies additional content to include in the response. Supported values:
`['reasoning.encrypted_content']` for accessing reasoning content across conversation steps,
and `['file_search_call.results']` for including file search results in responses.
Defaults to `undefined`.

- **promptCacheKey** _string_
A cache key for manual prompt caching control. Used by OpenAI to cache responses for similar requests to optimize your cache hit rates.

- **safetyIdentifier** \_string\_0
A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user.


The OpenAI responses provider also returns provider-specific metadata:

```code-block_code__yIKW2

const { providerMetadata } = await generateText({

  model: openai.responses('gpt-5'),

});

const openaiMetadata = providerMetadata?.openai;
```

The following OpenAI-specific metadata is returned:

- **responseId** _string_
The ID of the response. Can be used to continue a conversation.

- **cachedPromptTokens** _number_
The number of prompt tokens that were a cache hit.

- **reasoningTokens** _number_
The number of reasoning tokens that the model generated.


#### [Web Search](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#web-search)

The OpenAI responses API supports web search through the `openai.tools.webSearchPreview` tool.

You can force the use of the web search tool by setting the `toolChoice` parameter to `{ type: 'tool', toolName: 'web_search_preview' }`.

```code-block_code__yIKW2

const result = await generateText({

  model: openai.responses('gpt-5'),

  prompt: 'What happened in San Francisco last week?',

  tools: {

    web_search_preview: openai.tools.webSearchPreview({

      // optional configuration:

      searchContextSize: 'high',

      userLocation: {

        type: 'approximate',

        city: 'San Francisco',

        region: 'California',

      },

    }),

  },

  // Force web search tool:

  toolChoice: { type: 'tool', toolName: 'web_search_preview' },

});

// URL sources

const sources = result.sources;
```

#### [Reasoning Output](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#reasoning-output)

For reasoning models like `gpt-5`, you can enable reasoning summaries to see the model's thought process. Different models support different summarizers‚Äîfor example, `o4-mini` supports detailed summaries. Set `reasoningSummary: "auto"` to automatically receive the richest level available.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

const result = streamText({

  model: openai.responses('gpt-5'),

  prompt: 'Tell me about the Mission burrito debate in San Francisco.',

  providerOptions: {

    openai: {

      reasoningSummary: 'detailed', // 'auto' for condensed or 'detailed' for comprehensive

    },

  },

});

for await (const part of result.fullStream) {

  if (part.type === 'reasoning') {

    console.log(`Reasoning: ${part.textDelta}`);

  } else if (part.type === 'text-delta') {

    process.stdout.write(part.textDelta);

  }

}
```

For non-streaming calls with `generateText`, the reasoning summaries are available in the `reasoning` field of the response:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-5'),

  prompt: 'Tell me about the Mission burrito debate in San Francisco.',

  providerOptions: {

    openai: {

      reasoningSummary: 'auto',

    },

  },

});

console.log('Reasoning:', result.reasoning);
```

Learn more about reasoning summaries in the [OpenAI documentation](https://platform.openai.com/docs/guides/reasoning?api-mode=responses#reasoning-summaries).

#### [Verbosity Control](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#verbosity-control)

You can control the length and detail of model responses using the `textVerbosity` parameter:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-5-mini'),

  prompt: 'Write a poem about a boy and his first pet dog.',

  providerOptions: {

    openai: {

      textVerbosity: 'low', // 'low' for concise, 'medium' (default), or 'high' for verbose

    },

  },

});
```

The `textVerbosity` parameter scales output length without changing the underlying prompt:

- `'low'`: Produces terse, minimal responses
- `'medium'`: Balanced detail (default)
- `'high'`: Verbose responses with comprehensive detail

#### [File Search](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#file-search)

The OpenAI responses API supports file search through the `openai.tools.fileSearch` tool.

You can force the use of the file search tool by setting the `toolChoice` parameter to `{ type: 'tool', toolName: 'file_search' }`.

```code-block_code__yIKW2

const result = await generateText({

  model: openai.responses('gpt-5'),

  prompt: 'What does the document say about user authentication?',

  tools: {

    file_search: openai.tools.fileSearch({

      // optional configuration:

      vectorStoreIds: ['vs_123', 'vs_456'],

      maxNumResults: 10,

      ranking: {

        ranker: 'auto',

      },

      filters: {

        type: 'and',

        filters: [\
\
          { key: 'author', type: 'eq', value: 'John Doe' },\
\
          { key: 'date', type: 'gte', value: '2023-01-01' },\
\
        ],

      },

    }),

  },

  // Force file search tool:

  toolChoice: { type: 'tool', toolName: 'file_search' },

});
```

The tool must be named `file_search` when using OpenAI's file search
functionality. This name is required by OpenAI's API specification and cannot
be customized.

#### [Code Interpreter](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#code-interpreter)

The OpenAI responses API supports the code interpreter tool through the `openai.tools.codeInterpreter` tool. This allows models to write and execute Python code.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-5'),

  prompt: 'Write and run Python code to calculate the factorial of 10',

  tools: {

    code_interpreter: openai.tools.codeInterpreter({

      // optional configuration:

      container: {

        fileIds: ['file-123', 'file-456'], // optional file IDs to make available

      },

    }),

  },

});
```

The code interpreter tool can be configured with:

- **container**: Either a container ID string or an object with `fileIds` to specify uploaded files that should be available to the code interpreter

The tool must be named `code_interpreter` when using OpenAI's code interpreter
functionality. This name is required by OpenAI's API specification and cannot
be customized.

#### [Image Support](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#image-support-1)

The OpenAI Responses API supports Image inputs for appropriate models.
You can pass Image files as part of the message content using the 'image' type:

```code-block_code__yIKW2

const result = await generateText({

  model: openai.responses('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'Please describe the image.',\
\
        },\
\
        {\
\
          type: 'image',\
\
          image: fs.readFileSync('./data/image.png'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

The model will have access to the image and will respond to questions about it.
The image should be passed using the `image` field.

You can also pass a file-id from the OpenAI Files API.

```code-block_code__yIKW2

{

  type: 'image',

  image: 'file-8EFBcWHsQxZV7YGezBC1fq'

}
```

You can also pass the URL of an image.

```code-block_code__yIKW2

{

  type: 'image',

  image: 'https://sample.edu/image.png',

}
```

#### [PDF support](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#pdf-support-1)

The OpenAI Responses API supports reading PDF files.
You can pass PDF files as part of the message content using the `file` type:

```code-block_code__yIKW2

const result = await generateText({

  model: openai.responses('gpt-5'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'What is an embedding model?',\
\
        },\
\
        {\
\
          type: 'file',\
\
          data: fs.readFileSync('./data/ai.pdf'),\
\
          mediaType: 'application/pdf',\
\
          filename: 'ai.pdf', // optional\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

You can also pass a file-id from the OpenAI Files API.

```code-block_code__yIKW2

{

  type: 'file',

  data: 'file-8EFBcWHsQxZV7YGezBC1fq',

  mediaType: 'application/pdf',

}
```

You can also pass the URL of a pdf.

```code-block_code__yIKW2

{

  type: 'file',

  data: 'https://sample.edu/example.pdf',

  mediaType: 'application/pdf',

  filename: 'ai.pdf', // optional

}
```

The model will have access to the contents of the PDF file and
respond to questions about it.
The PDF file should be passed using the `data` field,
and the `mediaType` should be set to `'application/pdf'`.

#### [Structured Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#structured-outputs-1)

The OpenAI Responses API supports structured outputs. You can enforce structured outputs using `generateObject` or `streamObject`, which expose a `schema` option. Additionally, you can pass a Zod or JSON Schema object to the `experimental_output` option when using `generateText` or `streamText`.

```code-block_code__yIKW2

// Using generateObject

const result = await generateObject({

  model: openai.responses('gpt-4.1'),

  schema: z.object({

    recipe: z.object({

      name: z.string(),

      ingredients: z.array(

        z.object({

          name: z.string(),

          amount: z.string(),

        }),

      ),

      steps: z.array(z.string()),

    }),

  }),

  prompt: 'Generate a lasagna recipe.',

});

// Using generateText

const result = await generateText({

  model: openai.responses('gpt-4.1'),

  prompt: 'How do I make a pizza?',

  experimental_output: Output.object({

    schema: z.object({

      ingredients: z.array(z.string()),

      steps: z.array(z.string()),

    }),

  }),

});
```

### [Completion Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#completion-models)

You can create models that call the [OpenAI completions API](https://platform.openai.com/docs/api-reference/completions) using the `.completion()` factory method.
The first argument is the model id.
Currently only `gpt-3.5-turbo-instruct` is supported.

```code-block_code__yIKW2

const model = openai.completion('gpt-3.5-turbo-instruct');
```

OpenAI completion models support also some model specific settings that are not part of the [standard call settings](https://ai-sdk.dev/docs/ai-sdk-core/settings).
You can pass them as an options argument:

```code-block_code__yIKW2

const model = openai.completion('gpt-3.5-turbo-instruct');

await model.doGenerate({

  providerOptions: {

    openai: {

      echo: true, // optional, echo the prompt in addition to the completion

      logitBias: {

        // optional likelihood for specific tokens

        '50256': -100,

      },

      suffix: 'some text', // optional suffix that comes after a completion of inserted text

      user: 'test-user', // optional unique user identifier

    },

  },

});
```

The following optional provider options are available for OpenAI completion models:

- **echo**: _boolean_

Echo back the prompt in addition to the completion.

- **logitBias** _Record<number, number>_

Modifies the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in
the GPT tokenizer) to an associated bias value from -100 to 100. You
can use this tokenizer tool to convert text to token IDs. Mathematically,
the bias is added to the logits generated by the model prior to sampling.
The exact effect will vary per model, but values between -1 and 1 should
decrease or increase likelihood of selection; values like -100 or 100
should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|>
token from being generated.

- **logprobs** _boolean \| number_

Return the log probabilities of the tokens. Including logprobs will increase
the response size and can slow down response times. However, it can
be useful to better understand how the model is behaving.

Setting to true will return the log probabilities of the tokens that
were generated.

Setting to a number will return the log probabilities of the top n
tokens that were generated.

- **suffix** _string_

The suffix that comes after a completion of inserted text.

- **user** _string_

A unique identifier representing your end-user, which can help OpenAI to
monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).


### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#model-capabilities)

| Model | Image Input | Audio Input | Object Generation | Tool Usage |
| --- | --- | --- | --- | --- |
| `gpt-4.1` |  |  |  |  |
| `gpt-4.1-mini` |  |  |  |  |
| `gpt-4.1-nano` |  |  |  |  |
| `gpt-4o` |  |  |  |  |
| `gpt-4o-mini` |  |  |  |  |
| `gpt-4o-audio-preview` |  |  |  |  |
| `gpt-4-turbo` |  |  |  |  |
| `gpt-4` |  |  |  |  |
| `gpt-3.5-turbo` |  |  |  |  |
| `o1` |  |  |  |  |
| `o3-mini` |  |  |  |  |
| `o3` |  |  |  |  |
| `o4-mini` |  |  |  |  |
| `chatgpt-4o-latest` |  |  |  |  |
| `gpt-5` |  |  |  |  |
| `gpt-5-mini` |  |  |  |  |
| `gpt-5-nano` |  |  |  |  |
| `gpt-5-chat-latest` |  |  |  |  |

The table above lists popular models. Please see the [OpenAI\\
docs](https://platform.openai.com/docs/models) for a full list of available
models. The table above lists popular models. You can also pass any available
provider model ID as a string if needed.

## [Embedding Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#embedding-models)

You can create models that call the [OpenAI embeddings API](https://platform.openai.com/docs/api-reference/embeddings)
using the `.textEmbedding()` factory method.

```code-block_code__yIKW2

const model = openai.textEmbedding('text-embedding-3-large');
```

OpenAI embedding models support several additional provider options.
You can pass them as an options argument:

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { embed } from 'ai';

const { embedding } = await embed({

  model: openai.textEmbedding('text-embedding-3-large'),

  value: 'sunny day at the beach',

  providerOptions: {

    openai: {

      dimensions: 512, // optional, number of dimensions for the embedding

      user: 'test-user', // optional unique user identifier

    },

  },

});
```

The following optional provider options are available for OpenAI embedding models:

- **dimensions**: _number_

The number of dimensions the resulting output embeddings should have.
Only supported in text-embedding-3 and later models.

- **user** _string_

A unique identifier representing your end-user, which can help OpenAI to
monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).


### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#model-capabilities-1)

| Model | Default Dimensions | Custom Dimensions |
| --- | --- | --- |
| `text-embedding-3-large` | 3072 |  |
| `text-embedding-3-small` | 1536 |  |
| `text-embedding-ada-002` | 1536 |  |

## [Image Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#image-models)

You can create models that call the [OpenAI image generation API](https://platform.openai.com/docs/api-reference/images)
using the `.image()` factory method.

```code-block_code__yIKW2

const model = openai.image('dall-e-3');
```

Dall-E models do not support the `aspectRatio` parameter. Use the `size`
parameter instead.

### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#model-capabilities-2)

| Model | Sizes |
| --- | --- |
| `gpt-image-1` | 1024x1024, 1536x1024, 1024x1536 |
| `dall-e-3` | 1024x1024, 1792x1024, 1024x1792 |
| `dall-e-2` | 256x256, 512x512, 1024x1024 |

You can pass optional `providerOptions` to the image model. These are prone to change by OpenAI and are model dependent. For example, the `gpt-image-1` model supports the `quality` option:

```code-block_code__yIKW2

const { image, providerMetadata } = await generateImage({

  model: openai.image('gpt-image-1'),

  prompt: 'A salamander at sunrise in a forest pond in the Seychelles.',

  providerOptions: {

    openai: { quality: 'high' },

  },

});
```

For more on `generateImage()` see [Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation).

OpenAI's image models may return a revised prompt for each image. It can be access at `providerMetadata.openai.images[0]?.revisedPrompt`.

For more information on the available OpenAI image model options, see the [OpenAI API reference](https://platform.openai.com/docs/api-reference/images/create).

## [Transcription Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#transcription-models)

You can create models that call the [OpenAI transcription API](https://platform.openai.com/docs/api-reference/audio/transcribe)
using the `.transcription()` factory method.

The first argument is the model id e.g. `whisper-1`.

```code-block_code__yIKW2

const model = openai.transcription('whisper-1');
```

You can also pass additional provider-specific options using the `providerOptions` argument. For example, supplying the input language in ISO-639-1 (e.g. `en`) format will improve accuracy and latency.

```code-block_code__yIKW2

import { experimental_transcribe as transcribe } from 'ai';

import { openai } from '@ai-sdk/openai';

const result = await transcribe({

  model: openai.transcription('whisper-1'),

  audio: new Uint8Array([1, 2, 3, 4]),

  providerOptions: { openai: { language: 'en' } },

});
```

The following provider options are available:

- **timestampGranularities** _string\[\]_
The granularity of the timestamps in the transcription.
Defaults to `['segment']`.
Possible values are `['word']`, `['segment']`, and `['word', 'segment']`.
Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

- **language** _string_
The language of the input audio. Supplying the input language in ISO-639-1 format (e.g. 'en') will improve accuracy and latency.
Optional.

- **prompt** _string_
An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.
Optional.

- **temperature** _number_
The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
Defaults to 0.
Optional.

- **include** _string\[\]_
Additional information to include in the transcription response.


### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#model-capabilities-3)

| Model | Transcription | Duration | Segments | Language |
| --- | --- | --- | --- | --- |
| `whisper-1` |  |  |  |  |
| `gpt-4o-mini-transcribe` |  |  |  |  |
| `gpt-4o-transcribe` |  |  |  |  |

## [Speech Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#speech-models)

You can create models that call the [OpenAI speech API](https://platform.openai.com/docs/api-reference/audio/speech)
using the `.speech()` factory method.

The first argument is the model id e.g. `tts-1`.

```code-block_code__yIKW2

const model = openai.speech('tts-1');
```

You can also pass additional provider-specific options using the `providerOptions` argument. For example, supplying a voice to use for the generated audio.

```code-block_code__yIKW2

import { experimental_generateSpeech as generateSpeech } from 'ai';

import { openai } from '@ai-sdk/openai';

const result = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  providerOptions: { openai: {} },

});
```

- **instructions** _string_
Control the voice of your generated audio with additional instructions e.g. "Speak in a slow and steady tone".
Does not work with `tts-1` or `tts-1-hd`.
Optional.

- **response\_format** _string_
The format to audio in.
Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.
Defaults to `mp3`.
Optional.

- **speed** _number_
The speed of the generated audio.
Select a value from 0.25 to 4.0.
Defaults to 1.0.
Optional.


### [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai\#model-capabilities-4)

| Model | Instructions |
| --- | --- |
| `tts-1` |  |
| `tts-1-hd` |  |
| `gpt-4o-mini-tts` |  |

On this page

[OpenAI Provider](https://ai-sdk.dev/providers/ai-sdk-providers/openai#openai-provider)

[Setup](https://ai-sdk.dev/providers/ai-sdk-providers/openai#setup)

[Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/openai#provider-instance)

[Language Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#language-models)

[Example](https://ai-sdk.dev/providers/ai-sdk-providers/openai#example)

[Chat Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#chat-models)

[Reasoning](https://ai-sdk.dev/providers/ai-sdk-providers/openai#reasoning)

[Structured Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai#structured-outputs)

[Logprobs](https://ai-sdk.dev/providers/ai-sdk-providers/openai#logprobs)

[Image Support](https://ai-sdk.dev/providers/ai-sdk-providers/openai#image-support)

[PDF support](https://ai-sdk.dev/providers/ai-sdk-providers/openai#pdf-support)

[Predicted Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai#predicted-outputs)

[Image Detail](https://ai-sdk.dev/providers/ai-sdk-providers/openai#image-detail)

[Distillation](https://ai-sdk.dev/providers/ai-sdk-providers/openai#distillation)

[Prompt Caching](https://ai-sdk.dev/providers/ai-sdk-providers/openai#prompt-caching)

[Audio Input](https://ai-sdk.dev/providers/ai-sdk-providers/openai#audio-input)

[Responses Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#responses-models)

[Web Search](https://ai-sdk.dev/providers/ai-sdk-providers/openai#web-search)

[Reasoning Output](https://ai-sdk.dev/providers/ai-sdk-providers/openai#reasoning-output)

[Verbosity Control](https://ai-sdk.dev/providers/ai-sdk-providers/openai#verbosity-control)

[File Search](https://ai-sdk.dev/providers/ai-sdk-providers/openai#file-search)

[Code Interpreter](https://ai-sdk.dev/providers/ai-sdk-providers/openai#code-interpreter)

[Image Support](https://ai-sdk.dev/providers/ai-sdk-providers/openai#image-support-1)

[PDF support](https://ai-sdk.dev/providers/ai-sdk-providers/openai#pdf-support-1)

[Structured Outputs](https://ai-sdk.dev/providers/ai-sdk-providers/openai#structured-outputs-1)

[Completion Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#completion-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai#model-capabilities)

[Embedding Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#embedding-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai#model-capabilities-1)

[Image Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#image-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai#model-capabilities-2)

[Transcription Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#transcription-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai#model-capabilities-3)

[Speech Models](https://ai-sdk.dev/providers/ai-sdk-providers/openai#speech-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/openai#model-capabilities-4)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Applications Showcase
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

## Showcase

Check out these applications built with the AI SDK.

[![Perplexity Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fperplexity.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Perplexity](https://perplexity.ai/) [![v0 Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fv0.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
v0](https://v0.dev/chat) [![Postgres.new Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fpostgresnew.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Postgres.new](https://postgres.new/) [![Midday Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fmidday.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Midday](https://www.midday.ai/) [![Val Town Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fvaltown.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Val Town](https://val.town/) [![Morphic Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fmorphic.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Morphic](https://morphic.sh/) [![Dub.sh Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fdubsh.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Dub.sh](https://dub.sh/) [![Chatbase Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fchatbase.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Chatbase](https://chatbase.co/) [![ChatPRD Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fchatprd.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
ChatPRD](https://www.chatprd.ai/) [![Ozone Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Fozone.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Ozone](https://ozone.pro/) [![2txt Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2F2txt.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
2txt](https://2txt.vercel.app/) [![Vercel AI templates Logo](https://ai-sdk.dev/_next/image?url=%2Fimages%2Fshowcase%2Ftemplates.png&w=750&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)\\
\\
Vercel AI templates](https://vercel.com/templates?type=ai)

Are you using the AI SDK?

[Add your company](https://github.com/vercel/ai/discussions/1914)

## AI Load Setting Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error\#ai_loadsettingerror)

This error occurs when a setting is not loaded successfully.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error\#properties)

- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error\#checking-for-this-error)

You can check if an error is an instance of `AI_LoadSettingError` using:

```code-block_code__yIKW2

import { LoadSettingError } from 'ai';

if (LoadSettingError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error#ai_loadsettingerror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Playground
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIgpt-oss-20b
Hobby

Synced

Drop Image

OpenAI/gpt-oss-20b

For lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters).

Context

131,072 tokens

Input Pricing

$0.10 / million tokens

Output Pricing

$0.50 / million tokens

[Model Page](https://console.groq.com/docs/models) [Pricing](https://wow.groq.com/)

[Terms](https://console.groq.com/docs/terms-of-sale) [Privacy](https://groq.com/privacy-policy) [Website](https://groq.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## OpenAI GPT-3.5 Turbo
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIGPT-3.5 Turbo

Synced

Drop Image

OpenAI/GPT-3.5 Turbo

OpenAI's most capable and cost effective model in the GPT-3.5 family optimized for chat purposes, but also works well for traditional completions tasks.

Context

4,096 tokens

Input Pricing

$0.50 / million tokens

Output Pricing

$1.50 / million tokens

[Model Page](https://platform.openai.com/docs/models/gpt-3-5) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Strange Stream Output
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

[Azure OpenAI Slow to Stream](https://ai-sdk.dev/docs/troubleshooting/azure-stream-slow)

[Client-Side Function Calls Not Invoked](https://ai-sdk.dev/docs/troubleshooting/client-side-function-calls-not-invoked)

[Server Actions in Client Components](https://ai-sdk.dev/docs/troubleshooting/server-actions-in-client-components)

[useChat/useCompletion stream output contains 0:... instead of text](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output)

[Streamable UI Errors](https://ai-sdk.dev/docs/troubleshooting/streamable-ui-errors)

[Tool Invocation Missing Result Error](https://ai-sdk.dev/docs/troubleshooting/tool-invocation-missing-result)

[Streaming Not Working When Deployed](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-deployed)

[Streaming Not Working When Proxied](https://ai-sdk.dev/docs/troubleshooting/streaming-not-working-when-proxied)

[Getting Timeouts When Deploying on Vercel](https://ai-sdk.dev/docs/troubleshooting/timeout-on-vercel)

[Unclosed Streams](https://ai-sdk.dev/docs/troubleshooting/unclosed-streams)

[useChat Failed to Parse Stream](https://ai-sdk.dev/docs/troubleshooting/use-chat-failed-to-parse-stream)

[Server Action Plain Objects Error](https://ai-sdk.dev/docs/troubleshooting/client-stream-error)

[useChat No Response](https://ai-sdk.dev/docs/troubleshooting/use-chat-tools-no-response)

[Custom headers, body, and credentials not working with useChat](https://ai-sdk.dev/docs/troubleshooting/use-chat-custom-request-options)

[useChat "An error occurred"](https://ai-sdk.dev/docs/troubleshooting/use-chat-an-error-occurred)

[Repeated assistant messages in useChat](https://ai-sdk.dev/docs/troubleshooting/repeated-assistant-messages)

[onFinish not called when stream is aborted](https://ai-sdk.dev/docs/troubleshooting/stream-abort-handling)

[streamText fails silently](https://ai-sdk.dev/docs/troubleshooting/stream-text-not-working)

[Streaming Status Shows But No Text Appears](https://ai-sdk.dev/docs/troubleshooting/streaming-status-delay)

[Model is not assignable to type "LanguageModelV1"](https://ai-sdk.dev/docs/troubleshooting/model-is-not-assignable-to-type)

[TypeScript error "Cannot find namespace 'JSX'"](https://ai-sdk.dev/docs/troubleshooting/typescript-cannot-find-namespace-jsx)

[React error "Maximum update depth exceeded"](https://ai-sdk.dev/docs/troubleshooting/react-maximum-update-depth-exceeded)

[Jest: cannot find module '@ai-sdk/rsc'](https://ai-sdk.dev/docs/troubleshooting/jest-cannot-find-module-ai-rsc)

Copy markdown

# [useChat/useCompletion stream output contains 0:... instead of text](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output\#usechatusecompletion-stream-output-contains-0-instead-of-text)

## [Issue](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output\#issue)

I am using custom client code to process a server response that is sent using [`StreamingTextResponse`](https://ai-sdk.dev/docs/reference/stream-helpers/streaming-text-response). I am using version `3.0.20` or newer of the AI SDK. When I send a query, the UI streams text such as `0: "Je"`, `0: " suis"`, `0: "des"...` instead of the text that I‚Äôm looking for.

## [Background](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output\#background)

The AI SDK has switched to the stream data protocol in version `3.0.20`. It sends different stream parts to support data, tool calls, etc. What you see is the raw stream data protocol response.

## [Solution](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output\#solution)

You have several options:

1. Use the AI Core [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) function to send a raw text stream:



```code-block_code__yIKW2


export async function POST(req: Request) {

     const { prompt } = await req.json();




     const result = streamText({

       model: openai.completion('gpt-3.5-turbo-instruct'),

       maxOutputTokens: 2000,

       prompt,

     });




     return result.toTextStreamResponse();

}
```

2. Pin the AI SDK version to `3.0.19` . This will keep the raw text stream.


On this page

[useChat/useCompletion stream output contains 0:... instead of text](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output#usechatusecompletion-stream-output-contains-0-instead-of-text)

[Issue](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output#issue)

[Background](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output#background)

[Solution](https://ai-sdk.dev/docs/troubleshooting/strange-stream-output#solution)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## No Transcript Error
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error\#ai_notranscriptgeneratederror)

This error occurs when no transcript could be generated from the input.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error\#properties)

- `responses`: Array of responses
- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error\#checking-for-this-error)

You can check if an error is an instance of `AI_NoTranscriptGeneratedError` using:

```code-block_code__yIKW2

import { NoTranscriptGeneratedError } from 'ai';

if (NoTranscriptGeneratedError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error#ai_notranscriptgeneratederror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Amazon Claude 3.5
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonClaude 3.5 Sonnet (Bedrock)
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Claude 3.5 Sonnet (Bedrock)

Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet.

Context

200,000 tokens

Input Pricing

$3.00 / million tokens

Output Pricing

$15.00 / million tokens

[Model Page](https://aws.amazon.com/bedrock/claude/) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/bedrock/claude/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Mistral Small Model
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

MistralMistral Small
Hobby

Synced

Drop Image

Mistral/Mistral Small

Mistral Small is the ideal choice for simple tasks that one can do in bulk - like Classification, Customer Support, or Text Generation. It offers excellent performance at an affordable price point.

Context

32,000 tokens

Input Pricing

$0.10 / million tokens

Output Pricing

$0.30 / million tokens

[Model Page](https://mistral.ai/technology/) [Pricing](https://docs.mistral.ai/platform/pricing/)

[Terms](https://mistral.ai/terms) [Privacy](https://mistral.ai/terms#privacy-policy) [Website](https://mistral.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Code Block Component
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Copy markdown

# [Code Block](https://ai-sdk.dev/elements/components/code-block\#code-block)

The `CodeBlock` component provides syntax highlighting, line numbers, and copy to clipboard functionality for code blocks.

```font-mono text-sm
function MyComponent(props) {
  return (
    <div>
      <h1>Hello, {props.name}!</h1>
      <p>This is an example React component.</p>
    </div>
  );
}
```

```font-mono text-sm
function MyComponent(props) {
  return (
    <div>
      <h1>Hello, {props.name}!</h1>
      <p>This is an example React component.</p>
    </div>
  );
}
```

## [Installation](https://ai-sdk.dev/elements/components/code-block\#installation)

ai-elementsshadcnManual

```
npx ai-elements@latest add code-block
```

## [Usage](https://ai-sdk.dev/elements/components/code-block\#usage)

```code-block_code__yIKW2

import { CodeBlock, CodeBlockCopyButton } from '@/components/ai-elements/code-block';
```

```code-block_code__yIKW2

<CodeBlock data={"console.log('hello world')"} language="jsx">

  <CodeBlockCopyButton

    onCopy={() => console.log('Copied code to clipboard')}

    onError={() => console.error('Failed to copy code to clipboard')}

  />

</CodeBlock>
```

## [Usage with AI SDK](https://ai-sdk.dev/elements/components/code-block\#usage-with-ai-sdk)

`CodeBlock` will automatically render within
[`Response`](https://ai-sdk.dev/elements/components/response).

Build a simple code generation tool using the [`experimental_useObject`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-object) hook.

Add the following component to your frontend:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { experimental_useObject as useObject } from '@ai-sdk/react';

import { codeBlockSchema } from '@/app/api/codegen/route';

import {

  Input,

  PromptInputTextarea,

  PromptInputSubmit,

} from '@/components/ai-elements/prompt-input';

import {

  CodeBlock,

  CodeBlockCopyButton,

} from '@/components/ai-elements/code-block';

import { useState } from 'react';

export default function Page() {

  const [input, setInput] = useState('');

  const { object, submit, isLoading } = useObject({

    api: '/api/codegen',

    schema: codeBlockSchema,

  });

  const handleSubmit = (e: React.FormEvent) => {

    e.preventDefault();

    if (input.trim()) {

      submit(input);

    }

  };

  return (

    <div className="max-w-4xl mx-auto p-6 relative size-full rounded-lg border h-[600px]">

      <div className="flex flex-col h-full">

        <div className="flex-1 overflow-auto mb-4">

          {object?.code && object?.language && (

            <CodeBlock

              code={object.code}

              language={object.language}

              showLineNumbers={true}

            >

              <CodeBlockCopyButton />

            </CodeBlock>

          )}

        </div>

        <Input

          onSubmit={handleSubmit}

          className="mt-4 w-full max-w-2xl mx-auto relative"

        >

          <PromptInputTextarea

            value={input}

            placeholder="Generate a React todolist component"

            onChange={(e) => setInput(e.currentTarget.value)}

            className="pr-12"

          />

          <PromptInputSubmit

            status={isLoading ? 'streaming' : 'ready'}

            disabled={!input.trim()}

            className="absolute bottom-1 right-1"

          />

        </Input>

      </div>

    </div>

  );

}
```

Add the following route to your backend:

api/codegen/route.ts

```code-block_code__yIKW2

import { streamObject } from 'ai';

import { z } from 'zod';

export const codeBlockSchema = z.object({

  language: z.string(),

  filename: z.string(),

  code: z.string(),

});

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const context = await req.json();

  const result = streamObject({

    model: 'openai/gpt-4o',

    schema: codeBlockSchema,

    prompt:

      `You are a helpful coding assitant. Only generate code, no markdown formatting or backticks, or text.` +

      context,

  });

  return result.toTextStreamResponse();

}
```

## [Features](https://ai-sdk.dev/elements/components/code-block\#features)

- Syntax highlighting with react-syntax-highlighter
- Line numbers (optional)
- Copy to clipboard functionality
- Automatic light/dark theme switching
- Customizable styles
- Accessible design

## [Examples](https://ai-sdk.dev/elements/components/code-block\#examples)

### [Dark Mode](https://ai-sdk.dev/elements/components/code-block\#dark-mode)

To use the `CodeBlock` component in dark mode, you can wrap it in a `div` with the `dark` class.

```font-mono text-sm
function MyComponent(props) {
  return (
    <div>
      <h1>Hello, {props.name}!</h1>
      <p>This is an example React component.</p>
    </div>
  );
}
```

```font-mono text-sm
function MyComponent(props) {
  return (
    <div>
      <h1>Hello, {props.name}!</h1>
      <p>This is an example React component.</p>
    </div>
  );
}
```

## [Props](https://ai-sdk.dev/elements/components/code-block\#props)

### [`<CodeBlock />`](https://ai-sdk.dev/elements/components/code-block\#codeblock-)

### code:

string

The code content to display.

### language:

string

The programming language for syntax highlighting.

### showLineNumbers?:

boolean

Whether to show line numbers. Default: false.

### children?:

React.ReactNode

Child elements (like CodeBlockCopyButton) positioned in the top-right corner.

### className?:

string

Additional CSS classes to apply to the root container.

### \[...props\]?:

React.HTMLAttributes<HTMLDivElement>

Any other props are spread to the root div.

### [`<CodeBlockCopyButton />`](https://ai-sdk.dev/elements/components/code-block\#codeblockcopybutton-)

### onCopy?:

() =\> void

Callback fired after a successful copy.

### onError?:

(error: Error) => void

Callback fired if copying fails.

### timeout?:

number

How long to show the copied state (ms). Default: 2000.

### children?:

React.ReactNode

Custom content for the button. Defaults to copy/check icons.

### className?:

string

Additional CSS classes to apply to the button.

### \[...props\]?:

React.ComponentProps<typeof Button>

Any other props are spread to the underlying shadcn/ui Button component.

On this page

[Code Block](https://ai-sdk.dev/elements/components/code-block#code-block)

[Installation](https://ai-sdk.dev/elements/components/code-block#installation)

[Usage](https://ai-sdk.dev/elements/components/code-block#usage)

[Usage with AI SDK](https://ai-sdk.dev/elements/components/code-block#usage-with-ai-sdk)

[Features](https://ai-sdk.dev/elements/components/code-block#features)

[Examples](https://ai-sdk.dev/elements/components/code-block#examples)

[Dark Mode](https://ai-sdk.dev/elements/components/code-block#dark-mode)

[Props](https://ai-sdk.dev/elements/components/code-block#props)

[<CodeBlock />](https://ai-sdk.dev/elements/components/code-block#codeblock-)

[<CodeBlockCopyButton />](https://ai-sdk.dev/elements/components/code-block#codeblockcopybutton-)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Message Metadata Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#message-metadata)

Message metadata allows you to attach custom information to messages at the message level. This is useful for tracking timestamps, model information, token usage, user context, and other message-level data.

## [Overview](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#overview)

Message metadata differs from [data parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data) in that it's attached at the message level rather than being part of the message content. While data parts are ideal for dynamic content that forms part of the message, metadata is perfect for information about the message itself.

## [Getting Started](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#getting-started)

Here's a simple example of using message metadata to track timestamps and model information:

### [Defining Metadata Types](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#defining-metadata-types)

First, define your metadata type for type safety:

app/types.ts

```code-block_code__yIKW2

import { UIMessage } from 'ai';

import { z } from 'zod';

// Define your metadata schema

export const messageMetadataSchema = z.object({

  createdAt: z.number().optional(),

  model: z.string().optional(),

  totalTokens: z.number().optional(),

});

export type MessageMetadata = z.infer<typeof messageMetadataSchema>;

// Create a typed UIMessage

export type MyUIMessage = UIMessage<MessageMetadata>;
```

### [Sending Metadata from the Server](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#sending-metadata-from-the-server)

Use the `messageMetadata` callback in `toUIMessageStreamResponse` to send metadata at different streaming stages:

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText } from 'ai';

import { MyUIMessage } from '@/types';

export async function POST(req: Request) {

  const { messages }: { messages: MyUIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse({

    originalMessages: messages, // pass this in for type-safe return objects

    messageMetadata: ({ part }) => {

      // Send metadata when streaming starts

      if (part.type === 'start') {

        return {

          createdAt: Date.now(),

          model: 'gpt-4o',

        };

      }

      // Send additional metadata when streaming completes

      if (part.type === 'finish') {

        return {

          totalTokens: part.totalUsage.totalTokens,

        };

      }

    },

  });

}
```

To enable type-safe metadata return object in `messageMetadata`, pass in the
`originalMessages` parameter typed to your UIMessage type.

### [Accessing Metadata on the Client](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#accessing-metadata-on-the-client)

Access metadata through the `message.metadata` property:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { DefaultChatTransport } from 'ai';

import { MyUIMessage } from '@/types';

export default function Chat() {

  const { messages } = useChat<MyUIMessage>({

    transport: new DefaultChatTransport({

      api: '/api/chat',

    }),

  });

  return (

    <div>

      {messages.map(message => (

        <div key={message.id}>

          <div>

            {message.role === 'user' ? 'User: ' : 'AI: '}

            {message.metadata?.createdAt && (

              <span className="text-sm text-gray-500">

                {new Date(message.metadata.createdAt).toLocaleTimeString()}

              </span>

            )}

          </div>

          {/* Render message content */}

          {message.parts.map((part, index) =>

            part.type === 'text' ? <div key={index}>{part.text}</div> : null,

          )}

          {/* Display additional metadata */}

          {message.metadata?.totalTokens && (

            <div className="text-xs text-gray-400">

              {message.metadata.totalTokens} tokens

            </div>

          )}

        </div>

      ))}

    </div>

  );

}
```

For streaming arbitrary data that changes during generation, consider using
[data parts](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data) instead.

## [Common Use Cases](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#common-use-cases)

Message metadata is ideal for:

- **Timestamps**: When messages were created or completed
- **Model Information**: Which AI model was used
- **Token Usage**: Track costs and usage limits
- **User Context**: User IDs, session information
- **Performance Metrics**: Generation time, time to first token
- **Quality Indicators**: Finish reason, confidence scores

## [See Also](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata\#see-also)

- [Chatbot Guide](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot#message-metadata) \- Message metadata in the context of building chatbots
- [Streaming Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#message-metadata-vs-data-parts) \- Comparison with data parts
- [UIMessage Reference](https://ai-sdk.dev/docs/reference/ai-sdk-core/ui-message) \- Complete UIMessage type reference

On this page

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#message-metadata)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#overview)

[Getting Started](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#getting-started)

[Defining Metadata Types](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#defining-metadata-types)

[Sending Metadata from the Server](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#sending-metadata-from-the-server)

[Accessing Metadata on the Client](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#accessing-metadata-on-the-client)

[Common Use Cases](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#common-use-cases)

[See Also](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata#see-also)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## LangDB AI Gateway
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [LangDB](https://ai-sdk.dev/providers/community-providers/langdb\#langdb)

This community provider is not yet compatible with AI SDK 5. Please wait for
the provider to be updated or consider using an [AI SDK 5 compatible\\
provider](https://ai-sdk.dev/providers/ai-sdk-providers).

[LangDB](https://langdb.ai/) is a high-performance enterprise AI gateway built in Rust, designed to govern, secure, and optimize AI traffic.

LangDB provides OpenAI-compatible APIs, enabling developers to connect with multiple LLMs by changing just two lines of code. With LangDB, you can:

- Provide access to all major LLMs
- Enable plug-and-play functionality using any framework like Langchain, Vercel AI SDK, CrewAI, etc., for easy adoption.
- Simplify implementation of tracing and cost optimization features, ensuring streamlined operations.
- Dynamically route requests to the most suitable LLM based on predefined parameters.

## [Setup](https://ai-sdk.dev/providers/community-providers/langdb\#setup)

The LangDB provider is available via the `@langdb/vercel-provider` module. You can install it with:

pnpm

npm

yarn

bun

```
pnpm add @langdb/vercel-provider
```

## [Provider Instance](https://ai-sdk.dev/providers/community-providers/langdb\#provider-instance)

To create a LangDB provider instance, use the `createLangDB` function:

```code-block_code__yIKW2

import { createLangDB } from '@langdb/vercel-provider';

const langdb = createLangDB({

  apiKey: process.env.LANGDB_API_KEY, // Required

  projectId: 'your-project-id', // Required

  threadId: uuidv4(), // Optional

  runId: uuidv4(), // Optional

  label: 'code-agent', // Optional

  headers: { 'Custom-Header': 'value' }, // Optional

});
```

You can find your LangDB API key in the [LangDB dashboard](https://app.langdb.ai/).

## [Examples](https://ai-sdk.dev/providers/community-providers/langdb\#examples)

You can use LangDB with the `generateText` or `streamText` function:

### [`generateText`](https://ai-sdk.dev/providers/community-providers/langdb\#generatetext)

```code-block_code__yIKW2

import { createLangDB } from '@langdb/vercel-provider';

import { generateText } from 'ai';

const langdb = createLangDB({

  apiKey: process.env.LANGDB_API_KEY,

  projectId: 'your-project-id',

});

export async function generateTextExample() {

  const { text } = await generateText({

    model: langdb('openai/gpt-4o-mini'),

    prompt: 'Write a Python function that sorts a list:',

  });

  console.log(text);

}
```

### [generateImage](https://ai-sdk.dev/providers/community-providers/langdb\#generateimage)

```code-block_code__yIKW2

import { createLangDB } from '@langdb/vercel-provider';

import { experimental_generateImage as generateImage } from 'ai';

import fs from 'fs';

import path from 'path';

const langdb = createLangDB({

  apiKey: process.env.LANGDB_API_KEY,

  projectId: 'your-project-id',

});

export async function generateImageExample() {

  const { images } = await generateImage({

    model: langdb.image('openai/dall-e-3'),

    prompt: 'A delighted resplendent quetzal mid-flight amidst raindrops',

  });

  const imagePath = path.join(__dirname, 'generated-image.png');

  fs.writeFileSync(imagePath, images[0].uint8Array);

  console.log(`Image saved to: ${imagePath}`);

}
```

### [embed](https://ai-sdk.dev/providers/community-providers/langdb\#embed)

```code-block_code__yIKW2

import { createLangDB } from '@langdb/vercel-provider';

import { embed } from 'ai';

const langdb = createLangDB({

  apiKey: process.env.LANGDB_API_KEY,

  projectId: 'your-project-id',

});

export async function generateEmbeddings() {

  const { embedding } = await embed({

    model: langdb.textEmbeddingModel('text-embedding-3-small'),

    value: 'sunny day at the beach',

  });

  console.log('Embedding:', embedding);

}
```

## [Supported Models](https://ai-sdk.dev/providers/community-providers/langdb\#supported-models)

LangDB supports over 250+ models, enabling seamless interaction with a wide range of AI capabilities.

Checkout the [model list](https://app.langdb.ai/models) for more information.

For more information, visit the [LangDB documentation](https://docs.langdb.ai/).

On this page

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb#langdb)

[Setup](https://ai-sdk.dev/providers/community-providers/langdb#setup)

[Provider Instance](https://ai-sdk.dev/providers/community-providers/langdb#provider-instance)

[Examples](https://ai-sdk.dev/providers/community-providers/langdb#examples)

[generateText](https://ai-sdk.dev/providers/community-providers/langdb#generatetext)

[generateImage](https://ai-sdk.dev/providers/community-providers/langdb#generateimage)

[embed](https://ai-sdk.dev/providers/community-providers/langdb#embed)

[Supported Models](https://ai-sdk.dev/providers/community-providers/langdb#supported-models)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Type Validation Error
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error\#ai_typevalidationerror)

This error occurs when type validation fails.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error\#properties)

- `value`: The value that failed validation
- `message`: The error message including validation details

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error\#checking-for-this-error)

You can check if an error is an instance of `AI_TypeValidationError` using:

```code-block_code__yIKW2

import { TypeValidationError } from 'ai';

if (TypeValidationError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error#ai_typevalidationerror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## OpenAI Responses API
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Get started with OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses\#get-started-with-openai-responses-api)

With the [release of OpenAI's responses API](https://openai.com/index/new-tools-for-building-agents/), there has never been a better time to start building AI applications, particularly those that require a deeper understanding of the world.

The [AI SDK](https://ai-sdk.dev/) is a powerful TypeScript toolkit for building AI applications with large language models (LLMs) alongside popular frameworks like React, Next.js, Vue, Svelte, Node.js, and more.

## [OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses\#openai-responses-api)

OpenAI recently released the Responses API, a brand new way to build applications on OpenAI's platform. The new API offers a way to persist chat history, a web search tool for grounding LLM responses, file search tool for finding relevant files, and a computer use tool for building agents that can interact with and operate computers. Let's explore how to use the Responses API with the AI SDK.

## [Getting Started with the AI SDK](https://ai-sdk.dev/cookbook/guides/openai-responses\#getting-started-with-the-ai-sdk)

The AI SDK is the TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js, and more. Integrating LLMs into applications is complicated and heavily dependent on the specific model provider you use.

The AI SDK abstracts away the differences between model providers, eliminates boilerplate code for building chatbots, and allows you to go beyond text output to generate rich, interactive components.

At the center of the AI SDK is [AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core/overview), which provides a unified API to call any LLM. The code snippet below is all you need to call GPT-4o with the new Responses API using the AI SDK:

```code-block_code__yIKW2

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

const { text } = await generateText({

  model: openai.responses('gpt-4o'),

  prompt: 'Explain the concept of quantum entanglement.',

});
```

### [Generating Structured Data](https://ai-sdk.dev/cookbook/guides/openai-responses\#generating-structured-data)

While text generation can be useful, you might want to generate structured JSON data. For example, you might want to extract information from text, classify data, or generate synthetic data. AI SDK Core provides two functions ( [`generateObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object) and [`streamObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object)) to generate structured data, allowing you to constrain model outputs to a specific schema.

```code-block_code__yIKW2

import { generateObject } from 'ai';

import { openai } from '@ai-sdk/openai';

import { z } from 'zod';

const { object } = await generateObject({

  model: openai.responses('gpt-4o'),

  schema: z.object({

    recipe: z.object({

      name: z.string(),

      ingredients: z.array(z.object({ name: z.string(), amount: z.string() })),

      steps: z.array(z.string()),

    }),

  }),

  prompt: 'Generate a lasagna recipe.',

});
```

This code snippet will generate a type-safe recipe that conforms to the specified zod schema.

### [Using Tools with the AI SDK](https://ai-sdk.dev/cookbook/guides/openai-responses\#using-tools-with-the-ai-sdk)

The Responses API supports tool calling out of the box, allowing it to interact with external systems and perform discrete tasks. Here's an example of using tool calling with the AI SDK:

```code-block_code__yIKW2

import { generateText, tool } from 'ai';

import { openai } from '@ai-sdk/openai';

import { z } from 'zod';

const { text } = await generateText({

  model: openai.responses('gpt-4o'),

  prompt: 'What is the weather like today in San Francisco?',

  tools: {

    getWeather: tool({

      description: 'Get the weather in a location',

      inputSchema: z.object({

        location: z.string().describe('The location to get the weather for'),

      }),

      execute: async ({ location }) => ({

        location,

        temperature: 72 + Math.floor(Math.random() * 21) - 10,

      }),

    }),

  },

  stopWhen: stepCountIs(5), // enable multi-step 'agentic' LLM calls

});
```

This example demonstrates how `stopWhen` transforms a single LLM call into an agent. The `stopWhen: stepCountIs(5)` parameter allows the model to autonomously call tools, analyze results, and make additional tool calls as needed - turning what would be a simple one-shot completion into an intelligent agent that can chain multiple actions together to complete complex tasks.

### [Web Search Tool](https://ai-sdk.dev/cookbook/guides/openai-responses\#web-search-tool)

The Responses API introduces a built-in tool for grounding responses called `webSearch`. With this tool, the model can access the internet to find relevant information for its responses.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-4o-mini'),

  prompt: 'What happened in San Francisco last week?',

  tools: {

    web_search_preview: openai.tools.webSearchPreview(),

  },

});

console.log(result.text);

console.log(result.sources);
```

The `webSearch` tool also allows you to specify query-specific metadata that can be used to improve the quality of the search results.

```code-block_code__yIKW2

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-4o-mini'),

  prompt: 'What happened in San Francisco last week?',

  tools: {

    web_search_preview: openai.tools.webSearchPreview({

      searchContextSize: 'high',

      userLocation: {

        type: 'approximate',

        city: 'San Francisco',

        region: 'California',

      },

    }),

  },

});

console.log(result.text);

console.log(result.sources);
```

## [Using Persistence](https://ai-sdk.dev/cookbook/guides/openai-responses\#using-persistence)

With the Responses API, you can persist chat history with OpenAI across requests. This allows you to send just the user's last message and OpenAI can access the entire chat history:

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result1 = await generateText({

  model: openai.responses('gpt-4o-mini'),

  prompt: 'Invent a new holiday and describe its traditions.',

});

const result2 = await generateText({

  model: openai.responses('gpt-4o-mini'),

  prompt: 'Summarize in 2 sentences',

  providerOptions: {

    openai: {

      previousResponseId: result1.providerMetadata?.openai.responseId as string,

    },

  },

});
```

## [Migrating from Completions API](https://ai-sdk.dev/cookbook/guides/openai-responses\#migrating-from-completions-api)

Migrating from the OpenAI Completions API (via the AI SDK) to the new Responses API is simple. To migrate, simply change your provider instance from `openai(modelId)` to `openai.responses(modelId)`:

```code-block_code__yIKW2

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

// Completions API

const { text } = await generateText({

  model: openai('gpt-4o'),

  prompt: 'Explain the concept of quantum entanglement.',

});

// Responses API

const { text } = await generateText({

  model: openai.responses('gpt-4o'),

  prompt: 'Explain the concept of quantum entanglement.',

});
```

When using the Responses API, provider specific options that were previously specified on the model provider instance have now moved to the `providerOptions` object:

```code-block_code__yIKW2

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

// Completions API

const { text } = await generateText({

  model: openai('gpt-4o'),

  prompt: 'Explain the concept of quantum entanglement.',

  providerOptions: {

    openai: {

      parallelToolCalls: false,

    },

  },

});

// Responses API

const { text } = await generateText({

  model: openai.responses('gpt-4o'),

  prompt: 'Explain the concept of quantum entanglement.',

  providerOptions: {

    openai: {

      parallelToolCalls: false,

    },

  },

});
```

## [Get Started](https://ai-sdk.dev/cookbook/guides/openai-responses\#get-started)

Ready to get started? Here's how you can dive in:

1. Explore the documentation at [ai-sdk.dev/docs](https://ai-sdk.dev/docs) to understand the full capabilities of the AI SDK.
2. Check out practical examples at [ai-sdk.dev/examples](https://ai-sdk.dev/examples) to see the SDK in action and get inspired for your own projects.
3. Dive deeper with advanced guides on topics like Retrieval-Augmented Generation (RAG) and multi-modal chat at [ai-sdk.dev/docs/guides](https://ai-sdk.dev/docs/guides).
4. Check out ready-to-deploy AI templates at [vercel.com/templates?type=ai](https://vercel.com/templates?type=ai).

On this page

[Get started with OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses#get-started-with-openai-responses-api)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses#openai-responses-api)

[Getting Started with the AI SDK](https://ai-sdk.dev/cookbook/guides/openai-responses#getting-started-with-the-ai-sdk)

[Generating Structured Data](https://ai-sdk.dev/cookbook/guides/openai-responses#generating-structured-data)

[Using Tools with the AI SDK](https://ai-sdk.dev/cookbook/guides/openai-responses#using-tools-with-the-ai-sdk)

[Web Search Tool](https://ai-sdk.dev/cookbook/guides/openai-responses#web-search-tool)

[Using Persistence](https://ai-sdk.dev/cookbook/guides/openai-responses#using-persistence)

[Migrating from Completions API](https://ai-sdk.dev/cookbook/guides/openai-responses#migrating-from-completions-api)

[Get Started](https://ai-sdk.dev/cookbook/guides/openai-responses#get-started)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Perplexity Sonar
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fperplexity.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)PerplexitySonar
Hobby

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fperplexity.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Perplexity/Sonar

Perplexity's lightweight offering with search grounding, quicker and cheaper than Sonar Pro.

Context

127,000 tokens

Input Pricing

$1.00 / million tokens

Output Pricing

$1.00 / million tokens

[Model Page](https://sonar.perplexity.ai/) [Pricing](https://docs.perplexity.ai/docs/pricing)

[Terms](https://www.perplexity.ai/terms) [Privacy](https://www.perplexity.ai/privacy) [Website](https://perplexity.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AI SDK Settings
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings\#settings)

Large language models (LLMs) typically provide settings to augment their output.

All AI SDK functions support the following common settings in addition to the model, the [prompt](https://ai-sdk.dev/docs/ai-sdk-core/prompts), and additional provider-specific settings:

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  maxOutputTokens: 512,

  temperature: 0.3,

  maxRetries: 5,

  prompt: 'Invent a new holiday and describe its traditions.',

});
```

Some providers do not support all common settings. If you use a setting with a
provider that does not support it, a warning will be generated. You can check
the `warnings` property in the result object to see if any warnings were
generated.

### [`maxOutputTokens`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#maxoutputtokens)

Maximum number of tokens to generate.

### [`temperature`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#temperature)

Temperature setting.

The value is passed through to the provider. The range depends on the provider and model.
For most providers, `0` means almost deterministic results, and higher values mean more randomness.

It is recommended to set either `temperature` or `topP`, but not both.

In AI SDK 5.0, temperature is no longer set to `0` by default.

### [`topP`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#topp)

Nucleus sampling.

The value is passed through to the provider. The range depends on the provider and model.
For most providers, nucleus sampling is a number between 0 and 1.
E.g. 0.1 would mean that only tokens with the top 10% probability mass are considered.

It is recommended to set either `temperature` or `topP`, but not both.

### [`topK`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#topk)

Only sample from the top K options for each subsequent token.

Used to remove "long tail" low probability responses.
Recommended for advanced use cases only. You usually only need to use `temperature`.

### [`presencePenalty`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#presencepenalty)

The presence penalty affects the likelihood of the model to repeat information that is already in the prompt.

The value is passed through to the provider. The range depends on the provider and model.
For most providers, `0` means no penalty.

### [`frequencyPenalty`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#frequencypenalty)

The frequency penalty affects the likelihood of the model to repeatedly use the same words or phrases.

The value is passed through to the provider. The range depends on the provider and model.
For most providers, `0` means no penalty.

### [`stopSequences`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#stopsequences)

The stop sequences to use for stopping the text generation.

If set, the model will stop generating text when one of the stop sequences is generated.
Providers may have limits on the number of stop sequences.

### [`seed`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#seed)

It is the seed (integer) to use for random sampling.
If set and supported by the model, calls will generate deterministic results.

### [`maxRetries`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#maxretries)

Maximum number of retries. Set to 0 to disable retries. Default: `2`.

### [`abortSignal`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#abortsignal)

An optional abort signal that can be used to cancel the call.

The abort signal can e.g. be forwarded from a user interface to cancel the call,
or to define a timeout.

#### [Example: Timeout](https://ai-sdk.dev/docs/ai-sdk-core/settings\#example-timeout)

```code-block_code__yIKW2

const result = await generateText({

  model: openai('gpt-4o'),

  prompt: 'Invent a new holiday and describe its traditions.',

  abortSignal: AbortSignal.timeout(5000), // 5 seconds

});
```

### [`headers`](https://ai-sdk.dev/docs/ai-sdk-core/settings\#headers)

Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

You can use the request headers to provide additional information to the provider,
depending on what the provider supports. For example, some observability providers support
headers such as `Prompt-Id`.

```code-block_code__yIKW2

import { generateText } from 'ai';

import { openai } from '@ai-sdk/openai';

const result = await generateText({

  model: openai('gpt-4o'),

  prompt: 'Invent a new holiday and describe its traditions.',

  headers: {

    'Prompt-Id': 'my-prompt-id',

  },

});
```

The `headers` setting is for request-specific headers. You can also set
`headers` in the provider configuration. These headers will be sent with every
request made by the provider.

On this page

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings#settings)

[maxOutputTokens](https://ai-sdk.dev/docs/ai-sdk-core/settings#maxoutputtokens)

[temperature](https://ai-sdk.dev/docs/ai-sdk-core/settings#temperature)

[topP](https://ai-sdk.dev/docs/ai-sdk-core/settings#topp)

[topK](https://ai-sdk.dev/docs/ai-sdk-core/settings#topk)

[presencePenalty](https://ai-sdk.dev/docs/ai-sdk-core/settings#presencepenalty)

[frequencyPenalty](https://ai-sdk.dev/docs/ai-sdk-core/settings#frequencypenalty)

[stopSequences](https://ai-sdk.dev/docs/ai-sdk-core/settings#stopsequences)

[seed](https://ai-sdk.dev/docs/ai-sdk-core/settings#seed)

[maxRetries](https://ai-sdk.dev/docs/ai-sdk-core/settings#maxretries)

[abortSignal](https://ai-sdk.dev/docs/ai-sdk-core/settings#abortsignal)

[Example: Timeout](https://ai-sdk.dev/docs/ai-sdk-core/settings#example-timeout)

[headers](https://ai-sdk.dev/docs/ai-sdk-core/settings#headers)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK 5 Overview
[Blog](https://vercel.com/blog)/ **[Engineering](https://vercel.com/blog/category/engineering)**

# AI SDK 5

## Authors

[![](https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/51QJ4c10ql5HX9ZgDMylCn/b2f62b21451e3990f20cc193af7af312/lgrammel.png)](https://twitter.com/lgrammel) [![](https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/y66IcFMfLB9udVfoyYTld/df2fab90caf7b0fc7101ec985832b462/nicoalbanese.png)](https://twitter.com/nicoalbanese10) [![](https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/5HJhAIvvL1NH6GxXUsSsJ8/5b88aaeffae21891bea5c4528b666a28/josh-s-avatar.jpg)](https://twitter.com/nishimiya)

11 min read

Copy URL

Copied to clipboard!

Jul 31, 2025

Introducing type-safe chat and agentic loop control for full-stack AI applications

With over 2 million weekly downloads, the [AI SDK](https://v5.ai-sdk.dev/) is the leading open-source AI application toolkit for TypeScript and JavaScript. Its unified provider API allows you to use any language model and enables powerful integrations into leading web frameworks.

> ‚ÄúWhen customers ask how they should build their agents, I always say the AI SDK. The industry is moving really fast and everything is changing constantly. The AI SDK is the only perfect abstraction I've seen so far. v5 continues that track record. You can tell it was built by people that are obsessed with Typescript. Everything feels right.When customers ask how they should build their agents, I always say the AI SDK. The industry is moving really fast and everything is changing constantly. The AI SDK is the only perfect abstraction I've seen so far. v5 continues that track record. You can tell it was built by people that are obsessed with Typescript. Everything feels right.‚Äù
>
> ![](https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/6JvV4d4O311ukdTcaSqoBN/a34b0ce70fe7d8dd9286c3881a642d11/ben-hylak.jpg)
>
> **Ben Hylak,** raindrop.ai

Building applications with TypeScript means building applications for the web. Today, we are releasing AI SDK 5, the first AI framework with a fully typed and highly customizable chat integration for React, Svelte, Vue and Angular.

AI SDK 5 introduces:

- [**Redesigned Chat**](https://vercel.com/blog/ai-sdk-5#redesigned-chat)

- [**Agentic Loop Control**](https://vercel.com/blog/ai-sdk-5#agentic-loop-control)

- [**Speech Generation & Transcription**](https://vercel.com/blog/ai-sdk-5#experimental-speech-generation-&-transcription)

- [**Tool Improvements**](https://vercel.com/blog/ai-sdk-5#tool-improvements)

- [**V2 Specifications**](https://vercel.com/blog/ai-sdk-5#v2-specifications)

- [**Global Provider**](https://vercel.com/blog/ai-sdk-5#global-provider)

- [**Access Raw Responses**](https://vercel.com/blog/ai-sdk-5#access-raw-responses)

- [**Zod 4 Support**](https://vercel.com/blog/ai-sdk-5#zod-4-support)


Let‚Äôs "dive" into the details.

## [Redesigned Chat](https://vercel.com/blog/ai-sdk-5\#redesigned-chat)

With AI SDK 5, we've rebuilt chat from the ground up. We took the powerful primitives that developers love for working with LLMs and built a world-class UI integration on top, with end-to-end type safety across your entire application. From server to the client, every piece of data, tool call, and metadata is fully typed. This represents the next evolution of AI libraries for the web.

### [Separate UI and Model Messages](https://vercel.com/blog/ai-sdk-5\#separate-ui-and-model-messages)

One of the biggest challenges developers faced with previous versions of the AI SDK was managing different message types and figuring out how to properly persist chat history.

This was a core consideration in rebuilding `useChat`, which led to the creation of distinct types of messages:

- **UIMessage:** This is the _source of truth_ for your application state, containing all messages, metadata, tool results, and more. We recommend using UIMessages for persisting so that you can always restore the correct user-facing chat history.

- **ModelMessage:** This is a streamlined representation optimized for sending to language models.


We've made this distinction explicit in the API:

```code-block-module__NOThwW__code

// Explicitly convert your UIMessages to ModelMessages

const uiMessages: UIMessage[] = [ /* ... */ ]

const modelMessages = convertToModelMessages(uiMessages);

const result = await streamText({

  model: openai('gpt-4o'),

  // Convert the rich UIMessage format to ModelMessage format

  // This can be replaced with any function that returns ModelMessage[]

  messages: modelMessages,

});

// When finished: Get the complete UIMessage array for persistence

return result.toUIMessageStreamResponse({

  originalMessages: uiMessages,

  onFinish: ({ messages, responseMessage }) => {

    // Save the complete UIMessage array - your full source of truth

    saveChat({ chatId, messages });



    // Or save just the response message

    saveMessage({ chatId, message: responseMessage })

  },

});
```

This separation between UI and model messages makes persistence straightforward. The `onFinish` callback provides all your messages in the format needed to save, with no explicit conversion required.

For complete examples of implementing message persistence with the AI SDK, check out our chatbot [persistence documentation](https://v5.ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence) and the [persistence template repository](https://github.com/vercel-labs/ai-sdk-persistence-db/).

### [Customizable UI Messages](https://vercel.com/blog/ai-sdk-5\#customizable-ui-messages)

With AI SDK 5, you can customize the UIMessage to create your own type with the exact shape of your data, tools, and metadata, that is tailored to your application. You can pass this type as a generic argument to `createUIMessageStream` on the server and to `useChat` on the client, providing full-stack type-safety.

```code-block-module__NOThwW__code

// Define your custom message type once

import { UIMessage } from 'ai';

// ... import your tool and data part types

export type MyUIMessage = UIMessage<MyMetadata, MyDataParts, MyTools>;

// Use it on the client

const { messages } = useChat<MyUIMessage>();

// And use it on the server

const stream = createUIMessageStream<MyUIMessage>(/* ... */);
```

To learn more, check out the [UIMessage documentation](https://v5.ai-sdk.dev/docs/reference/ai-sdk-core/ui-message).

### [Data Parts](https://vercel.com/blog/ai-sdk-5\#data-parts)

Modern AI applications need to send more than just an LLM's plain-text response from the server to the client (e.g. anything from status updates to partial tool results). Without proper typing, streaming custom data can turn your frontend into a mess of runtime checks and type assertions. **Data parts** solve this by providing a first-class way to stream any arbitrary, type-safe data from the server to the client, ensuring your code remains maintainable as your application grows.

On the server, you can stream a data part by specifying your part type (e.g. `data-weather`) and then passing your data. You can update the same data part by specifying an ID:

```code-block-module__NOThwW__code

// On the server, create a UIMessage stream

// Typing the stream with your custom message type

const stream = createUIMessageStream<MyUIMessage>({

  async execute({ writer }) {

    // manually write start step if no LLM call



    const dataPartId = 'weather-1';

    // 1. Send the initial loading state

    writer.write({

      type: 'data-weather', // type-checked against MyUIMessage

      id: dataPartId,

      data: { city: 'San Francisco', status: 'loading' },

    });

    // 2. Later, update the same part (same id) with the final result

    writer.write({

      type: 'data-weather',

      id: dataPartId,

      data: { city: 'San Francisco', weather: 'sunny', status: 'success' },

    });

  },

});
```

On the client, you can then render this specific part. When you use the same ID, the AI SDK replaces the existing data part with the new one:

```code-block-module__NOThwW__code

// On the client, data parts are fully typed

const { messages } = useChat<MyUIMessage>();

{

  messages.map(message =>

    message.parts.map((part, index) => {

      switch (part.type) {

        case 'data-weather':

          return (

            <div key={index}>

              {/* TS knows part.data has city, status, and optional weather */}

              {part.data.status === 'loading'

                ? `Getting weather for ${part.data.city}...`

                : `Weather in ${part.data.city}: ${part.data.weather}`}

            </div>

          );

      }

    }),

  );

}
```

There are also instances where you want to send data that you do not want to persist, but use to communicate status updates, or make other changes to the UI - this is where transient data parts and the `onData` hook comes in.

Transient parts are sent to the client but not added to the message history. They are only accessible via the `onData` useChat handler:

```code-block-module__NOThwW__code

// server

writer.write({

  type: 'data-notification',

  data: { message: 'Processing...', level: 'info' },

  transient: true, // Won't be added to message history

});

// client

const [notification, setNotification] = useState();

const { messages } = useChat({

  onData: ({ data, type }) => {

    if (type === 'data-notification') {

      setNotification({ message: data.message, level: data.level });

    }

  },

});
```

To learn more, check out the [data parts documentation](https://v5.ai-sdk.dev/docs/ai-sdk-ui/streaming-data).

### [Type-Safe Tool Invocations](https://vercel.com/blog/ai-sdk-5\#type-safe-tool-invocations)

Tool invocations in useChat have been redesigned with type-specific part identifiers. Each tool now creates a part type like `tool-TOOLNAME` instead of using generic `tool-invocation` parts.

AI SDK 5 builds on this foundation with three improvements:

- **Type Safety**: By defining your tools' shape within your custom message type, you get end-to-end type safety for both input (your tools' `inputSchema`) and output (your tools' `outputSchema`).

- **Automatic Input Streaming**: Tool call inputs now stream by default, providing partial updates as the model generates them.

- **Explicit Error States**: tool execution errors are limited to the tool and can be resubmitted to the LLM.


Together, these features enable you to build maintainable UIs that show users exactly what's happening throughout the tool execution process‚Äîfrom initial invocation through streaming updates to final results or errors:

```code-block-module__NOThwW__code

// On the client, tool parts are fully typed with the new structure

const { messages } = useChat<MyUIMessage>();

{

  messages.map(message => (

    <>

      {message.parts.map(part => {

        switch (part.type) {

          // Static tools with specific (`tool-${toolName}`) types

          case 'tool-getWeather':

            // New states for streaming and error handling

            switch (part.state) {

              case 'input-streaming':

                // Automatically streamed partial inputs

                return <div>Getting weather for {part.input.location}...</div>;

              case 'input-available':

                return <div>Getting weather for {part.input.location}...</div>;

              case 'output-available':

                return <div>The weather is: {part.output}</div>;

              case 'output-error':

                // Explicit error state with information

                return <div>Error: {part.errorText}</div>;

            }

        }

      })}

    </>

  ));

}
```

The chat also supports dynamic tools ( [more below](https://vercel.com/blog/ai-sdk-5#dynamic-tools)). Dynamic tools (e.g. tools from MCP server) are not known during development and can be rendered using the `dynamic-tool` part:

```code-block-module__NOThwW__code

const { messages } = useChat<MyUIMessage>();

{

  messages.map(message => (

    <>

      {message.parts.map(part => {

        switch (part.type) {

          // Dynamic tools use generic `dynamic-tool` type

          case 'dynamic-tool':

            return (

              <div key={index}>

                <h4>Tool: {part.toolName}</h4>

                {part.state === 'input-streaming' && (

                  <pre>{JSON.stringify(part.input, null, 2)}</pre>

                )}

                {part.state === 'output-available' && (

                  <pre>{JSON.stringify(part.output, null, 2)}</pre>

                )}

                {part.state === 'output-error' && (

                  <div>Error: {part.errorText}</div>

                )}

              </div>

            );

        }

      })}

    </>

  ));

}
```

To learn more, see the [dynamic tools section](https://vercel.com/blog/ai-sdk-5#dynamic-tools) below or check out the [tool calling documentation](https://v5.ai-sdk.dev/docs/ai-sdk-ui/chatbot#using-inferred-types).

### [Message Metadata](https://vercel.com/blog/ai-sdk-5\#message-metadata)

For information _about_ a message, such as a timestamp, model ID, or token count, you can now attach type-safe metadata to a message. You can use it to attach metadata that is relevant to your application.

To send metadata from the server:

```code-block-module__NOThwW__code

// on the server

const result = streamText({

  /* ... */

});

return result.toUIMessageStreamResponse({

  messageMetadata: ({ part }) => {

    if (part.type === "start") {

      return {

        // This object is checked against your metadata type

        model: "gpt-4o",

      };

    }

    if (part.type === "finish") {

      return {

        model: part.response.modelId,

        totalTokens: part.totalUsage.totalTokens,

      };

    }

  },

});
```

You can then access it on the client:

```code-block-module__NOThwW__code

// on the client

const { messages } = useChat<MyUIMessage>();

{

  messages.map(message => (

    <div key={message.id}>

      {/* TS knows message.metadata may have model and totalTokens */}

      {message.metadata?.model && (

        <span>Model: {message.metadata.model}</span>

      )}

      {message.metadata?.totalTokens && (

        <span>{message.metadata.totalTokens} tokens</span>

      )}

    </div>

  ));

}
```

As you update metadata values at different points in the message lifecycle, the client always displays the most current value.

To learn more, check out the [message metadata documentation](https://v5.ai-sdk.dev/docs/ai-sdk-ui/message-metadata).

### [Modular Architecture & Extensibility](https://vercel.com/blog/ai-sdk-5\#modular-architecture-&-extensibility)

The new `useChat` hook has been redesigned with modularity at its core, enabling three powerful extensibility patterns:

- **Flexible Transports:** Swap out the default `fetch`-based transport for custom implementations. Use WebSockets for real-time communication or connect directly to LLM providers without a backend for client-only applications, browser extensions, and privacy-focused use cases. To learn more, check out the [transport documentation](https://v5.ai-sdk.dev/docs/ai-sdk-ui/transport).

- **Decoupled State Management:** The hook's state is fully decoupled, allowing seamless integration with external stores like Zustand, Redux, or MobX. Share chat state across your entire application while maintaining all of `useChat`'s powerful features.

- **Framework-Agnostic Chat:** Build your own chat hooks for any framework using the exposed `AbstractChat` class. Create custom integrations while maintaining full compatibility with the AI SDK ecosystem.


### [Vue, Svelte, and Angular Support](https://vercel.com/blog/ai-sdk-5\#vue,-svelte,-and-angular-support)

AI SDK 5 brings the redesigned chat experience to every major web framework. Vue and Svelte now have complete feature parity with React, and we've introduced support for Angular.

All frameworks now get the same powerful features: custom message types for your application's specific needs, data parts for streaming arbitrary typed data, fully typed tool invocations with automatic input streaming, and type-safe message metadata. Whether you're using `useChat` in React, Vue's composition API, Svelte's stores, or Angular's signals, you're working with the same powerful primitives and end-to-end type safety.

To learn more, check out the [Vue](https://github.com/vercel/ai/tree/main/examples/nuxt-openai), [Svelte](https://github.com/vercel/ai-chatbot-svelte), and [Angular example](https://github.com/vercel/ai/tree/main/examples/angular).

### [**SSE Streaming**](https://vercel.com/blog/ai-sdk-5\#sse-streaming)

The AI SDK now uses Server-Sent Events (SSE) as its standard for streaming data from the server to the client. SSE is natively supported in all major browsers and environments. This change makes our streaming protocol more robust, easier to debug with standard browser developer tools, and simpler to build upon.

## [Agentic Loop Control](https://vercel.com/blog/ai-sdk-5\#agentic-loop-control)

Building reliable AI agents requires precise control over execution flow and context. With AI SDK 5, we're introducing primitives that give you complete control over how your agents run and what context and tools they have at each step.

AI SDK 5 introduces three features for building agents:

- **stopWhen**: Define when a tool-calling loop is stopped.

- **prepareStep**: Adjust the parameters for each step

- **Agent Abstraction**: Use `generateText` and `streamText` with predefined settings


### [stopWhen](https://vercel.com/blog/ai-sdk-5\#stopwhen)

When you make a request with the `generateText` and `streamText`, it runs for a single step by default. The `stopWhen` parameter transforms your single request into a tool-calling loop that will continue until:

- The `stopWhen` condition is satisfied, or

- The model generates text instead of a tool call (always a stopping condition)


Common stopping conditions include:

- **Step limit**: `stepCountIs(5)` \- run for up to 5 steps

- **Specific tool**: `hasToolCall('finalAnswer')` \- stop when a particular tool is called


```code-block-module__NOThwW__code

import { openai } from "@ai-sdk/openai";

import { generateText, stepCountIs, hasToolCall } from "ai";

const result = await generateText({

  model: openai("gpt-4o"),

  tools: {

    /* your tools */

  },

  // Stop a tool-calling loop after 5 steps or;

  // When weather tool is called

  stopWhen: [stepCountIs(5), hasToolCall("weather")],

});
```

### [prepareStep](https://vercel.com/blog/ai-sdk-5\#preparestep)

While `stopWhen` keeps your agent running, `prepareStep ` allows you to control the settings for each step.

Before each step executes, you can adjust:

- **Messages**: Compress or filter context to stay within limits or filter out irrelevant tokens.

- **Model**: Switch between models based on task complexity.

- **System prompt**: Adapt instructions for different tasks.

- **Tools**: Enable/disable tools as needed.

- **Tool choice**: Force specific tool usage (or none) when required.


```code-block-module__NOThwW__code

const result = await streamText({

  model: openai('gpt-4o'),

  messages: convertToModelMessages(messages),

  tools: {

    /* Your tools */

  },

  prepareStep: async ({ stepNumber, messages }) => {

    if (stepNumber === 0) {

      return {

        // Use a different model for the first step

        model: openai('gpt-4o-mini'),

        // Force a specific tool choice

        toolChoice: { type: 'tool', toolName: 'analyzeIntent' },

      };

    }

    // Compress context for longer conversations

    if (messages.length > 10) {

      return {

        // use a model with a larger context window

        model: openai('gpt-4.1'),

        messages: messages.slice(-10),

      };

    }

  },

});
```

### [Agent Abstraction](https://vercel.com/blog/ai-sdk-5\#agent-abstraction)

The `Agent` class provides an object-oriented approach to building agents. It doesn't add new capabilities - everything you can do with `Agent` can be done with `generateText` or `streamText`. Instead, it allows you to encapsulate your agent configuration and execution:

```code-block-module__NOThwW__code

import { openai } from "@ai-sdk/openai";

import { Experimental_Agent as Agent, stepCountIs } from "ai";

const codingAgent = new Agent({

  model: openai("gpt-4o"),

  system: "You are a coding agent. You specialise in Next.js and TypeScript.",

  stopWhen: stepCountIs(10),

  tools: {

    /* Your tools */

  },

});

// Calls `generateText`

const result = codingAgent.generate({

  prompt: "Build an AI coding agent.",

});

// Calls `streamText`

const result = codingAgent.stream({

  prompt: "Build an AI coding agent.",

});
```

## [Experimental Speech Generation & Transcription](https://vercel.com/blog/ai-sdk-5\#experimental-speech-generation-&-transcription)

AI SDK 5 extends our unified provider abstraction to speech. Just as we've done for text and image generation, we're bringing the same consistent, type-safe interface to both speech generation and transcription. Whether you're using [OpenAI](https://v5.ai-sdk.dev/providers/ai-sdk-providers/openai#speech-models), [ElevenLabs](https://v5.ai-sdk.dev/providers/ai-sdk-providers/elevenlabs#transcription-models), or [DeepGram](https://v5.ai-sdk.dev/providers/ai-sdk-providers/deepgram#transcription-models), you work with the same familiar API pattern, and can switch providers with a single line change.

```code-block-module__NOThwW__code

import {

  experimental_generateSpeech as generateSpeech,

  experimental_transcribe as transcribe,

} from 'ai';

import { openai } from '@ai-sdk/openai';

// Text-to-Speech: Generate audio from text

const { audio } = await generateSpeech({

  model: openai.speech('tts-1'),

  text: 'Hello, world!',

  voice: 'alloy',

});

// Speech-to-Text: Transcribe audio to text

const { text, segments } = await transcribe({

  model: openai.transcription('whisper-1'),

  audio: await readFile('audio.mp3'),

});
```

To learn more, check out the [speech](https://v5.ai-sdk.dev/docs/ai-sdk-core/speech) and [transcription](https://v5.ai-sdk.dev/docs/ai-sdk-core/transcription) documentation.

## [Tool Improvements](https://vercel.com/blog/ai-sdk-5\#tool-improvements)

AI SDK 5 enhances tool capabilities with comprehensive improvements including dynamic tools, provider-executed functions, lifecycle hooks, and type-safety throughout the tool calling process.

### [Parameter & Result Renaming](https://vercel.com/blog/ai-sdk-5\#parameter-&-result-renaming)

In AI SDK 5, we've aligned our tool definition interface more closely with the Model Context Protocol (MCP) specification by renaming key concepts:

- **parameters ‚Üí inputSchema**: This rename better describes the schema's purpose of validating and typing the tool's input.

- **result ‚Üí output**: Similarly, tool outputs are now consistently named.


AI SDK 5 also introduces an optional `outputSchema ` property, which aligns with the MCP specification and enables type-safety for client-side tool calling.

These changes make tool definitions more intuitive and consistent with emerging industry standards:

```code-block-module__NOThwW__code

// Before (v4)

const weatherTool = tool({

  name: 'getWeather',

  parameters: z.object({ location: z.string() }),

  execute: async ({ location }) => {

    return `Weather in ${location}: sunny, 72¬∞F`;

  }

});

// After (v5)

const weatherTool = tool({

  description: 'Get the weather for a location',

  inputSchema: z.object({ location: z.string() }),

  outputSchema: z.string(), // New in v5 (optional)

  execute: async ({ location }) => {

    return `Weather in ${location}: sunny, 72¬∞F`;

  }

});
```

### [Dynamic Tools](https://vercel.com/blog/ai-sdk-5\#dynamic-tools)

AI applications often need to work with tools that can't be known in advance:

- MCP (Model Context Protocol) tools without schemas

- User-defined functions loaded at runtime

- External tool providers


Dynamic tools and the `dynamicTool` function enables tools where input and output types are determined at runtime rather than at development time. Dynamic tools are separated from static tools to give you type safety and flexibility at the same time.

```code-block-module__NOThwW__code

import { dynamicTool } from 'ai';

import { z } from 'zod';

const customDynamicTool = dynamicTool({

  description: 'Execute a custom user-defined function',

  inputSchema: z.object({}),

  // input is typed as 'unknown'

  execute: async input => {

    const { action, parameters } = input as any;

    // Execute your dynamic logic

    return {

      result: `Executed ${action} with ${JSON.stringify(parameters)}`,

    };

  },

});

const weatherTool = tool({ /* ... */ })

const result = await generateText({

  model: 'openai/gpt-4o',

  tools: {

    // Static tool with known types

    weatherTool,

    // Dynamic tool

    customDynamicTool,

  },

  onStepFinish: ({ toolCalls, toolResults }) => {

    // Type-safe iteration

    for (const toolCall of toolCalls) {

      if (toolCall.dynamic) {

        // Dynamic tool: input is 'unknown'

        console.log('Dynamic:', toolCall.toolName, toolCall.input);

        continue;

      }

      // Static tool: full type inference

      switch (toolCall.toolName) {

        case 'weather':

          console.log(toolCall.input.location); // typed as string

          break;

      }

    }

  },

});
```

To learn more, check out the [dynamic tool documentation](https://v5.ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling#dynamic-tools).

### [Provider-Executed Tools](https://vercel.com/blog/ai-sdk-5\#provider-executed-tools)

Many AI providers have introduced provider-executed tools. When these tools are called, the provider will execute the tool and send back the tool result as part of the response (e.g. OpenAI‚Äôs web search and file search, xAI‚Äôs web search, and more).

The AI SDK now natively supports provider-executed tools, automatically appending the results to the message history without any additional configuration.

```code-block-module__NOThwW__code

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai.responses('gpt-4o-mini'),

  tools: {

    web_search_preview: openai.tools.webSearchPreview({}),

  },

  // ...

});
```

### [**Tool Lifecycle Hooks**](https://vercel.com/blog/ai-sdk-5\#tool-lifecycle-hooks)

AI SDK 5 introduces granular tool lifecycle hooks ( `onInputStart`, `onInputDelta`, `onInputAvailable`) that can be paired with data parts for sending input-related information (e.g. status updates) back to the client.

```code-block-module__NOThwW__code

const weatherTool = tool({

  description: 'Get the weather for a given city',

  inputSchema: z.object({ city: z.string() }),

  onInputStart: ({ toolCallId }) => {

    console.log('Tool input streaming started:', toolCallId);

  },

  onInputDelta: ({ inputTextDelta, toolCallId }) => {

    console.log('Tool input delta:', inputTextDelta);

  },

  onInputAvailable: ({ input, toolCallId }) => {

    console.log('Tool input ready:', input);

  },

  execute: async ({ city }) => {

    return `Weather in ${city}: sunny, 72¬∞F`;

  },

});
```

### [**Tool Provider Options**](https://vercel.com/blog/ai-sdk-5\#tool-provider-options)

AI SDK 5 adds support for tool-level provider options. You can use this to, for example, cache tool definitions with Anthropic for multi-step agents, reducing token usage, processing time, and costs:

```code-block-module__NOThwW__code

const result = await generateText({

  model: anthropic('claude-3-5-sonnet-20240620'),

  tools: {

    cityAttractions: tool({

      inputSchema: z.object({ city: z.string() }),

      // Apply provider-specific options to individual tools

      providerOptions: {

        anthropic: {

          cacheControl: { type: 'ephemeral' },

        },

      },

      execute: async ({ city }) => {

        // Implementation

      },

    }),

  },

});
```

## [V2 Specifications](https://vercel.com/blog/ai-sdk-5\#v2-specifications)

The foundation of the AI SDK is the specification layer, which standardizes how different language models, embeddings models, etc. plug into functions such as `streamText` . The specification layer enables the provider architecture of the AI SDK.

In AI SDK 5, we have updated all specifications to V2. These new specifications incorporate changes in the underlying API capabilities (like provider-executed tools) and have extensibility mechanisms such as provider metadata and options. They will serve as the foundation for AI SDK 5 and beyond.

To learn more about the V2 specifications, visit the [custom provider documentation](https://v5.ai-sdk.dev/providers/community-providers/custom-providers).

## [Global Provider](https://vercel.com/blog/ai-sdk-5\#global-provider)

The AI SDK 5 includes a global provider feature that allows you to specify a model using just a plain model ID string:

```code-block-module__NOThwW__code

import { streamText } from 'ai';

const result = await streamText({

  model: 'openai/gpt-4o', // Uses the global provider (defaults to AI Gateway)

  prompt: 'Invent a new holiday and describe its traditions.',

});
```

By default, the global provider is set to the [Vercel AI Gateway](https://vercel.com/docs/ai-gateway).

### [Customizing the Global Provider](https://vercel.com/blog/ai-sdk-5\#customizing-the-global-provider)

You can set your own preferred global provider:

```code-block-module__NOThwW__code

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

// Initialise once during startup:

globalThis.AI_SDK_DEFAULT_PROVIDER = openai;

// Somewhere else in your codebase:

const result = streamText({

  model: 'gpt-4o', // Uses OpenAI provider without prefix

  prompt: 'Invent a new holiday and describe its traditions.',

});
```

This simplifies provider usage and makes it easier to switch between providers without changing your model references throughout your codebase.

## [Access Raw Responses](https://vercel.com/blog/ai-sdk-5\#access-raw-responses)

When you need full control or want to implement new features before they're officially supported, the AI SDK provides complete access to raw request and response data. This escape hatch is invaluable for debugging, implementing provider-specific features, or handling edge cases.

### [Raw Streaming Chunks](https://vercel.com/blog/ai-sdk-5\#raw-streaming-chunks)

With AI SDK 5, you can access the raw chunks with streamed functions as they are received from your provider:

```code-block-module__NOThwW__code

import { openai } from "@ai-sdk/openai";

import { streamText } from "ai";

const result = streamText({

  model: openai("gpt-4o-mini"),

  prompt: "Invent a new holiday and describe its traditions.",

  includeRawChunks: true,

});

// Access raw chunks through fullStream

for await (const part of result.fullStream) {

  if (part.type === "raw") {

    // Access provider-specific data structures

    // e.g., OpenAI's choices, usage, etc.

    console.log("Raw chunk:", part.rawValue);

  }

}
```

### [Request and Response Bodies](https://vercel.com/blog/ai-sdk-5\#request-and-response-bodies)

You can also access the exact request sent to the provider and the full response received:

```code-block-module__NOThwW__code

const result = await generateText({

  model: openai("gpt-4o"),

  prompt: "Write a haiku about debugging",

});

// Access the raw request body sent to the provider

// See exact prompt formatting, parameters, etc.

console.log("Request:", result.request.body);

// Access the raw response body from the provider

// Full provider response including metadata

console.log("Response:", result.response.body);
```

## [Zod 4 Support](https://vercel.com/blog/ai-sdk-5\#zod-4-support)

AI SDK 5 supports Zod 4. You can use either Zod 3 or the new [Zod 4 mini](https://zod.dev/v4) schemas for input and output validation across all validation-enabled APIs.

We recommend using Zod 4 for new projects. Follow the recommendation on the [Zod v4 docs](https://zod.dev/v4/#installation).

## [**Migrating to AI SDK 5**](https://vercel.com/blog/ai-sdk-5\#migrating-to-ai-sdk-5)

AI SDK 5 includes breaking changes that remove deprecated APIs. We've made the migration process easier with automated migration tools. You can run our automated codemods to handle some of the changes.

```code-block-module__NOThwW__code

npx @ai-sdk/codemod upgrade
```

For a detailed overview of all changes and manual steps that might be needed, refer to our [AI SDK 5 migration guide](https://v5.ai-sdk.dev/docs/migration-guides/migration-guide-5-0). The guide includes step-by-step instructions and examples to ensure a smooth update.

## [Getting started](https://vercel.com/blog/ai-sdk-5\#getting-started)

With redesigned chat, agentic control and a new specification, there's never been a better time to start building AI applications with the AI SDK.

- **Start a new AI project:** Ready to build something new? Check out our latest [guides](https://v5.ai-sdk.dev/).

- **Explore our templates:** Visit our [Template Gallery](https://vercel.com/templates/ai) to see the AI SDK in action.

- **Migrate to v5:** Upgrading an existing project? Our comprehensive [Migration Guide](https://v5.ai-sdk.dev/docs/migration-guides/migration-guide-5-0) and codemods are ready to help.

- **Chat SDK:** Check out [the Chat SDK open-source template](https://chat-sdk.dev/) that helps you quickly build powerful chatbot applications without starting from scratch.

- **Join the community:** Share what you're building and get help in our [GitHub Discussions](https://github.com/vercel/ai/discussions).


## [Contributors](https://vercel.com/blog/ai-sdk-5\#contributors)

AI SDK 5 is the result of the combined work of our core team at Vercel ( [Lars](https://x.com/lgrammel), [Nico](https://x.com/nicoalbanese10), and [Josh](https://x.com/nishimiya)) and our amazing community of contributors:

[@R-Taneja](https://github.com/R-Taneja), [@danielamitay](https://github.com/danielamitay), [@Und3rf10w](https://github.com/Und3rf10w), [@kvnang](https://github.com/kvnang), [@jakesjews](https://github.com/jakesjews), [@shaper](https://github.com/shaper), [@ankrgyl](https://github.com/ankrgyl), [@gkarthi-signoz](https://github.com/gkarthi-signoz), [@bytaesu](https://github.com/bytaesu), [@ben-vargas](https://github.com/ben-vargas), [@jakobhoeg](https://github.com/jakobhoeg), [@andrico1234](https://github.com/andrico1234), [@jessevdp](https://github.com/jessevdp), [@cristiand391](https://github.com/cristiand391), [@shelleypham](https://github.com/shelleypham), [@damianstasik](https://github.com/damianstasik), [@petergoldstein](https://github.com/petergoldstein), [@lucaazalim](https://github.com/lucaazalim), [@li-kai](https://github.com/li-kai), [@remorses](https://github.com/remorses), [@Potrock](https://github.com/Potrock), [@cwgorman](https://github.com/cwgorman), [@jpdenford](https://github.com/jpdenford), [@allenzhou101](https://github.com/allenzhou101), [@jonaslalin](https://github.com/jonaslalin), [@quuu](https://github.com/quuu), [@jeremyphilemon](https://github.com/jeremyphilemon), [@jeffbarg](https://github.com/jeffbarg), [@zabealbe](https://github.com/zabealbe), [@Gaubee](https://github.com/Gaubee), [@FranciscoMoretti](https://github.com/FranciscoMoretti), [@undo76](https://github.com/undo76), [@winzamark123](https://github.com/winzamark123), [@psinha40898](https://github.com/psinha40898), [@patrickloeber](https://github.com/patrickloeber), [@iteratetograceness](https://github.com/iteratetograceness), [@gr2m](https://github.com/gr2m), [@patelvivekdev](https://github.com/patelvivekdev), [@nvti](https://github.com/nvti), [@jacoblee93](https://github.com/jacoblee93), [@AbhiPrasad](https://github.com/AbhiPrasad), [@huanshenyi](https://github.com/huanshenyi), [@DeJeune](https://github.com/DeJeune), [@tleekkul](https://github.com/tleekkul), [@albertlast](https://github.com/albertlast), [@mmstroik](https://github.com/mmstroik), [@http-samc](https://github.com/http-samc), [@QuantGeekDev](https://github.com/QuantGeekDev), [@benjamincburns](https://github.com/benjamincburns), [@chrisvariety](https://github.com/chrisvariety), [@himanshusinghs](https://github.com/himanshusinghs), [@gorango](https://github.com/gorango), [@joshualipman123](https://github.com/joshualipman123), [@abhikjain360](https://github.com/abhikjain360), [@zhm](https://github.com/zhm), [@elliott-with-the-longest-name-on-github](https://github.com/elliott-with-the-longest-name-on-github), [@samdenty](https://github.com/samdenty), [@cgoinglove](https://github.com/cgoinglove), [@minpeter](https://github.com/minpeter), [@haydenbleasel](https://github.com/haydenbleasel), [@SnehanChakravarthi](https://github.com/SnehanChakravarthi), [@Sma1lboy](https://github.com/Sma1lboy), [@faiz-gear](https://github.com/faiz-gear), [@mattzcarey](https://github.com/mattzcarey), [@BramMeerten](https://github.com/BramMeerten), [@gentamura](https://github.com/gentamura), [@colegottdank](https://github.com/colegottdank), [@wobsoriano](https://github.com/wobsoriano), [@philipkiely-baseten](https://github.com/philipkiely-baseten), [@AmagiDDmxh](https://github.com/AmagiDDmxh), [@dylanmoz](https://github.com/dylanmoz), [@Deipzza](https://github.com/Deipzza), [@whysosaket](https://github.com/whysosaket), [@leopardracer](https://github.com/leopardracer), [@archiewood](https://github.com/archiewood), [@theswerd](https://github.com/theswerd), [@chasewoo](https://github.com/chasewoo), [@omahs](https://github.com/omahs), [@akselleirv](https://github.com/akselleirv), [@EricZhou0815](https://github.com/EricZhou0815), [@mxzinke](https://github.com/mxzinke)

Your feedback, bug reports, and pull requests on GitHub have been instrumental in shaping this release. We're excited to see what you'll build with these new capabilities.

**Ready to deploy?** Start building with a free account. Speak to an expert for your _Pro_ or Enterprise needs.

[Start Deploying](https://vercel.com/new) [Talk to an Expert](https://vercel.com/contact/sales)

**Explore Vercel Enterprise** with an interactive product tour, trial, or a personalized demo.

[Explore Enterprise](https://vercel.com/try-enterprise)

## Web Search Agent
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent\#web-search-agent)

There are two approaches you can take to building a web search agent with the AI SDK:

1. Use a model that has native web-searching capabilities
2. Create a tool to access the web and return search results.

Both approaches have their advantages and disadvantages. Models with native search capabilities tend to be faster and there is no additional cost to make the search. The disadvantage is that you have less control over what is being searched, and the functionality is limited to models that support it.

instead, by creating a tool, you can achieve more flexibility and greater control over your search queries. It allows you to customize your search strategy, specify search parameters, and you can use it with any LLM that supports tool calling. This approach will incur additional costs for the search API you use, but gives you complete control over the search experience.

## [Using native web-search](https://ai-sdk.dev/cookbook/node/web-search-agent\#using-native-web-search)

There are several models that offer native web-searching capabilities (Perplexity, OpenAI, Gemini). Let's look at how you could build a Web Search Agent across providers.

### [OpenAI Responses API](https://ai-sdk.dev/cookbook/node/web-search-agent\#openai-responses-api)

OpenAI's Responses API has a built-in web search tool that can be used to search the web and return search results. This tool is called `web_search_preview` and is accessed via the `openai` provider.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const { text, sources } = await generateText({

  model: openai.responses('gpt-4o-mini'),

  prompt: 'What happened in San Francisco last week?',

  tools: {

    web_search_preview: openai.tools.webSearchPreview({}),

  },

});

console.log(text);

console.log(sources);
```

### [Perplexity](https://ai-sdk.dev/cookbook/node/web-search-agent\#perplexity)

Perplexity's Sonar models combines real-time web search with natural language processing. Each response is grounded in current web data and includes detailed citations.

```code-block_code__yIKW2

import { perplexity } from '@ai-sdk/perplexity';

import { generateText } from 'ai';

const { text, sources } = await generateText({

  model: perplexity('sonar-pro'),

  prompt: 'What are the latest developments in quantum computing?',

});

console.log(text);

console.log(sources);
```

### [Gemini](https://ai-sdk.dev/cookbook/node/web-search-agent\#gemini)

With compatible Gemini models, you can enable search grounding to give the model access to the latest information using Google search.

```code-block_code__yIKW2

import { google } from '@ai-sdk/google';

import { generateText } from 'ai';

const { text, sources, providerMetadata } = await generateText({

  model: google('gemini-2.5-flash'),

  tools: {

    google_search: google.tools.googleSearch({}),

  },

  prompt:

    'List the top 5 San Francisco news from the past week.' +

    'You must include the date of each article.',

});

console.log(text);

console.log(sources);

// access the grounding metadata.

const metadata = providerMetadata?.google;

const groundingMetadata = metadata?.groundingMetadata;

const safetyRatings = metadata?.safetyRatings;
```

## [Building a web search tool](https://ai-sdk.dev/cookbook/node/web-search-agent\#building-a-web-search-tool)

Let's look at how you can build tools that search the web and return results. These tools can be used with any model that supports tool calling, giving you maximum flexibility and control over your search experience. We'll examine several search API options that can be integrated as tools in your agent.

Unlike the native web search examples where searching is built into the model, using web search tools requires multiple steps. The language model will make two generations - the first to call the relevant web search tool (extracting search queries from the context), and the second to process the results and generate a response. This multi-step process is handled automatically when you set `stopWhen: stepCountIs()` to a value greater than 1.

By using `stopWhen`, you can automatically send tool results back to the
language model alongside the original question, enabling the model to respond
with information relevant to the user's query based on the search results.
This creates a seamless experience where the agent can search the web and
incorporate those findings into its response.

### [Exa](https://ai-sdk.dev/cookbook/node/web-search-agent\#exa)

[Exa](https://exa.ai/) is a search API designed for AI. Let's look at how you could implement a search tool using Exa:

```code-block_code__yIKW2

import { generateText, tool, stepCountIs } from 'ai';

import { openai } from '@ai-sdk/openai';

import { z } from 'zod';

import Exa from 'exa-js';

export const exa = new Exa(process.env.EXA_API_KEY);

export const webSearch = tool({

  description: 'Search the web for up-to-date information',

  inputSchema: z.object({

    query: z.string().min(1).max(100).describe('The search query'),

  }),

  execute: async ({ query }) => {

    const { results } = await exa.searchAndContents(query, {

      livecrawl: 'always',

      numResults: 3,

    });

    return results.map(result => ({

      title: result.title,

      url: result.url,

      content: result.text.slice(0, 1000), // take just the first 1000 characters

      publishedDate: result.publishedDate,

    }));

  },

});

const { text } = await generateText({

  model: openai('gpt-4o-mini'), // can be any model that supports tools

  prompt: 'What happened in San Francisco last week?',

  tools: {

    webSearch,

  },

  stopWhen: stepCountIs(5),

});
```

### [Firecrawl](https://ai-sdk.dev/cookbook/node/web-search-agent\#firecrawl)

[Firecrawl](https://firecrawl.dev/) provides an API for web scraping and crawling. Let's look at how you could implement a scraping tool using Firecrawl:

```code-block_code__yIKW2

import { generateText, tool, stepCountIs } from 'ai';

import { openai } from '@ai-sdk/openai';

import { z } from 'zod';

import FirecrawlApp from '@mendable/firecrawl-js';

import 'dotenv/config';

const app = new FirecrawlApp({ apiKey: process.env.FIRECRAWL_API_KEY });

export const webSearch = tool({

  description: 'Search the web for up-to-date information',

  inputSchema: z.object({

    urlToCrawl: z

      .string()

      .url()

      .min(1)

      .max(100)

      .describe('The URL to crawl (including http:// or https://)'),

  }),

  execute: async ({ urlToCrawl }) => {

    const crawlResponse = await app.crawlUrl(urlToCrawl, {

      limit: 1,

      scrapeOptions: {

        formats: ['markdown', 'html'],

      },

    });

    if (!crawlResponse.success) {

      throw new Error(`Failed to crawl: ${crawlResponse.error}`);

    }

    return crawlResponse.data;

  },

});

const main = async () => {

  const { text } = await generateText({

    model: openai('gpt-4o-mini'), // can be any model that supports tools

    prompt: 'Get the latest blog post from vercel.com/blog',

    tools: {

      webSearch,

    },

    stopWhen: stepCountIs(5),

  });

  console.log(text);

};

main();
```

On this page

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent#web-search-agent)

[Using native web-search](https://ai-sdk.dev/cookbook/node/web-search-agent#using-native-web-search)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/node/web-search-agent#openai-responses-api)

[Perplexity](https://ai-sdk.dev/cookbook/node/web-search-agent#perplexity)

[Gemini](https://ai-sdk.dev/cookbook/node/web-search-agent#gemini)

[Building a web search tool](https://ai-sdk.dev/cookbook/node/web-search-agent#building-a-web-search-tool)

[Exa](https://ai-sdk.dev/cookbook/node/web-search-agent#exa)

[Firecrawl](https://ai-sdk.dev/cookbook/node/web-search-agent#firecrawl)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Amazon Nova Lite
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonNova Lite

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Nova Lite

A very low cost multimodal model that is lightning fast for processing image, video, and text inputs.

Context

300,000 tokens

Input Pricing

$0.06 / million tokens

Output Pricing

$0.24 / million tokens

[Model Page](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/ai/generative-ai/nova)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Chatbot Tool Usage
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#chatbot-tool-usage)

With [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat) and [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text), you can use tools in your chatbot application.
The AI SDK supports three types of tools in this context:

1. Automatically executed server-side tools
2. Automatically executed client-side tools
3. Tools that require user interaction, such as confirmation dialogs

The flow is as follows:

1. The user enters a message in the chat UI.
2. The message is sent to the API route.
3. In your server side route, the language model generates tool calls during the `streamText` call.
4. All tool calls are forwarded to the client.
5. Server-side tools are executed using their `execute` method and their results are forwarded to the client.
6. Client-side tools that should be automatically executed are handled with the `onToolCall` callback.
You must call `addToolResult` to provide the tool result.
7. Client-side tool that require user interactions can be displayed in the UI.
The tool calls and results are available as tool invocation parts in the `parts` property of the last assistant message.
8. When the user interaction is done, `addToolResult` can be used to add the tool result to the chat.
9. The chat can be configured to automatically submit when all tool results are available using `sendAutomaticallyWhen`.
This triggers another iteration of this flow.

The tool calls and tool executions are integrated into the assistant message as typed tool parts.
A tool part is at first a tool call, and then it becomes a tool result when the tool is executed.
The tool result contains all information about the tool call as well as the result of the tool execution.

Tool result submission can be configured using the `sendAutomaticallyWhen`
option. You can use the `lastAssistantMessageIsCompleteWithToolCalls` helper
to automatically submit when all tool results are available. This simplifies
the client-side code while still allowing full control when needed.

## [Example](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#example)

In this example, we'll use three tools:

- `getWeatherInformation`: An automatically executed server-side tool that returns the weather in a given city.
- `askForConfirmation`: A user-interaction client-side tool that asks the user for confirmation.
- `getLocation`: An automatically executed client-side tool that returns a random city.

### [API route](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#api-route)

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText, UIMessage } from 'ai';

import { z } from 'zod';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

    tools: {

      // server-side tool with execute function:

      getWeatherInformation: {

        description: 'show the weather in a given city to the user',

        inputSchema: z.object({ city: z.string() }),

        execute: async ({}: { city: string }) => {

          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];

          return weatherOptions[\
\
            Math.floor(Math.random() * weatherOptions.length)\
\
          ];

        },

      },

      // client-side tool that starts user interaction:

      askForConfirmation: {

        description: 'Ask the user for confirmation.',

        inputSchema: z.object({

          message: z.string().describe('The message to ask for confirmation.'),

        }),

      },

      // client-side tool that is automatically executed on the client:

      getLocation: {

        description:

          'Get the user location. Always ask for confirmation before using this tool.',

        inputSchema: z.object({}),

      },

    },

  });

  return result.toUIMessageStreamResponse();

}
```

### [Client-side page](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#client-side-page)

The client-side page uses the `useChat` hook to create a chatbot application with real-time message streaming.
Tool calls are displayed in the chat UI as typed tool parts.
Please make sure to render the messages using the `parts` property of the message.

There are three things worth mentioning:

1. The [`onToolCall`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#on-tool-call) callback is used to handle client-side tools that should be automatically executed.
In this example, the `getLocation` tool is a client-side tool that returns a random city.
You call `addToolResult` to provide the result (without `await` to avoid potential deadlocks).

2. The [`sendAutomaticallyWhen`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#send-automatically-when) option with `lastAssistantMessageIsCompleteWithToolCalls` helper automatically submits when all tool results are available.

3. The `parts` array of assistant messages contains tool parts with typed names like `tool-askForConfirmation`.
The client-side tool `askForConfirmation` is displayed in the UI.
It asks the user for confirmation and displays the result once the user confirms or denies the execution.
The result is added to the chat using `addToolResult` with the `tool` parameter for type safety.


app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import {

  DefaultChatTransport,

  lastAssistantMessageIsCompleteWithToolCalls,

} from 'ai';

import { useState } from 'react';

export default function Chat() {

  const { messages, sendMessage, addToolResult } = useChat({

    transport: new DefaultChatTransport({

      api: '/api/chat',

    }),

    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,

    // run client-side tools that are automatically executed:

    async onToolCall({ toolCall }) {

      if (toolCall.toolName === 'getLocation') {

        const cities = ['New York', 'Los Angeles', 'Chicago', 'San Francisco'];

        // No await - avoids potential deadlocks

        addToolResult({

          tool: 'getLocation',

          toolCallId: toolCall.toolCallId,

          output: cities[Math.floor(Math.random() * cities.length)],

        });

      }

    },

  });

  const [input, setInput] = useState('');

  return (

    <>

      {messages?.map(message => (

        <div key={message.id}>

          <strong>{`${message.role}: `}</strong>

          {message.parts.map(part => {

            switch (part.type) {

              // render text parts as simple text:

              case 'text':

                return part.text;

              // for tool parts, use the typed tool part names:

              case 'tool-askForConfirmation': {

                const callId = part.toolCallId;

                switch (part.state) {

                  case 'input-streaming':

                    return (

                      <div key={callId}>Loading confirmation request...</div>

                    );

                  case 'input-available':

                    return (

                      <div key={callId}>

                        {part.input.message}

                        <div>

                          <button

                            onClick={() =>

                              addToolResult({

                                tool: 'askForConfirmation',

                                toolCallId: callId,

                                output: 'Yes, confirmed.',

                              })

                            }

                          >

                            Yes

                          </button>

                          <button

                            onClick={() =>

                              addToolResult({

                                tool: 'askForConfirmation',

                                toolCallId: callId,

                                output: 'No, denied',

                              })

                            }

                          >

                            No

                          </button>

                        </div>

                      </div>

                    );

                  case 'output-available':

                    return (

                      <div key={callId}>

                        Location access allowed: {part.output}

                      </div>

                    );

                  case 'output-error':

                    return <div key={callId}>Error: {part.errorText}</div>;

                }

                break;

              }

              case 'tool-getLocation': {

                const callId = part.toolCallId;

                switch (part.state) {

                  case 'input-streaming':

                    return (

                      <div key={callId}>Preparing location request...</div>

                    );

                  case 'input-available':

                    return <div key={callId}>Getting location...</div>;

                  case 'output-available':

                    return <div key={callId}>Location: {part.output}</div>;

                  case 'output-error':

                    return (

                      <div key={callId}>

                        Error getting location: {part.errorText}

                      </div>

                    );

                }

                break;

              }

              case 'tool-getWeatherInformation': {

                const callId = part.toolCallId;

                switch (part.state) {

                  // example of pre-rendering streaming tool inputs:

                  case 'input-streaming':

                    return (

                      <pre key={callId}>{JSON.stringify(part, null, 2)}</pre>

                    );

                  case 'input-available':

                    return (

                      <div key={callId}>

                        Getting weather information for {part.input.city}...

                      </div>

                    );

                  case 'output-available':

                    return (

                      <div key={callId}>

                        Weather in {part.input.city}: {part.output}

                      </div>

                    );

                  case 'output-error':

                    return (

                      <div key={callId}>

                        Error getting weather for {part.input.city}:{' '}

                        {part.errorText}

                      </div>

                    );

                }

                break;

              }

            }

          })}

          <br />

        </div>

      ))}

      <form

        onSubmit={e => {

          e.preventDefault();

          if (input.trim()) {

            sendMessage({ text: input });

            setInput('');

          }

        }}

      >

        <input value={input} onChange={e => setInput(e.target.value)} />

      </form>

    </>

  );

}
```

## [Dynamic Tools](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#dynamic-tools)

When using dynamic tools (tools with unknown types at compile time), the UI parts use a generic `dynamic-tool` type instead of specific tool types:

app/page.tsx

```code-block_code__yIKW2

{

  message.parts.map((part, index) => {

    switch (part.type) {

      // Static tools with specific (`tool-${toolName}`) types

      case 'tool-getWeatherInformation':

        return <WeatherDisplay part={part} />;

      // Dynamic tools use generic `dynamic-tool` type

      case 'dynamic-tool':

        return (

          <div key={index}>

            <h4>Tool: {part.toolName}</h4>

            {part.state === 'input-streaming' && (

              <pre>{JSON.stringify(part.input, null, 2)}</pre>

            )}

            {part.state === 'output-available' && (

              <pre>{JSON.stringify(part.output, null, 2)}</pre>

            )}

            {part.state === 'output-error' && (

              <div>Error: {part.errorText}</div>

            )}

          </div>

        );

    }

  });

}
```

Dynamic tools are useful when integrating with:

- MCP (Model Context Protocol) tools without schemas
- User-defined functions loaded at runtime
- External tool providers

## [Tool call streaming](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#tool-call-streaming)

Tool call streaming is **enabled by default** in AI SDK 5.0, allowing you to stream tool calls while they are being generated. This provides a better user experience by showing tool inputs as they are generated in real-time.

app/api/chat/route.ts

```code-block_code__yIKW2

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

    // toolCallStreaming is enabled by default in v5

    // ...

  });

  return result.toUIMessageStreamResponse();

}
```

With tool call streaming enabled, partial tool calls are streamed as part of the data stream.
They are available through the `useChat` hook.
The typed tool parts of assistant messages will also contain partial tool calls.
You can use the `state` property of the tool part to render the correct UI.

app/page.tsx

```code-block_code__yIKW2

export default function Chat() {

  // ...

  return (

    <>

      {messages?.map(message => (

        <div key={message.id}>

          {message.parts.map(part => {

            switch (part.type) {

              case 'tool-askForConfirmation':

              case 'tool-getLocation':

              case 'tool-getWeatherInformation':

                switch (part.state) {

                  case 'input-streaming':

                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;

                  case 'input-available':

                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;

                  case 'output-available':

                    return <pre>{JSON.stringify(part.output, null, 2)}</pre>;

                  case 'output-error':

                    return <div>Error: {part.errorText}</div>;

                }

            }

          })}

        </div>

      ))}

    </>

  );

}
```

## [Step start parts](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#step-start-parts)

When you are using multi-step tool calls, the AI SDK will add step start parts to the assistant messages.
If you want to display boundaries between tool calls, you can use the `step-start` parts as follows:

app/page.tsx

```code-block_code__yIKW2

// ...

// where you render the message parts:

message.parts.map((part, index) => {

  switch (part.type) {

    case 'step-start':

      // show step boundaries as horizontal lines:

      return index > 0 ? (

        <div key={index} className="text-gray-500">

          <hr className="my-2 border-gray-300" />

        </div>

      ) : null;

    case 'text':

    // ...

    case 'tool-askForConfirmation':

    case 'tool-getLocation':

    case 'tool-getWeatherInformation':

    // ...

  }

});

// ...
```

## [Server-side Multi-Step Calls](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#server-side-multi-step-calls)

You can also use multi-step calls on the server-side with `streamText`.
This works when all invoked tools have an `execute` function on the server side.

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { convertToModelMessages, streamText, UIMessage, stepCountIs } from 'ai';

import { z } from 'zod';

export async function POST(req: Request) {

  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({

    model: openai('gpt-4o'),

    messages: convertToModelMessages(messages),

    tools: {

      getWeatherInformation: {

        description: 'show the weather in a given city to the user',

        inputSchema: z.object({ city: z.string() }),

        // tool has execute function:

        execute: async ({}: { city: string }) => {

          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];

          return weatherOptions[\
\
            Math.floor(Math.random() * weatherOptions.length)\
\
          ];

        },

      },

    },

    stopWhen: stepCountIs(5),

  });

  return result.toUIMessageStreamResponse();

}
```

## [Errors](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage\#errors)

Language models can make errors when calling tools.
By default, these errors are masked for security reasons, and show up as "An error occurred" in the UI.

To surface the errors, you can use the `onError` function when calling `toUIMessageResponse`.

```code-block_code__yIKW2

export function errorHandler(error: unknown) {

  if (error == null) {

    return 'unknown error';

  }

  if (typeof error === 'string') {

    return error;

  }

  if (error instanceof Error) {

    return error.message;

  }

  return JSON.stringify(error);

}
```

```code-block_code__yIKW2

const result = streamText({

  // ...

});

return result.toUIMessageStreamResponse({

  onError: errorHandler,

});
```

In case you are using `createUIMessageResponse`, you can use the `onError` function when calling `toUIMessageResponse`:

```code-block_code__yIKW2

const response = createUIMessageResponse({

  // ...

  async execute(dataStream) {

    // ...

  },

  onError: error => `Custom error: ${error.message}`,

});
```

On this page

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#chatbot-tool-usage)

[Example](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#example)

[API route](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#api-route)

[Client-side page](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#client-side-page)

[Dynamic Tools](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#dynamic-tools)

[Tool call streaming](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#tool-call-streaming)

[Step start parts](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#step-start-parts)

[Server-side Multi-Step Calls](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#server-side-multi-step-calls)

[Errors](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage#errors)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK RSC Overview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Overview](https://ai-sdk.dev/docs/ai-sdk-rsc/overview)

[Streaming React Components](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-react-components)

[Managing Generative UI State](https://ai-sdk.dev/docs/ai-sdk-rsc/generative-ui-state)

[Saving and Restoring States](https://ai-sdk.dev/docs/ai-sdk-rsc/saving-and-restoring-states)

[Multistep Interfaces](https://ai-sdk.dev/docs/ai-sdk-rsc/multistep-interfaces)

[Streaming Values](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-values)

[Handling Loading State](https://ai-sdk.dev/docs/ai-sdk-rsc/loading-state)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling)

[Handling Authentication](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication)

[Migrating from RSC to UI](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

AI SDK RSC

Copy markdown

# [AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc\#ai-sdk-rsc)

AI SDK RSC is currently experimental. We recommend using [AI SDK\\
UI](https://ai-sdk.dev/docs/ai-sdk-ui/overview) for production. For guidance on migrating from
RSC to UI, see our [migration guide](https://ai-sdk.dev/docs/ai-sdk-rsc/migrating-to-ui).

[Overview\\
\\
Learn about AI SDK RSC.](https://ai-sdk.dev/docs/ai-sdk-rsc/overview) [Streaming React Components\\
\\
Learn how to stream React components.](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-react-components) [Managing Generative UI State\\
\\
Learn how to manage generative UI state.](https://ai-sdk.dev/docs/ai-sdk-rsc/generative-ui-state) [Saving and Restoring States\\
\\
Learn how to save and restore states.](https://ai-sdk.dev/docs/ai-sdk-rsc/saving-and-restoring-states) [Multi-step Interfaces\\
\\
Learn how to build multi-step interfaces.](https://ai-sdk.dev/docs/ai-sdk-rsc/multistep-interfaces) [Streaming Values\\
\\
Learn how to stream values with AI SDK RSC.](https://ai-sdk.dev/docs/ai-sdk-rsc/streaming-values) [Error Handling\\
\\
Learn how to handle errors.](https://ai-sdk.dev/docs/ai-sdk-rsc/error-handling) [Authentication\\
\\
Learn how to authenticate users.](https://ai-sdk.dev/docs/ai-sdk-rsc/authentication)

On this page

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc#ai-sdk-rsc)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Prompts
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Prompts](https://ai-sdk.dev/docs/foundations/prompts\#prompts)

Prompts are instructions that you give a [large language model (LLM)](https://ai-sdk.dev/docs/foundations/overview#large-language-models) to tell it what to do.
It's like when you ask someone for directions; the clearer your question, the better the directions you'll get.

Many LLM providers offer complex interfaces for specifying prompts. They involve different roles and message types.
While these interfaces are powerful, they can be hard to use and understand.

In order to simplify prompting, the AI SDK supports text, message, and system prompts.

## [Text Prompts](https://ai-sdk.dev/docs/foundations/prompts\#text-prompts)

Text prompts are strings.
They are ideal for simple generation use cases,
e.g. repeatedly generating content for variants of the same prompt text.

You can set text prompts using the `prompt` property made available by AI SDK functions like [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) or [`generateObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object).
You can structure the text in any way and inject variables, e.g. using a template literal.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  prompt: 'Invent a new holiday and describe its traditions.',

});
```

You can also use template literals to provide dynamic data to your prompt.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  prompt:

    `I am planning a trip to ${destination} for ${lengthOfStay} days. ` +

    `Please suggest the best tourist activities for me to do.`,

});
```

## [System Prompts](https://ai-sdk.dev/docs/foundations/prompts\#system-prompts)

System prompts are the initial set of instructions given to models that help guide and constrain the models' behaviors and responses.
You can set system prompts using the `system` property.
System prompts work with both the `prompt` and the `messages` properties.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  system:

    `You help planning travel itineraries. ` +

    `Respond to the users' request with a list ` +

    `of the best stops to make in their destination.`,

  prompt:

    `I am planning a trip to ${destination} for ${lengthOfStay} days. ` +

    `Please suggest the best tourist activities for me to do.`,

});
```

When you use a message prompt, you can also use system messages instead of a
system prompt.

## [Message Prompts](https://ai-sdk.dev/docs/foundations/prompts\#message-prompts)

A message prompt is an array of user, assistant, and tool messages.
They are great for chat interfaces and more complex, multi-modal prompts.
You can use the `messages` property to set message prompts.

Each message has a `role` and a `content` property. The content can either be text (for user and assistant messages), or an array of relevant parts (data) for that message type.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'user', content: 'Hi!' },\
\
    { role: 'assistant', content: 'Hello, how can I help?' },\
\
    { role: 'user', content: 'Where can I buy the best Currywurst in Berlin?' },\
\
  ],

});
```

Instead of sending a text in the `content` property, you can send an array of parts that includes a mix of text and other content parts.

Not all language models support all message and content types. For example,
some models might not be capable of handling multi-modal inputs or tool
messages. [Learn more about the capabilities of select\\
models](https://ai-sdk.dev/docs/foundations/providers-and-models#model-capabilities).

### [Provider Options](https://ai-sdk.dev/docs/foundations/prompts\#provider-options)

You can pass through additional provider-specific metadata to enable provider-specific functionality at 3 levels.

#### [Function Call Level](https://ai-sdk.dev/docs/foundations/prompts\#function-call-level)

Functions like [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text#provider-options) or [`generateText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text#provider-options) accept a `providerOptions` property.

Adding provider options at the function call level should be used when you do not need granular control over where the provider options are applied.

```code-block_code__yIKW2

const { text } = await generateText({

  model: azure('your-deployment-name'),

  providerOptions: {

    openai: {

      reasoningEffort: 'low',

    },

  },

});
```

#### [Message Level](https://ai-sdk.dev/docs/foundations/prompts\#message-level)

For granular control over applying provider options at the message level, you can pass `providerOptions` to the message object:

```code-block_code__yIKW2

import { ModelMessage } from 'ai';

const messages: ModelMessage[] = [\
\
  {\
\
    role: 'system',\
\
    content: 'Cached system message',\
\
    providerOptions: {\
\
      // Sets a cache control breakpoint on the system message\
\
      anthropic: { cacheControl: { type: 'ephemeral' } },\
\
    },\
\
  },\
\
];
```

#### [Message Part Level](https://ai-sdk.dev/docs/foundations/prompts\#message-part-level)

Certain provider-specific options require configuration at the message part level:

```code-block_code__yIKW2

import { ModelMessage } from 'ai';

const messages: ModelMessage[] = [\
\
  {\
\
    role: 'user',\
\
    content: [\
\
      {\
\
        type: 'text',\
\
        text: 'Describe the image in detail.',\
\
        providerOptions: {\
\
          openai: { imageDetail: 'low' },\
\
        },\
\
      },\
\
      {\
\
        type: 'image',\
\
        image:\
\
          'https://github.com/vercel/ai/blob/main/examples/ai-core/data/comic-cat.png?raw=true',\
\
        // Sets image detail configuration for image part:\
\
        providerOptions: {\
\
          openai: { imageDetail: 'low' },\
\
        },\
\
      },\
\
    ],\
\
  },\
\
];
```

AI SDK UI hooks like [`useChat`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat) return
arrays of `UIMessage` objects, which do not support provider options. We
recommend using the
[`convertToModelMessages`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/convert-to-core-messages)
function to convert `UIMessage` objects to
[`ModelMessage`](https://ai-sdk.dev/docs/reference/ai-sdk-core/model-message) objects before
applying or appending message(s) or message parts with `providerOptions`.

### [User Messages](https://ai-sdk.dev/docs/foundations/prompts\#user-messages)

#### [Text Parts](https://ai-sdk.dev/docs/foundations/prompts\#text-parts)

Text content is the most common type of content. It is a string that is passed to the model.

If you only need to send text content in a message, the `content` property can be a string,
but you can also use it to send multiple content parts.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'Where can I buy the best Currywurst in Berlin?',\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

#### [Image Parts](https://ai-sdk.dev/docs/foundations/prompts\#image-parts)

User messages can include image parts. An image can be one of the following:

- base64-encoded image:
  - `string` with base-64 encoded content
  - data URL `string`, e.g. `data:image/png;base64,...`
- binary image:
  - `ArrayBuffer`
  - `Uint8Array`
  - `Buffer`
- URL:
  - http(s) URL `string`, e.g. `https://example.com/image.png`
  - `URL` object, e.g. `new URL('https://example.com/image.png')`

##### [Example: Binary image (Buffer)](https://ai-sdk.dev/docs/foundations/prompts\#example-binary-image-buffer)

```code-block_code__yIKW2

const result = await generateText({

  model,

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'Describe the image in detail.' },\
\
        {\
\
          type: 'image',\
\
          image: fs.readFileSync('./data/comic-cat.png'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

##### [Example: Base-64 encoded image (string)](https://ai-sdk.dev/docs/foundations/prompts\#example-base-64-encoded-image-string)

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'Describe the image in detail.' },\
\
        {\
\
          type: 'image',\
\
          image: fs.readFileSync('./data/comic-cat.png').toString('base64'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

##### [Example: Image URL (string)](https://ai-sdk.dev/docs/foundations/prompts\#example-image-url-string)

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'Describe the image in detail.' },\
\
        {\
\
          type: 'image',\
\
          image:\
\
            'https://github.com/vercel/ai/blob/main/examples/ai-core/data/comic-cat.png?raw=true',\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

#### [File Parts](https://ai-sdk.dev/docs/foundations/prompts\#file-parts)

Only a few providers and models currently support file parts: [Google\\
Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai), [Google\\
Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex),
[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai) (for `wav` and `mp3` audio with
`gpt-4o-audio-preview`), [Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic),
[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai) (for `pdf`).

User messages can include file parts. A file can be one of the following:

- base64-encoded file:
  - `string` with base-64 encoded content
  - data URL `string`, e.g. `data:image/png;base64,...`
- binary data:
  - `ArrayBuffer`
  - `Uint8Array`
  - `Buffer`
- URL:
  - http(s) URL `string`, e.g. `https://example.com/some.pdf`
  - `URL` object, e.g. `new URL('https://example.com/some.pdf')`

You need to specify the MIME type of the file you are sending.

##### [Example: PDF file from Buffer](https://ai-sdk.dev/docs/foundations/prompts\#example-pdf-file-from-buffer)

```code-block_code__yIKW2

import { google } from '@ai-sdk/google';

import { generateText } from 'ai';

const result = await generateText({

  model: google('gemini-1.5-flash'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'What is the file about?' },\
\
        {\
\
          type: 'file',\
\
          mediaType: 'application/pdf',\
\
          data: fs.readFileSync('./data/example.pdf'),\
\
          filename: 'example.pdf', // optional, not used by all providers\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

##### [Example: mp3 audio file from Buffer](https://ai-sdk.dev/docs/foundations/prompts\#example-mp3-audio-file-from-buffer)

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText } from 'ai';

const result = await generateText({

  model: openai('gpt-4o-audio-preview'),

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        { type: 'text', text: 'What is the audio saying?' },\
\
        {\
\
          type: 'file',\
\
          mediaType: 'audio/mpeg',\
\
          data: fs.readFileSync('./data/galileo.mp3'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

### [Assistant Messages](https://ai-sdk.dev/docs/foundations/prompts\#assistant-messages)

Assistant messages are messages that have a role of `assistant`.
They are typically previous responses from the assistant
and can contain text, reasoning, and tool call parts.

#### [Example: Assistant message with text content](https://ai-sdk.dev/docs/foundations/prompts\#example-assistant-message-with-text-content)

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'user', content: 'Hi!' },\
\
    { role: 'assistant', content: 'Hello, how can I help?' },\
\
  ],

});
```

#### [Example: Assistant message with text content in array](https://ai-sdk.dev/docs/foundations/prompts\#example-assistant-message-with-text-content-in-array)

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'user', content: 'Hi!' },\
\
    {\
\
      role: 'assistant',\
\
      content: [{ type: 'text', text: 'Hello, how can I help?' }],\
\
    },\
\
  ],

});
```

#### [Example: Assistant message with tool call content](https://ai-sdk.dev/docs/foundations/prompts\#example-assistant-message-with-tool-call-content)

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'user', content: 'How many calories are in this block of cheese?' },\
\
    {\
\
      role: 'assistant',\
\
      content: [\
\
        {\
\
          type: 'tool-call',\
\
          toolCallId: '12345',\
\
          toolName: 'get-nutrition-data',\
\
          input: { cheese: 'Roquefort' },\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

#### [Example: Assistant message with file content](https://ai-sdk.dev/docs/foundations/prompts\#example-assistant-message-with-file-content)

This content part is for model-generated files. Only a few models support
this, and only for file types that they can generate.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'user', content: 'Generate an image of a roquefort cheese!' },\
\
    {\
\
      role: 'assistant',\
\
      content: [\
\
        {\
\
          type: 'file',\
\
          mediaType: 'image/png',\
\
          data: fs.readFileSync('./data/roquefort.jpg'),\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

### [Tool messages](https://ai-sdk.dev/docs/foundations/prompts\#tool-messages)

[Tools](https://ai-sdk.dev/docs/foundations/tools) (also known as function calling) are programs
that you can provide an LLM to extend its built-in functionality. This can be
anything from calling an external API to calling functions within your UI.
Learn more about Tools in [the next section](https://ai-sdk.dev/docs/foundations/tools).

For models that support [tool](https://ai-sdk.dev/docs/foundations/tools) calls, assistant messages can contain tool call parts, and tool messages can contain tool output parts.
A single assistant message can call multiple tools, and a single tool message can contain multiple tool results.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    {\
\
      role: 'user',\
\
      content: [\
\
        {\
\
          type: 'text',\
\
          text: 'How many calories are in this block of cheese?',\
\
        },\
\
        { type: 'image', image: fs.readFileSync('./data/roquefort.jpg') },\
\
      ],\
\
    },\
\
    {\
\
      role: 'assistant',\
\
      content: [\
\
        {\
\
          type: 'tool-call',\
\
          toolCallId: '12345',\
\
          toolName: 'get-nutrition-data',\
\
          input: { cheese: 'Roquefort' },\
\
        },\
\
        // there could be more tool calls here (parallel calling)\
\
      ],\
\
    },\
\
    {\
\
      role: 'tool',\
\
      content: [\
\
        {\
\
          type: 'tool-result',\
\
          toolCallId: '12345', // needs to match the tool call id\
\
          toolName: 'get-nutrition-data',\
\
          output: {\
\
            type: 'json',\
\
            value: {\
\
              name: 'Cheese, roquefort',\
\
              calories: 369,\
\
              fat: 31,\
\
              protein: 22,\
\
            },\
\
          },\
\
        },\
\
        // there could be more tool results here (parallel calling)\
\
      ],\
\
    },\
\
  ],

});
```

#### [Multi-modal Tool Results](https://ai-sdk.dev/docs/foundations/prompts\#multi-modal-tool-results)

Multi-part tool results are experimental and only supported by Anthropic.

Tool results can be multi-part and multi-modal, e.g. a text and an image.
You can use the `experimental_content` property on tool parts to specify multi-part tool results.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    // ...\
\
    {\
\
      role: 'tool',\
\
      content: [\
\
        {\
\
          type: 'tool-result',\
\
          toolCallId: '12345', // needs to match the tool call id\
\
          toolName: 'get-nutrition-data',\
\
          // for models that do not support multi-part tool results,\
\
          // you can include a regular output part:\
\
          output: {\
\
            type: 'json',\
\
            value: {\
\
              name: 'Cheese, roquefort',\
\
              calories: 369,\
\
              fat: 31,\
\
              protein: 22,\
\
            },\
\
          },\
\
        },\
\
        {\
\
          type: 'tool-result',\
\
          toolCallId: '12345', // needs to match the tool call id\
\
          toolName: 'get-nutrition-data',\
\
          // for models that support multi-part tool results,\
\
          // you can include a multi-part content part:\
\
          output: {\
\
            type: 'content',\
\
            value: [\
\
              {\
\
                type: 'text',\
\
                text: 'Here is an image of the nutrition data for the cheese:',\
\
              },\
\
              {\
\
                type: 'media',\
\
                data: fs\
\
                  .readFileSync('./data/roquefort-nutrition-data.png')\
\
                  .toString('base64'),\
\
                mediaType: 'image/png',\
\
              },\
\
            ],\
\
          },\
\
        },\
\
      ],\
\
    },\
\
  ],

});
```

### [System Messages](https://ai-sdk.dev/docs/foundations/prompts\#system-messages)

System messages are messages that are sent to the model before the user messages to guide the assistant's behavior.
You can alternatively use the `system` property.

```code-block_code__yIKW2

const result = await generateText({

  model: 'openai/gpt-4.1',

  messages: [\
\
    { role: 'system', content: 'You help planning travel itineraries.' },\
\
    {\
\
      role: 'user',\
\
      content:\
\
        'I am planning a trip to Berlin for 3 days. Please suggest the best tourist activities for me to do.',\
\
    },\
\
  ],

});
```

On this page

[Prompts](https://ai-sdk.dev/docs/foundations/prompts#prompts)

[Text Prompts](https://ai-sdk.dev/docs/foundations/prompts#text-prompts)

[System Prompts](https://ai-sdk.dev/docs/foundations/prompts#system-prompts)

[Message Prompts](https://ai-sdk.dev/docs/foundations/prompts#message-prompts)

[Provider Options](https://ai-sdk.dev/docs/foundations/prompts#provider-options)

[Function Call Level](https://ai-sdk.dev/docs/foundations/prompts#function-call-level)

[Message Level](https://ai-sdk.dev/docs/foundations/prompts#message-level)

[Message Part Level](https://ai-sdk.dev/docs/foundations/prompts#message-part-level)

[User Messages](https://ai-sdk.dev/docs/foundations/prompts#user-messages)

[Text Parts](https://ai-sdk.dev/docs/foundations/prompts#text-parts)

[Image Parts](https://ai-sdk.dev/docs/foundations/prompts#image-parts)

[Example: Binary image (Buffer)](https://ai-sdk.dev/docs/foundations/prompts#example-binary-image-buffer)

[Example: Base-64 encoded image (string)](https://ai-sdk.dev/docs/foundations/prompts#example-base-64-encoded-image-string)

[Example: Image URL (string)](https://ai-sdk.dev/docs/foundations/prompts#example-image-url-string)

[File Parts](https://ai-sdk.dev/docs/foundations/prompts#file-parts)

[Example: PDF file from Buffer](https://ai-sdk.dev/docs/foundations/prompts#example-pdf-file-from-buffer)

[Example: mp3 audio file from Buffer](https://ai-sdk.dev/docs/foundations/prompts#example-mp3-audio-file-from-buffer)

[Assistant Messages](https://ai-sdk.dev/docs/foundations/prompts#assistant-messages)

[Example: Assistant message with text content](https://ai-sdk.dev/docs/foundations/prompts#example-assistant-message-with-text-content)

[Example: Assistant message with text content in array](https://ai-sdk.dev/docs/foundations/prompts#example-assistant-message-with-text-content-in-array)

[Example: Assistant message with tool call content](https://ai-sdk.dev/docs/foundations/prompts#example-assistant-message-with-tool-call-content)

[Example: Assistant message with file content](https://ai-sdk.dev/docs/foundations/prompts#example-assistant-message-with-file-content)

[Tool messages](https://ai-sdk.dev/docs/foundations/prompts#tool-messages)

[Multi-modal Tool Results](https://ai-sdk.dev/docs/foundations/prompts#multi-modal-tool-results)

[System Messages](https://ai-sdk.dev/docs/foundations/prompts#system-messages)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## CohereCommand Nightly
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fcohere.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)CohereCommand Nightly

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fcohere.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Cohere/Command Nightly

An instruction-following conversational model by Cohere that performs language tasks with high quality and reliability while providing longer context compared to generative models.

Context

4,096 tokens

[Model Page](https://docs.cohere.com/docs/command-beta) [Pricing](https://cohere.com/pricing)

[Terms](https://cohere.com/terms-of-use) [Privacy](https://cohere.com/privacy) [Website](https://cohere.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AI SDK Tools
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Tools](https://ai-sdk.dev/docs/foundations/tools\#tools)

While [large language models (LLMs)](https://ai-sdk.dev/docs/foundations/overview#large-language-models) have incredible generation capabilities,
they struggle with discrete tasks (e.g. mathematics) and interacting with the outside world (e.g. getting the weather).

Tools are actions that an LLM can invoke.
The results of these actions can be reported back to the LLM to be considered in the next response.

For example, when you ask an LLM for the "weather in London", and there is a weather tool available, it could call a tool
with London as the argument. The tool would then fetch the weather data and return it to the LLM. The LLM can then use this
information in its response.

## [What is a tool?](https://ai-sdk.dev/docs/foundations/tools\#what-is-a-tool)

A tool is an object that can be called by the model to perform a specific task.
You can use tools with [`generateText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text)
and [`streamText`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) by passing one or more tools to the `tools` parameter.

A tool consists of three properties:

- **`description`**: An optional description of the tool that can influence when the tool is picked.
- **`inputSchema`**: A [Zod schema](https://ai-sdk.dev/docs/foundations/tools#schema-specification-and-validation-with-zod) or a [JSON schema](https://ai-sdk.dev/docs/reference/ai-sdk-core/json-schema) that defines the input required for the tool to run. The schema is consumed by the LLM, and also used to validate the LLM tool calls.
- **`execute`**: An optional async function that is called with the arguments from the tool call.

`streamUI` uses UI generator tools with a `generate` function that can return
React components.

If the LLM decides to use a tool, it will generate a tool call.
Tools with an `execute` function are run automatically when these calls are generated.
The output of the tool calls are returned using tool result objects.

You can automatically pass tool results back to the LLM
using [multi-step calls](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling#multi-step-calls) with `streamText` and `generateText`.

## [Schemas](https://ai-sdk.dev/docs/foundations/tools\#schemas)

Schemas are used to define the parameters for tools and to validate the [tool calls](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling).

The AI SDK supports both raw JSON schemas (using the [`jsonSchema` function](https://ai-sdk.dev/docs/reference/ai-sdk-core/json-schema))
and [Zod](https://zod.dev/) schemas (either directly or using the [`zodSchema` function](https://ai-sdk.dev/docs/reference/ai-sdk-core/zod-schema)).

[Zod](https://zod.dev/) is a popular TypeScript schema validation library.
You can install it with:

pnpm

npm

yarn

bun

```
pnpm add zod
```

You can then specify a Zod schema, for example:

```code-block_code__yIKW2

import z from 'zod';

const recipeSchema = z.object({

  recipe: z.object({

    name: z.string(),

    ingredients: z.array(

      z.object({

        name: z.string(),

        amount: z.string(),

      }),

    ),

    steps: z.array(z.string()),

  }),

});
```

You can also use schemas for structured output generation with
[`generateObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object) and
[`streamObject`](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object).

## [Toolkits](https://ai-sdk.dev/docs/foundations/tools\#toolkits)

When you work with tools, you typically need a mix of application specific tools and general purpose tools.
There are several providers that offer pre-built tools as **toolkits** that you can use out of the box:

- **[agentic](https://github.com/transitive-bullshit/agentic)** \- A collection of 20+ tools. Most tools connect to access external APIs such as [Exa](https://exa.ai/) or [E2B](https://e2b.dev/).
- **[browserbase](https://docs.browserbase.com/integrations/vercel/introduction#vercel-ai-integration)** \- Browser tool that runs a headless browser
- **[browserless](https://docs.browserless.io/ai-integrations/vercel-ai-sdk)** \- Browser automation service with AI integration - self hosted or cloud based
- **[Smithery](https://smithery.ai/docs/use/connect)** \- Smithery provides an open marketplace of 6K+ MCPs, including [Browserbase](https://browserbase.com/) and [Exa](https://exa.ai/).
- **[Stripe agent tools](https://docs.stripe.com/agents)** \- Tools for interacting with Stripe.
- **[StackOne ToolSet](https://docs.stackone.com/agents)** \- Agentic integrations for hundreds of [enterprise SaaS](https://www.stackone.com/integrations)
- **[Toolhouse](https://docs.toolhouse.ai/toolhouse/using-vercel-ai)** \- AI function-calling in 3 lines of code for over 25 different actions.
- **[Agent Tools](https://ai-sdk-agents.vercel.app/?item=introduction)** \- A collection of tools for agents.
- **[AI Tool Maker](https://github.com/nihaocami/ai-tool-maker)** \- A CLI utility to generate AI SDK tools from OpenAPI specs.
- **[Composio](https://docs.composio.dev/javascript/vercel)** \- Composio provides 250+ tools like GitHub, Gmail, Salesforce and [more](https://composio.dev/tools).
- **[Interlify](https://www.interlify.com/docs/integrate-with-vercel-ai)** \- Convert APIs into tools so that AI can connect to your backend in minutes.
- **[Freestyle](https://docs.freestyle.sh/integrations/vercel)** \- Tool for your AI to execute JavaScript or TypeScript with arbitrary node modules.
- **[JigsawStack](http://www.jigsawstack.com/docs/integration/vercel)** \- JigsawStack provides over 30+ small custom fine tuned models available for specific uses.

Do you have open source tools or tool libraries that are compatible with the
AI SDK? Please [file a pull request](https://github.com/vercel/ai/pulls) to
add them to this list.

## [Learn more](https://ai-sdk.dev/docs/foundations/tools\#learn-more)

The AI SDK Core [Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)
and [Agents](https://ai-sdk.dev/docs/foundations/agents) documentation has more information about tools and tool calling.

On this page

[Tools](https://ai-sdk.dev/docs/foundations/tools#tools)

[What is a tool?](https://ai-sdk.dev/docs/foundations/tools#what-is-a-tool)

[Schemas](https://ai-sdk.dev/docs/foundations/tools#schemas)

[Toolkits](https://ai-sdk.dev/docs/foundations/tools#toolkits)

[Learn more](https://ai-sdk.dev/docs/foundations/tools#learn-more)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Agents Overview
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [Agents](https://ai-sdk.dev/docs/foundations/agents\#agents)

When building AI applications, you often need **systems that can understand context and take meaningful actions**. When building these systems, the key consideration is finding the right balance between flexibility and control. Let's explore different approaches and patterns for building these systems, with a focus on helping you match capabilities to your needs.

## [Building Blocks](https://ai-sdk.dev/docs/foundations/agents\#building-blocks)

When building AI systems, you can combine these fundamental components:

### [Single-Step LLM Generation](https://ai-sdk.dev/docs/foundations/agents\#single-step-llm-generation)

The basic building block - one call to an LLM to get a response. Useful for straightforward tasks like classification or text generation.

### [Tool Usage](https://ai-sdk.dev/docs/foundations/agents\#tool-usage)

Enhanced capabilities through tools (like calculators, APIs, or databases) that the LLM can use to accomplish tasks. Tools provide a controlled way to extend what the LLM can do.

When solving complex problems, **an LLM can make multiple tool calls across multiple steps without you explicitly specifying the order** \- for example, looking up information in a database, using that to make calculations, and then storing results. The AI SDK makes this [multi-step tool usage](https://ai-sdk.dev/docs/foundations/agents#multi-step-tool-usage) straightforward through the `stopWhen` parameter.

### [Multi-Agent Systems](https://ai-sdk.dev/docs/foundations/agents\#multi-agent-systems)

Multiple LLMs working together, each specialized for different aspects of a complex task. This enables sophisticated behaviors while keeping individual components focused.

## [Patterns](https://ai-sdk.dev/docs/foundations/agents\#patterns)

These building blocks can be combined with workflow patterns that help manage complexity:

- [Sequential Processing](https://ai-sdk.dev/docs/foundations/agents#sequential-processing-chains) \- Steps executed in order
- [Parallel Processing](https://ai-sdk.dev/docs/foundations/agents#parallel-processing) \- Independent tasks run simultaneously
- [Evaluation/Feedback Loops](https://ai-sdk.dev/docs/foundations/agents#evaluator-optimizer) \- Results checked and improved iteratively
- [Orchestration](https://ai-sdk.dev/docs/foundations/agents#orchestrator-worker) \- Coordinating multiple components
- [Routing](https://ai-sdk.dev/docs/foundations/agents#routing) \- Directing work based on context

## [Choosing Your Approach](https://ai-sdk.dev/docs/foundations/agents\#choosing-your-approach)

The key factors to consider:

- **Flexibility vs Control** \- How much freedom does the LLM need vs how tightly must you constrain its actions?
- **Error Tolerance** \- What are the consequences of mistakes in your use case?
- **Cost Considerations** \- More complex systems typically mean more LLM calls and higher costs
- **Maintenance** \- Simpler architectures are easier to debug and modify

**Start with the simplest approach that meets your needs**. Add complexity only when required by:

1. Breaking down tasks into clear steps
2. Adding tools for specific capabilities
3. Implementing feedback loops for quality control
4. Introducing multiple agents for complex workflows

Let's look at examples of these patterns in action.

## [Patterns with Examples](https://ai-sdk.dev/docs/foundations/agents\#patterns-with-examples)

The following patterns, adapted from [Anthropic's guide on building effective agents](https://www.anthropic.com/research/building-effective-agents), serve as building blocks that can be combined to create comprehensive workflows. Each pattern addresses specific aspects of task execution, and by combining them thoughtfully, you can build reliable solutions for complex problems.

### [Sequential Processing (Chains)](https://ai-sdk.dev/docs/foundations/agents\#sequential-processing-chains)

The simplest workflow pattern executes steps in a predefined order. Each step's output becomes input for the next step, creating a clear chain of operations. This pattern is ideal for tasks with well-defined sequences, like content generation pipelines or data transformation processes.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, generateObject } from 'ai';

import { z } from 'zod';

async function generateMarketingCopy(input: string) {

  const model = openai('gpt-4o');

  // First step: Generate marketing copy

  const { text: copy } = await generateText({

    model,

    prompt: `Write persuasive marketing copy for: ${input}. Focus on benefits and emotional appeal.`,

  });

  // Perform quality check on copy

  const { object: qualityMetrics } = await generateObject({

    model,

    schema: z.object({

      hasCallToAction: z.boolean(),

      emotionalAppeal: z.number().min(1).max(10),

      clarity: z.number().min(1).max(10),

    }),

    prompt: `Evaluate this marketing copy for:

    1. Presence of call to action (true/false)

    2. Emotional appeal (1-10)

    3. Clarity (1-10)

    Copy to evaluate: ${copy}`,

  });

  // If quality check fails, regenerate with more specific instructions

  if (

    !qualityMetrics.hasCallToAction ||

    qualityMetrics.emotionalAppeal < 7 ||

    qualityMetrics.clarity < 7

  ) {

    const { text: improvedCopy } = await generateText({

      model,

      prompt: `Rewrite this marketing copy with:

      ${!qualityMetrics.hasCallToAction ? '- A clear call to action' : ''}

      ${qualityMetrics.emotionalAppeal < 7 ? '- Stronger emotional appeal' : ''}

      ${qualityMetrics.clarity < 7 ? '- Improved clarity and directness' : ''}

      Original copy: ${copy}`,

    });

    return { copy: improvedCopy, qualityMetrics };

  }

  return { copy, qualityMetrics };

}
```

### [Routing](https://ai-sdk.dev/docs/foundations/agents\#routing)

This pattern allows the model to make decisions about which path to take through a workflow based on context and intermediate results. The model acts as an intelligent router, directing the flow of execution between different branches of your workflow. This is particularly useful when handling varied inputs that require different processing approaches. In the example below, the results of the first LLM call change the properties of the second LLM call like model size and system prompt.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateObject, generateText } from 'ai';

import { z } from 'zod';

async function handleCustomerQuery(query: string) {

  const model = openai('gpt-4o');

  // First step: Classify the query type

  const { object: classification } = await generateObject({

    model,

    schema: z.object({

      reasoning: z.string(),

      type: z.enum(['general', 'refund', 'technical']),

      complexity: z.enum(['simple', 'complex']),

    }),

    prompt: `Classify this customer query:

    ${query}

    Determine:

    1. Query type (general, refund, or technical)

    2. Complexity (simple or complex)

    3. Brief reasoning for classification`,

  });

  // Route based on classification

  // Set model and system prompt based on query type and complexity

  const { text: response } = await generateText({

    model:

      classification.complexity === 'simple'

        ? openai('gpt-4o-mini')

        : openai('o3-mini'),

    system: {

      general:

        'You are an expert customer service agent handling general inquiries.',

      refund:

        'You are a customer service agent specializing in refund requests. Follow company policy and collect necessary information.',

      technical:

        'You are a technical support specialist with deep product knowledge. Focus on clear step-by-step troubleshooting.',

    }[classification.type],

    prompt: query,

  });

  return { response, classification };

}
```

### [Parallel Processing](https://ai-sdk.dev/docs/foundations/agents\#parallel-processing)

Some tasks can be broken down into independent subtasks that can be executed simultaneously. This pattern takes advantage of parallel execution to improve efficiency while maintaining the benefits of structured workflows. For example, analyzing multiple documents or processing different aspects of a single input concurrently (like code review).

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, generateObject } from 'ai';

import { z } from 'zod';

// Example: Parallel code review with multiple specialized reviewers

async function parallelCodeReview(code: string) {

  const model = openai('gpt-4o');

  // Run parallel reviews

  const [securityReview, performanceReview, maintainabilityReview] =

    await Promise.all([\
\
      generateObject({\
\
        model,\
\
        system:\
\
          'You are an expert in code security. Focus on identifying security vulnerabilities, injection risks, and authentication issues.',\
\
        schema: z.object({\
\
          vulnerabilities: z.array(z.string()),\
\
          riskLevel: z.enum(['low', 'medium', 'high']),\
\
          suggestions: z.array(z.string()),\
\
        }),\
\
        prompt: `Review this code:\
\
      ${code}`,\
\
      }),\
\
      generateObject({\
\
        model,\
\
        system:\
\
          'You are an expert in code performance. Focus on identifying performance bottlenecks, memory leaks, and optimization opportunities.',\
\
        schema: z.object({\
\
          issues: z.array(z.string()),\
\
          impact: z.enum(['low', 'medium', 'high']),\
\
          optimizations: z.array(z.string()),\
\
        }),\
\
        prompt: `Review this code:\
\
      ${code}`,\
\
      }),\
\
      generateObject({\
\
        model,\
\
        system:\
\
          'You are an expert in code quality. Focus on code structure, readability, and adherence to best practices.',\
\
        schema: z.object({\
\
          concerns: z.array(z.string()),\
\
          qualityScore: z.number().min(1).max(10),\
\
          recommendations: z.array(z.string()),\
\
        }),\
\
        prompt: `Review this code:\
\
      ${code}`,\
\
      }),\
\
    ]);

  const reviews = [\
\
    { ...securityReview.object, type: 'security' },\
\
    { ...performanceReview.object, type: 'performance' },\
\
    { ...maintainabilityReview.object, type: 'maintainability' },\
\
  ];

  // Aggregate results using another model instance

  const { text: summary } = await generateText({

    model,

    system: 'You are a technical lead summarizing multiple code reviews.',

    prompt: `Synthesize these code review results into a concise summary with key actions:

    ${JSON.stringify(reviews, null, 2)}`,

  });

  return { reviews, summary };

}
```

### [Orchestrator-Worker](https://ai-sdk.dev/docs/foundations/agents\#orchestrator-worker)

In this pattern, a primary model (orchestrator) coordinates the execution of specialized workers. Each worker is optimized for a specific subtask, while the orchestrator maintains overall context and ensures coherent results. This pattern excels at complex tasks requiring different types of expertise or processing.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateObject } from 'ai';

import { z } from 'zod';

async function implementFeature(featureRequest: string) {

  // Orchestrator: Plan the implementation

  const { object: implementationPlan } = await generateObject({

    model: openai('o3-mini'),

    schema: z.object({

      files: z.array(

        z.object({

          purpose: z.string(),

          filePath: z.string(),

          changeType: z.enum(['create', 'modify', 'delete']),

        }),

      ),

      estimatedComplexity: z.enum(['low', 'medium', 'high']),

    }),

    system:

      'You are a senior software architect planning feature implementations.',

    prompt: `Analyze this feature request and create an implementation plan:

    ${featureRequest}`,

  });

  // Workers: Execute the planned changes

  const fileChanges = await Promise.all(

    implementationPlan.files.map(async file => {

      // Each worker is specialized for the type of change

      const workerSystemPrompt = {

        create:

          'You are an expert at implementing new files following best practices and project patterns.',

        modify:

          'You are an expert at modifying existing code while maintaining consistency and avoiding regressions.',

        delete:

          'You are an expert at safely removing code while ensuring no breaking changes.',

      }[file.changeType];

      const { object: change } = await generateObject({

        model: openai('gpt-4o'),

        schema: z.object({

          explanation: z.string(),

          code: z.string(),

        }),

        system: workerSystemPrompt,

        prompt: `Implement the changes for ${file.filePath} to support:

        ${file.purpose}

        Consider the overall feature context:

        ${featureRequest}`,

      });

      return {

        file,

        implementation: change,

      };

    }),

  );

  return {

    plan: implementationPlan,

    changes: fileChanges,

  };

}
```

### [Evaluator-Optimizer](https://ai-sdk.dev/docs/foundations/agents\#evaluator-optimizer)

This pattern introduces quality control into workflows by having dedicated evaluation steps that assess intermediate results. Based on the evaluation, the workflow can either proceed, retry with adjusted parameters, or take corrective action. This creates more robust workflows capable of self-improvement and error recovery.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, generateObject } from 'ai';

import { z } from 'zod';

async function translateWithFeedback(text: string, targetLanguage: string) {

  let currentTranslation = '';

  let iterations = 0;

  const MAX_ITERATIONS = 3;

  // Initial translation

  const { text: translation } = await generateText({

    model: openai('gpt-4o-mini'), // use small model for first attempt

    system: 'You are an expert literary translator.',

    prompt: `Translate this text to ${targetLanguage}, preserving tone and cultural nuances:

    ${text}`,

  });

  currentTranslation = translation;

  // Evaluation-optimization loop

  while (iterations < MAX_ITERATIONS) {

    // Evaluate current translation

    const { object: evaluation } = await generateObject({

      model: openai('gpt-4o'), // use a larger model to evaluate

      schema: z.object({

        qualityScore: z.number().min(1).max(10),

        preservesTone: z.boolean(),

        preservesNuance: z.boolean(),

        culturallyAccurate: z.boolean(),

        specificIssues: z.array(z.string()),

        improvementSuggestions: z.array(z.string()),

      }),

      system: 'You are an expert in evaluating literary translations.',

      prompt: `Evaluate this translation:

      Original: ${text}

      Translation: ${currentTranslation}

      Consider:

      1. Overall quality

      2. Preservation of tone

      3. Preservation of nuance

      4. Cultural accuracy`,

    });

    // Check if quality meets threshold

    if (

      evaluation.qualityScore >= 8 &&

      evaluation.preservesTone &&

      evaluation.preservesNuance &&

      evaluation.culturallyAccurate

    ) {

      break;

    }

    // Generate improved translation based on feedback

    const { text: improvedTranslation } = await generateText({

      model: openai('gpt-4o'), // use a larger model

      system: 'You are an expert literary translator.',

      prompt: `Improve this translation based on the following feedback:

      ${evaluation.specificIssues.join('\n')}

      ${evaluation.improvementSuggestions.join('\n')}

      Original: ${text}

      Current Translation: ${currentTranslation}`,

    });

    currentTranslation = improvedTranslation;

    iterations++;

  }

  return {

    finalTranslation: currentTranslation,

    iterationsRequired: iterations,

  };

}
```

## [Multi-Step Tool Usage](https://ai-sdk.dev/docs/foundations/agents\#multi-step-tool-usage)

If your use case involves solving problems where the solution path is poorly defined or too complex to map out as a workflow in advance, you may want to provide the LLM with a set of lower-level tools and allow it to break down the task into small pieces that it can solve on its own iteratively, without discrete instructions. To implement this kind of agentic pattern, you need to call an LLM in a loop until a task is complete. The AI SDK makes this simple with the `stopWhen` parameter.

The AI SDK gives you control over the stopping conditions, enabling you to keep the LLM running until one of the conditions are met. The SDK automatically triggers an additional request to the model after every tool result (each request is considered a "step"), continuing until the model does not generate a tool call or other stopping conditions (e.g. `stepCountIs`) you define are satisfied.

`stopWhen` can be used with both `generateText` and `streamText`

### [Using `stopWhen`](https://ai-sdk.dev/docs/foundations/agents\#using-stopwhen)

This example demonstrates how to create an agent that solves math problems.
It has a calculator tool (using [math.js](https://mathjs.org/)) that it can call to evaluate mathematical expressions.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, tool, stepCountIs } from 'ai';

import * as mathjs from 'mathjs';

import { z } from 'zod';

const { text: answer } = await generateText({

  model: openai('gpt-4o-2024-08-06'),

  tools: {

    calculate: tool({

      description:

        'A tool for evaluating mathematical expressions. ' +

        'Example expressions: ' +

        "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'.",

      inputSchema: z.object({ expression: z.string() }),

      execute: async ({ expression }) => mathjs.evaluate(expression),

    }),

  },

  stopWhen: stepCountIs(10),

  system:

    'You are solving math problems. ' +

    'Reason step by step. ' +

    'Use the calculator when necessary. ' +

    'When you give the final answer, ' +

    'provide an explanation for how you arrived at it.',

  prompt:

    'A taxi driver earns $9461 per 1-hour of work. ' +

    'If he works 12 hours a day and in 1 hour ' +

    'he uses 12 liters of petrol with a price  of $134 for 1 liter. ' +

    'How much money does he earn in one day?',

});

console.log(`ANSWER: ${answer}`);
```

### [Structured Answers](https://ai-sdk.dev/docs/foundations/agents\#structured-answers)

When building an agent for tasks like mathematical analysis or report generation, it's often useful to have the agent's final output structured in a consistent format that your application can process. You can use an **answer tool** and the `toolChoice: 'required'` setting to force the LLM to answer with a structured output that matches the schema of the answer tool. The answer tool has no `execute` function, so invoking it will terminate the agent.

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, tool, stepCountIs } from 'ai';

import 'dotenv/config';

import { z } from 'zod';

const { toolCalls } = await generateText({

  model: openai('gpt-4o-2024-08-06'),

  tools: {

    calculate: tool({

      description:

        'A tool for evaluating mathematical expressions. Example expressions: ' +

        "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'.",

      inputSchema: z.object({ expression: z.string() }),

      execute: async ({ expression }) => mathjs.evaluate(expression),

    }),

    // answer tool: the LLM will provide a structured answer

    answer: tool({

      description: 'A tool for providing the final answer.',

      inputSchema: z.object({

        steps: z.array(

          z.object({

            calculation: z.string(),

            reasoning: z.string(),

          }),

        ),

        answer: z.string(),

      }),

      // no execute function - invoking it will terminate the agent

    }),

  },

  toolChoice: 'required',

  stopWhen: stepCountIs(10),

  system:

    'You are solving math problems. ' +

    'Reason step by step. ' +

    'Use the calculator when necessary. ' +

    'The calculator can only do simple additions, subtractions, multiplications, and divisions. ' +

    'When you give the final answer, provide an explanation for how you got it.',

  prompt:

    'A taxi driver earns $9461 per 1-hour work. ' +

    'If he works 12 hours a day and in 1 hour he uses 14-liters petrol with price $134 for 1-liter. ' +

    'How much money does he earn in one day?',

});

console.log(`FINAL TOOL CALLS: ${JSON.stringify(toolCalls, null, 2)}`);
```

You can also use the
[`experimental_output`](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data#structured-output-with-generatetext)
setting for `generateText` to generate structured outputs.

### [Accessing all steps](https://ai-sdk.dev/docs/foundations/agents\#accessing-all-steps)

Calling `generateText` with `stopWhen` can result in several calls to the LLM (steps).
You can access information from all steps by using the `steps` property of the response.

```code-block_code__yIKW2

import { generateText, stepCountIs } from 'ai';

const { steps } = await generateText({

  model: openai('gpt-4o'),

  stopWhen: stepCountIs(10),

  // ...

});

// extract all tool calls from the steps:

const allToolCalls = steps.flatMap(step => step.toolCalls);
```

### [Getting notified on each completed step](https://ai-sdk.dev/docs/foundations/agents\#getting-notified-on-each-completed-step)

You can use the `onStepFinish` callback to get notified on each completed step.
It is triggered when a step is finished,
i.e. all text deltas, tool calls, and tool results for the step are available.

```code-block_code__yIKW2

import { generateText, stepCountIs } from 'ai';

const result = await generateText({

  model: 'openai/gpt-4.1',

  stopWhen: stepCountIs(10),

  onStepFinish({ text, toolCalls, toolResults, finishReason, usage }) {

    // your own logic, e.g. for saving the chat history or recording usage

  },

  // ...

});
```

On this page

[Agents](https://ai-sdk.dev/docs/foundations/agents#agents)

[Building Blocks](https://ai-sdk.dev/docs/foundations/agents#building-blocks)

[Single-Step LLM Generation](https://ai-sdk.dev/docs/foundations/agents#single-step-llm-generation)

[Tool Usage](https://ai-sdk.dev/docs/foundations/agents#tool-usage)

[Multi-Agent Systems](https://ai-sdk.dev/docs/foundations/agents#multi-agent-systems)

[Patterns](https://ai-sdk.dev/docs/foundations/agents#patterns)

[Choosing Your Approach](https://ai-sdk.dev/docs/foundations/agents#choosing-your-approach)

[Patterns with Examples](https://ai-sdk.dev/docs/foundations/agents#patterns-with-examples)

[Sequential Processing (Chains)](https://ai-sdk.dev/docs/foundations/agents#sequential-processing-chains)

[Routing](https://ai-sdk.dev/docs/foundations/agents#routing)

[Parallel Processing](https://ai-sdk.dev/docs/foundations/agents#parallel-processing)

[Orchestrator-Worker](https://ai-sdk.dev/docs/foundations/agents#orchestrator-worker)

[Evaluator-Optimizer](https://ai-sdk.dev/docs/foundations/agents#evaluator-optimizer)

[Multi-Step Tool Usage](https://ai-sdk.dev/docs/foundations/agents#multi-step-tool-usage)

[Using stopWhen](https://ai-sdk.dev/docs/foundations/agents#using-stopwhen)

[Structured Answers](https://ai-sdk.dev/docs/foundations/agents#structured-answers)

[Accessing all steps](https://ai-sdk.dev/docs/foundations/agents#accessing-all-steps)

[Getting notified on each completed step](https://ai-sdk.dev/docs/foundations/agents#getting-notified-on-each-completed-step)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## MistralPixtral 12B
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

MistralPixtral 12B 2409
Pro

Synced

Drop Image

Mistral/Pixtral 12B 2409

A 12B model with image understanding capabilities in addition to text.

Context

128,000 tokens

Input Pricing

$2.00 / million tokens

Output Pricing

$6.00 / million tokens

[Model Page](https://mistral.ai/news/pixtral-12b/) [Pricing](https://docs.mistral.ai/platform/pricing/)

[Terms](https://mistral.ai/terms) [Privacy](https://mistral.ai/terms#privacy-policy) [Website](https://mistral.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Claude 3.5 Haiku
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonClaude 3.5 Haiku (Bedrock)
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Claude 3.5 Haiku (Bedrock)

Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions. Claude 3 Haiku can process images and return text outputs, and features a 200K context window.

Context

200,000 tokens

Input Pricing

$0.80 / million tokens

Output Pricing

$4.00 / million tokens

[Model Page](https://aws.amazon.com/about-aws/whats-new/2024/11/anthropics-claude-3-5-haiku-model-amazon-bedrock/) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/bedrock/claude/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AWS Bedrock Cohere Stream
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AIStream](https://ai-sdk.dev/docs/reference/stream-helpers/ai-stream)

[StreamingTextResponse](https://ai-sdk.dev/docs/reference/stream-helpers/streaming-text-response)

[streamToResponse](https://ai-sdk.dev/docs/reference/stream-helpers/stream-to-response)

[OpenAIStream](https://ai-sdk.dev/docs/reference/stream-helpers/openai-stream)

[AnthropicStream](https://ai-sdk.dev/docs/reference/stream-helpers/anthropic-stream)

[AWSBedrockStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-stream)

[AWSBedrockAnthropicStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-anthropic-stream)

[AWSBedrockAnthropicMessagesStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-messages-stream)

[AWSBedrockCohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream)

[AWSBedrockLlama2Stream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-llama-2-stream)

[CohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream)

[GoogleGenerativeAIStream](https://ai-sdk.dev/docs/reference/stream-helpers/google-generative-ai-stream)

[HuggingFaceStream](https://ai-sdk.dev/docs/reference/stream-helpers/hugging-face-stream)

[@ai-sdk/langchain Adapter](https://ai-sdk.dev/docs/reference/stream-helpers/langchain-adapter)

[@ai-sdk/llamaindex Adapter](https://ai-sdk.dev/docs/reference/stream-helpers/llamaindex-adapter)

[MistralStream](https://ai-sdk.dev/docs/reference/stream-helpers/mistral-stream)

[ReplicateStream](https://ai-sdk.dev/docs/reference/stream-helpers/replicate-stream)

[InkeepStream](https://ai-sdk.dev/docs/reference/stream-helpers/inkeep-stream)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`AWSBedrockCohereStream`](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#awsbedrockcoherestream)

AWSBedrockCohereStream has been removed in AI SDK 4.0.

AWSBedrockCohereStream is part of the legacy AWS Bedrock integration. It is
not compatible with the AI SDK 3.1 functions.

## [Import](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#import)

The AWS Bedrock stream functions are utilties that transform the outputs from the AWS Bedrock API into a ReadableStream. It uses AIStream under the hood and handles parsing Bedrock's response.

### [React](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#react)

```
import { AWSBedrockCohereStream } from "ai"
```

## [API Signature](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#parameters)

### response:

AWSBedrockResponse

The response object returned from AWS Bedrock.

AWSBedrockResponse

### body?:

AsyncIterable<{ chunk?: { bytes?: Uint8Array } }>

An optional async iterable of objects containing optional binary data chunks.

### callbacks?:

AIStreamCallbacksAndOptions

An object containing callback functions to handle the start, each token, and completion of the AI response. In the absence of this parameter, default behavior is implemented.

AIStreamCallbacksAndOptions

### onStart:

() =\> Promise<void>

An optional function that is called at the start of the stream processing.

### onCompletion:

(completion: string) => Promise<void>

An optional function that is called for every completion. It's passed the completion as a string.

### onFinal:

(completion: string) => Promise<void>

An optional function that is called once when the stream is closed with the final completion message.

### onToken:

(token: string) => Promise<void>

An optional function that is called for each token in the stream. It's passed the token as a string.

### [Returns](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream\#returns)

A `ReadableStream`.

On this page

[AWSBedrockCohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#awsbedrockcoherestream)

[Import](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#import)

[React](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#react)

[API Signature](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#parameters)

[Returns](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream#returns)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Invalid Data Error
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error\#ai_invaliddatacontenterror)

This error occurs when the data content provided in a multi-modal message part is invalid. Check out the [prompt examples for multi-modal messages](https://ai-sdk.dev/docs/foundations/prompts#message-prompts).

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error\#properties)

- `content`: The invalid content value
- `message`: The error message describing the expected and received content types

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error\#checking-for-this-error)

You can check if an error is an instance of `AI_InvalidDataContentError` using:

```code-block_code__yIKW2

import { InvalidDataContentError } from 'ai';

if (InvalidDataContentError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error#ai_invaliddatacontenterror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI Application Guides
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Guides

Copy markdown

# [Guides](https://ai-sdk.dev/cookbook/guides\#guides)

These use-case specific guides are intended to help you build real applications with the AI SDK.

[RAG Chatbot\\
\\
Learn how to build a retrieval-augmented generation chatbot with the AI SDK.](https://ai-sdk.dev/cookbook/guides/rag-chatbot) [Multimodal Chatbot\\
\\
Learn how to build a multimodal chatbot with the AI SDK.](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot) [Get started with Llama 3.1\\
\\
Get started with Llama 3.1 using the AI SDK.](https://ai-sdk.dev/cookbook/guides/llama-3_1) [Get started with OpenAI o1\\
\\
Get started with OpenAI o1 using the AI SDK.](https://ai-sdk.dev/cookbook/guides/o1) [Get started with Gemini 2.5\\
\\
Get started with Gemini 2.5 using the AI SDK.](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

On this page

[Guides](https://ai-sdk.dev/cookbook/guides#guides)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## AI SDK Playground
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

## Stream Text with Image
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt\#stream-text-with-image-prompt)

Vision models such as GPT-4o can process both text and images. In this example, we will show you how to send an image URL along with the user's message to the model with `useChat`.

## [Using Image URLs](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt\#using-image-urls)

### [Server](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt\#server)

The server route uses `convertToModelMessages` to handle the conversion from `UIMessage` s to model messages, which automatically handles multimodal content including images.

app/api/chat/route.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { streamText } from 'ai';

export const maxDuration = 60;

export async function POST(req: Request) {

  const { messages } = await req.json();

  // Call the language model

  const result = streamText({

    model: openai('gpt-4.1'),

    messages: convertToModelMessages(messages),

  });

  // Respond with the stream

  return result.toUIMessageStreamResponse();

}
```

### [Client](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt\#client)

On the client side, we use the new `useChat` hook and send multimodal messages using the `parts` array.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useChat } from '@ai-sdk/react';

import { DefaultChatTransport } from 'ai';

import { useState } from 'react';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export default function Chat() {

  const [input, setInput] = useState('');

  const [imageUrl, setImageUrl] = useState(

    'https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png',

  );

  const { messages, sendMessage } = useChat();

  const handleSubmit = async (event: React.FormEvent<HTMLFormElement>) => {

    event.preventDefault();

    sendMessage({

      role: 'user',

      parts: [\
\
        // check if imageUrl is defined, if so, add it to the message\
\
        ...(imageUrl.trim().length > 0\
\
          ? [\
\
              {\
\
                type: 'file' as const,\
\
                mediaType: 'image/png',\
\
                url: imageUrl,\
\
              },\
\
            ]\
\
          : []),\
\
        { type: 'text' as const, text: input },\
\
      ],

    });

    setInput('');

    setImageUrl('');

  };

  return (

    <div>

      <div>

        {messages.map(m => (

          <div key={m.id}>

            <span>{m.role === 'user' ? 'User: ' : 'AI: '}</span>

            <div>

              {m.parts.map((part, i) => {

                switch (part.type) {

                  case 'text':

                    return part.text;

                  case 'file':

                    return (

                      <img

                        key={(part.filename || 'image') + i}

                        src={part.url}

                        alt={part.filename ?? 'image'}

                      />

                    );

                  default:

                    return null;

                }

              })}

            </div>

          </div>

        ))}

      </div>

      <form onSubmit={handleSubmit}>

        <div>

          <label htmlFor="image-url">Image URL:</label>

          <input

            id="image-url"

            value={imageUrl}

            placeholder="Enter image URL..."

            onChange={e => setImageUrl(e.currentTarget.value)}

          />

        </div>

        <div>

          <label htmlFor="image-description">Prompt:</label>

          <input

            id="image-description"

            value={input}

            placeholder="What does the image show..."

            onChange={e => setInput(e.currentTarget.value)}

          />

        </div>

        <button type="submit">Send Message</button>

      </form>

    </div>

  );

}
```

On this page

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt#stream-text-with-image-prompt)

[Using Image URLs](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt#using-image-urls)

[Server](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt#server)

[Client](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt#client)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Observability Integrations
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Observability Integrations

Copy markdown

# [Observability Integrations](https://ai-sdk.dev/providers/observability\#observability-integrations)

Several LLM observability providers offer integrations with the AI SDK telemetry data:

- [Braintrust](https://ai-sdk.dev/providers/observability/braintrust)
- [Helicone](https://ai-sdk.dev/providers/observability/helicone)
- [Traceloop](https://ai-sdk.dev/providers/observability/traceloop)
- [Weave](https://ai-sdk.dev/providers/observability/weave)
- [Langfuse](https://ai-sdk.dev/providers/observability/langfuse)
- [LangSmith](https://ai-sdk.dev/providers/observability/langsmith)
- [Laminar](https://ai-sdk.dev/providers/observability/laminar)
- [LangWatch](https://ai-sdk.dev/providers/observability/langwatch)
- [Maxim](https://ai-sdk.dev/providers/observability/maxim)
- [HoneyHive](https://docs.honeyhive.ai/integrations/vercel)
- [SigNoz](https://ai-sdk.dev/providers/observability/signoz)

There are also providers that provide monitoring and tracing for the AI SDK through model wrappers:

- [Literal AI](https://docs.literalai.com/integrations/vercel-ai-sdk)

Do you have an observability integration that supports the AI SDK and has an
integration guide? Please open a pull request to add it to the list.

On this page

[Observability Integrations](https://ai-sdk.dev/providers/observability#observability-integrations)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Amazon Claude 3 Haiku
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonClaude 3 Haiku (Bedrock)
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Claude 3 Haiku (Bedrock)

Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions. Claude 3 Haiku can process images and return text outputs, and features a 200K context window.

Context

200,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$1.25 / million tokens

[Model Page](https://aws.amazon.com/bedrock/claude/) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/bedrock/claude/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## OpenAI Models Overview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

Azureo4-mini
Pro

Synced

Drop Image

OpenAI/o4-mini

OpenAI's o4-mini delivers fast, cost-efficient reasoning with exceptional performance for its size, particularly excelling in math (best-performing on AIME benchmarks), coding, and visual tasks.

Context

200,000 tokens

Input Pricing

$1.10 / million tokens

Output Pricing

$4.40 / million tokens

[Model Page](https://platform.openai.com/docs/models/o4-mini) [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service)

[Terms](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/code-of-conduct) [Privacy](https://privacy.microsoft.com/en-us/privacystatement) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## Bloom AI Playground
[AI SDK](https://ai-sdk.dev/)

[New Chat](https://ai-sdk.dev/playground)

## OpenAI GPT-4.1 Mini
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

OpenAIGPT-4.1 mini
Pro

Synced

Drop Image

OpenAI/GPT-4.1 mini

GPT 4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases.

Context

1,047,576 tokens

Input Pricing

$0.40 / million tokens

Output Pricing

$1.60 / million tokens

[Model Page](https://platform.openai.com/docs/models/gpt-4.1-mini) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## CohereStream Utility
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AIStream](https://ai-sdk.dev/docs/reference/stream-helpers/ai-stream)

[StreamingTextResponse](https://ai-sdk.dev/docs/reference/stream-helpers/streaming-text-response)

[streamToResponse](https://ai-sdk.dev/docs/reference/stream-helpers/stream-to-response)

[OpenAIStream](https://ai-sdk.dev/docs/reference/stream-helpers/openai-stream)

[AnthropicStream](https://ai-sdk.dev/docs/reference/stream-helpers/anthropic-stream)

[AWSBedrockStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-stream)

[AWSBedrockAnthropicStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-anthropic-stream)

[AWSBedrockAnthropicMessagesStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-messages-stream)

[AWSBedrockCohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-cohere-stream)

[AWSBedrockLlama2Stream](https://ai-sdk.dev/docs/reference/stream-helpers/aws-bedrock-llama-2-stream)

[CohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream)

[GoogleGenerativeAIStream](https://ai-sdk.dev/docs/reference/stream-helpers/google-generative-ai-stream)

[HuggingFaceStream](https://ai-sdk.dev/docs/reference/stream-helpers/hugging-face-stream)

[@ai-sdk/langchain Adapter](https://ai-sdk.dev/docs/reference/stream-helpers/langchain-adapter)

[@ai-sdk/llamaindex Adapter](https://ai-sdk.dev/docs/reference/stream-helpers/llamaindex-adapter)

[MistralStream](https://ai-sdk.dev/docs/reference/stream-helpers/mistral-stream)

[ReplicateStream](https://ai-sdk.dev/docs/reference/stream-helpers/replicate-stream)

[InkeepStream](https://ai-sdk.dev/docs/reference/stream-helpers/inkeep-stream)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`CohereStream`](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#coherestream)

CohereStream has been removed in AI SDK 4.0.

CohereStream is part of the legacy Cohere integration. It is not compatible
with the AI SDK 3.1 functions.

The CohereStream function is a utility that transforms the output from Cohere's API into a ReadableStream. It uses AIStream under the hood, applying a specific parser for the Cohere's response data structure. This works with the official Cohere API, and it's supported in both Node.js, the Edge Runtime, and browser environments.

## [Import](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#import)

### [React](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#react)

```
import { CohereStream } from "ai"
```

## [API Signature](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#parameters)

### response:

Response

The response object returned by a call made by the Provider SDK.

### callbacks?:

AIStreamCallbacksAndOptions

An object containing callback functions to handle the start, each token, and completion of the AI response. In the absence of this parameter, default behavior is implemented.

AIStreamCallbacksAndOptions

### onStart:

() =\> Promise<void>

An optional function that is called at the start of the stream processing.

### onCompletion:

(completion: string) => Promise<void>

An optional function that is called for every completion. It's passed the completion as a string.

### onFinal:

(completion: string) => Promise<void>

An optional function that is called once when the stream is closed with the final completion message.

### onToken:

(token: string) => Promise<void>

An optional function that is called for each token in the stream. It's passed the token as a string.

### [Returns](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream\#returns)

A `ReadableStream`.

On this page

[CohereStream](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#coherestream)

[Import](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#import)

[React](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#react)

[API Signature](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#parameters)

[Returns](https://ai-sdk.dev/docs/reference/stream-helpers/cohere-stream#returns)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## API Key Load Error
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[AI\_APICallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-api-call-error)

[AI\_DownloadError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-download-error)

[AI\_EmptyResponseBodyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-empty-response-body-error)

[AI\_InvalidArgumentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-argument-error)

[AI\_InvalidDataContentError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content-error)

[AI\_InvalidDataContent](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-data-content)

[AI\_InvalidMessageRoleError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-message-role-error)

[AI\_InvalidPromptError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-prompt-error)

[AI\_InvalidResponseDataError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-response-data-error)

[AI\_InvalidToolArgumentsError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-invalid-tool-arguments-error)

[AI\_JSONParseError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-json-parse-error)

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error)

[AI\_LoadSettingError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-setting-error)

[AI\_MessageConversionError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-message-conversion-error)

[AI\_NoAudioGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-audio-generated-error)

[AI\_NoContentGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-content-generated-error)

[AI\_NoImageGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-image-generated-error)

[AI\_NoObjectGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-object-generated-error)

[AI\_NoOutputSpecifiedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-output-specified-error)

[AI\_NoSuchModelError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-model-error)

[AI\_NoSuchProviderError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-provider-error)

[AI\_NoSuchToolError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-such-tool-error)

[AI\_NoTranscriptGeneratedError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-no-transcript-generated-error)

[AI\_RetryError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-retry-error)

[AI\_TooManyEmbeddingValuesForCallError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-too-many-embedding-values-for-call-error)

[ToolCallRepairError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-tool-call-repair-error)

[AI\_TypeValidationError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-type-validation-error)

[AI\_UnsupportedFunctionalityError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-unsupported-functionality-error)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error\#ai_loadapikeyerror)

This error occurs when API key is not loaded successfully.

## [Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error\#properties)

- `message`: The error message

## [Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error\#checking-for-this-error)

You can check if an error is an instance of `AI_LoadAPIKeyError` using:

```code-block_code__yIKW2

import { LoadAPIKeyError } from 'ai';

if (LoadAPIKeyError.isInstance(error)) {

  // Handle the error

}
```

On this page

[AI\_LoadAPIKeyError](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error#ai_loadapikeyerror)

[Properties](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error#properties)

[Checking for this Error](https://ai-sdk.dev/docs/reference/ai-sdk-errors/ai-load-api-key-error#checking-for-this-error)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Image Generation API
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK by Vercel](https://ai-sdk.dev/docs/introduction)

[Foundations](https://ai-sdk.dev/docs/foundations)

[Overview](https://ai-sdk.dev/docs/foundations/overview)

[Providers and Models](https://ai-sdk.dev/docs/foundations/providers-and-models)

[Prompts](https://ai-sdk.dev/docs/foundations/prompts)

[Tools](https://ai-sdk.dev/docs/foundations/tools)

[Streaming](https://ai-sdk.dev/docs/foundations/streaming)

[Agents](https://ai-sdk.dev/docs/foundations/agents)

[Getting Started](https://ai-sdk.dev/docs/getting-started)

[Navigating the Library](https://ai-sdk.dev/docs/getting-started/navigating-the-library)

[Next.js App Router](https://ai-sdk.dev/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](https://ai-sdk.dev/docs/getting-started/nextjs-pages-router)

[Svelte](https://ai-sdk.dev/docs/getting-started/svelte)

[Vue.js (Nuxt)](https://ai-sdk.dev/docs/getting-started/nuxt)

[Node.js](https://ai-sdk.dev/docs/getting-started/nodejs)

[Expo](https://ai-sdk.dev/docs/getting-started/expo)

[AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)

[Overview](https://ai-sdk.dev/docs/ai-sdk-core/overview)

[Generating Text](https://ai-sdk.dev/docs/ai-sdk-core/generating-text)

[Generating Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling)

[Prompt Engineering](https://ai-sdk.dev/docs/ai-sdk-core/prompt-engineering)

[Settings](https://ai-sdk.dev/docs/ai-sdk-core/settings)

[Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings)

[Image Generation](https://ai-sdk.dev/docs/ai-sdk-core/image-generation)

[Transcription](https://ai-sdk.dev/docs/ai-sdk-core/transcription)

[Speech](https://ai-sdk.dev/docs/ai-sdk-core/speech)

[Language Model Middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

[Provider & Model Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-core/error-handling)

[Testing](https://ai-sdk.dev/docs/ai-sdk-core/testing)

[Telemetry](https://ai-sdk.dev/docs/ai-sdk-core/telemetry)

[AI SDK UI](https://ai-sdk.dev/docs/ai-sdk-ui)

[Overview](https://ai-sdk.dev/docs/ai-sdk-ui/overview)

[Chatbot](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Tool Usage](https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](https://ai-sdk.dev/docs/ai-sdk-ui/completion)

[Object Generation](https://ai-sdk.dev/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data)

[Error Handling](https://ai-sdk.dev/docs/ai-sdk-ui/error-handling)

[Transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](https://ai-sdk.dev/docs/ai-sdk-rsc)

[Advanced](https://ai-sdk.dev/docs/advanced)

[Reference](https://ai-sdk.dev/docs/reference)

[AI SDK Core](https://ai-sdk.dev/docs/reference/ai-sdk-core)

[generateText](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-text)

[streamText](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text)

[generateObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-object)

[streamObject](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-object)

[embed](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed)

[embedMany](https://ai-sdk.dev/docs/reference/ai-sdk-core/embed-many)

[generateImage](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image)

[transcribe](https://ai-sdk.dev/docs/reference/ai-sdk-core/transcribe)

[generateSpeech](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-speech)

[tool](https://ai-sdk.dev/docs/reference/ai-sdk-core/tool)

[dynamicTool](https://ai-sdk.dev/docs/reference/ai-sdk-core/dynamic-tool)

[experimental\_createMCPClient](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-mcp-client)

[Experimental\_StdioMCPTransport](https://ai-sdk.dev/docs/reference/ai-sdk-core/mcp-stdio-transport)

[jsonSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/json-schema)

[zodSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/zod-schema)

[valibotSchema](https://ai-sdk.dev/docs/reference/ai-sdk-core/valibot-schema)

[ModelMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/model-message)

[UIMessage](https://ai-sdk.dev/docs/reference/ai-sdk-core/ui-message)

[createProviderRegistry](https://ai-sdk.dev/docs/reference/ai-sdk-core/provider-registry)

[customProvider](https://ai-sdk.dev/docs/reference/ai-sdk-core/custom-provider)

[cosineSimilarity](https://ai-sdk.dev/docs/reference/ai-sdk-core/cosine-similarity)

[wrapLanguageModel](https://ai-sdk.dev/docs/reference/ai-sdk-core/wrap-language-model)

[LanguageModelV2Middleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/language-model-v2-middleware)

[extractReasoningMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/extract-reasoning-middleware)

[simulateStreamingMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-streaming-middleware)

[defaultSettingsMiddleware](https://ai-sdk.dev/docs/reference/ai-sdk-core/default-settings-middleware)

[stepCountIs](https://ai-sdk.dev/docs/reference/ai-sdk-core/step-count-is)

[hasToolCall](https://ai-sdk.dev/docs/reference/ai-sdk-core/has-tool-call)

[simulateReadableStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/simulate-readable-stream)

[smoothStream](https://ai-sdk.dev/docs/reference/ai-sdk-core/smooth-stream)

[generateId](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-id)

[createIdGenerator](https://ai-sdk.dev/docs/reference/ai-sdk-core/create-id-generator)

[AI SDK UI](https://ai-sdk.dev/docs/reference/ai-sdk-ui)

[AI SDK RSC](https://ai-sdk.dev/docs/reference/ai-sdk-rsc)

[Stream Helpers](https://ai-sdk.dev/docs/reference/stream-helpers)

[AI SDK Errors](https://ai-sdk.dev/docs/reference/ai-sdk-errors)

[Migration Guides](https://ai-sdk.dev/docs/migration-guides)

[Troubleshooting](https://ai-sdk.dev/docs/troubleshooting)

Copy markdown

# [`generateImage()`](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image\#generateimage)

`generateImage` is an experimental feature.

Generates images based on a given prompt using an image model.

It is ideal for use cases where you need to generate images programmatically,
such as creating visual content or generating images for data augmentation.

```code-block_code__yIKW2

import { experimental_generateImage as generateImage } from 'ai';

const { images } = await generateImage({

  model: openai.image('dall-e-3'),

  prompt: 'A futuristic cityscape at sunset',

  n: 3,

  size: '1024x1024',

});

console.log(images);
```

## [Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image\#import)

```
import { experimental_generateImage as generateImage } from "ai"
```

## [API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image\#api-signature)

### [Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image\#parameters)

### model:

ImageModelV2

The image model to use.

### prompt:

string

The input prompt to generate the image from.

### n?:

number

Number of images to generate.

### size?:

string

Size of the images to generate. Format: \`{width}x{height}\`.

### aspectRatio?:

string

Aspect ratio of the images to generate. Format: \`{width}:{height}\`.

### seed?:

number

Seed for the image generation.

### providerOptions?:

ProviderOptions

Additional provider-specific options.

### maxRetries?:

number

Maximum number of retries. Default: 2.

### abortSignal?:

AbortSignal

An optional abort signal to cancel the call.

### headers?:

Record<string, string>

Additional HTTP headers for the request.

### [Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image\#returns)

### image:

GeneratedFile

The first image that was generated.

GeneratedFile

### base64:

string

Image as a base64 encoded string.

### uint8Array:

Uint8Array

Image as a Uint8Array.

### mediaType:

string

The IANA media type of the image.

### images:

Array<GeneratedFile>

All images that were generated.

GeneratedFile

### base64:

string

Image as a base64 encoded string.

### uint8Array:

Uint8Array

Image as a Uint8Array.

### mediaType:

string

The IANA media type of the image.

### warnings:

ImageGenerationWarning\[\]

Warnings from the model provider (e.g. unsupported settings).

### providerMetadata?:

ImageModelProviderMetadata

Optional metadata from the provider. The outer key is the provider name. The inner values are the metadata. An \`images\` key is always present in the metadata and is an array with the same length as the top level \`images\` key. Details depend on the provider.

### responses:

Array<ImageModelResponseMetadata>

Response metadata from the provider. There may be multiple responses if we made multiple calls to the model.

ImageModelResponseMetadata

### timestamp:

Date

Timestamp for the start of the generated response.

### modelId:

string

The ID of the response model that was used to generate the response.

### headers?:

Record<string, string>

Response headers.

On this page

[generateImage()](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#generateimage)

[Import](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#import)

[API Signature](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#api-signature)

[Parameters](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#parameters)

[Returns](https://ai-sdk.dev/docs/reference/ai-sdk-core/generate-image#returns)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Cerebras AI Provider
[AI SDK](https://ai-sdk.dev/)

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [Cerebras Provider](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras\#cerebras-provider)

The [Cerebras](https://cerebras.ai/) provider offers access to powerful language models through the Cerebras API, including their high-speed inference capabilities powered by Wafer-Scale Engines and CS-3 systems.

API keys can be obtained from the [Cerebras Platform](https://cloud.cerebras.ai/).

## [Setup](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras\#setup)

The Cerebras provider is available via the `@ai-sdk/cerebras` module. You can install it with:

pnpm

npm

yarn

bun

```
pnpm add @ai-sdk/cerebras
```

## [Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras\#provider-instance)

You can import the default provider instance `cerebras` from `@ai-sdk/cerebras`:

```code-block_code__yIKW2

import { cerebras } from '@ai-sdk/cerebras';
```

For custom configuration, you can import `createCerebras` and create a provider instance with your settings:

```code-block_code__yIKW2

import { createCerebras } from '@ai-sdk/cerebras';

const cerebras = createCerebras({

  apiKey: process.env.CEREBRAS_API_KEY ?? '',

});
```

You can use the following optional settings to customize the Cerebras provider instance:

- **baseURL** _string_

Use a different URL prefix for API calls.
The default prefix is `https://api.cerebras.ai/v1`.

- **apiKey** _string_

API key that is being sent using the `Authorization` header. It defaults to
the `CEREBRAS_API_KEY` environment variable.

- **headers** _Record<string,string>_

Custom headers to include in the requests.

- **fetch** _(input: RequestInfo, init?: RequestInit) => Promise<Response>_

Custom [fetch](https://developer.mozilla.org/en-US/docs/Web/API/fetch) implementation.


## [Language Models](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras\#language-models)

You can create language models using a provider instance:

```code-block_code__yIKW2

import { cerebras } from '@ai-sdk/cerebras';

import { generateText } from 'ai';

const { text } = await generateText({

  model: cerebras('llama3.1-8b'),

  prompt: 'Write a vegetarian lasagna recipe for 4 people.',

});
```

Cerebras language models can be used in the `streamText` function
(see [AI SDK Core](https://ai-sdk.dev/docs/ai-sdk-core)).

You can create Cerebras language models using a provider instance. The first argument is the model ID, e.g. `llama-3.3-70b`:

```code-block_code__yIKW2

const model = cerebras('llama-3.3-70b');
```

You can also use the `.languageModel()` and `.chat()` methods:

```code-block_code__yIKW2

const model = cerebras.languageModel('llama-3.3-70b');

const model = cerebras.chat('llama-3.3-70b');
```

## [Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras\#model-capabilities)

| Model | Image Input | Object Generation | Tool Usage | Tool Streaming |
| --- | --- | --- | --- | --- |
| `llama3.1-8b` |  |  |  |  |
| `llama3.1-70b` |  |  |  |  |
| `llama-3.3-70b` |  |  |  |  |

Please see the [Cerebras\\
docs](https://inference-docs.cerebras.ai/introduction) for more details about
the available models. Note that context windows are temporarily limited to
8192 tokens in the Free Tier. You can also pass any available provider model
ID as a string if needed.

On this page

[Cerebras Provider](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras#cerebras-provider)

[Setup](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras#setup)

[Provider Instance](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras#provider-instance)

[Language Models](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras#language-models)

[Model Capabilities](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras#model-capabilities)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## LlamaIndex Framework
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers)

[AI Gateway](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)

[xAI Grok](https://ai-sdk.dev/providers/ai-sdk-providers/xai)

[Vercel](https://ai-sdk.dev/providers/ai-sdk-providers/vercel)

[OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/openai)

[Azure OpenAI](https://ai-sdk.dev/providers/ai-sdk-providers/azure)

[Anthropic](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic)

[Amazon Bedrock](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock)

[Groq](https://ai-sdk.dev/providers/ai-sdk-providers/groq)

[Fal](https://ai-sdk.dev/providers/ai-sdk-providers/fal)

[DeepInfra](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra)

[Google Generative AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai)

[Google Vertex AI](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex)

[Mistral AI](https://ai-sdk.dev/providers/ai-sdk-providers/mistral)

[Together.ai](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)

[Cohere](https://ai-sdk.dev/providers/ai-sdk-providers/cohere)

[Fireworks](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks)

[DeepSeek](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek)

[Cerebras](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras)

[Replicate](https://ai-sdk.dev/providers/ai-sdk-providers/replicate)

[Perplexity](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity)

[Luma](https://ai-sdk.dev/providers/ai-sdk-providers/luma)

[ElevenLabs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs)

[AssemblyAI](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai)

[Deepgram](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram)

[Gladia](https://ai-sdk.dev/providers/ai-sdk-providers/gladia)

[LMNT](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt)

[Hume](https://ai-sdk.dev/providers/ai-sdk-providers/hume)

[Rev.ai](https://ai-sdk.dev/providers/ai-sdk-providers/revai)

[OpenAI Compatible Providers](https://ai-sdk.dev/providers/openai-compatible-providers)

[Writing a Custom Provider](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers)

[LM Studio](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio)

[NVIDIA NIM](https://ai-sdk.dev/providers/openai-compatible-providers/nim)

[Baseten](https://ai-sdk.dev/providers/openai-compatible-providers/baseten)

[Heroku](https://ai-sdk.dev/providers/openai-compatible-providers/heroku)

[Community Providers](https://ai-sdk.dev/providers/community-providers)

[Automatic1111](https://ai-sdk.dev/providers/community-providers/automatic1111)

[Writing a Custom Provider](https://ai-sdk.dev/providers/community-providers/custom-providers)

[Qwen](https://ai-sdk.dev/providers/community-providers/qwen)

[Ollama](https://ai-sdk.dev/providers/community-providers/ollama)

[A2A](https://ai-sdk.dev/providers/community-providers/a2a)

[Requesty](https://ai-sdk.dev/providers/community-providers/requesty)

[FriendliAI](https://ai-sdk.dev/providers/community-providers/friendliai)

[Portkey](https://ai-sdk.dev/providers/community-providers/portkey)

[Cloudflare Workers AI](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai)

[Cloudflare AI Gateway](https://ai-sdk.dev/providers/community-providers/cloudflare-ai-gateway)

[OpenRouter](https://ai-sdk.dev/providers/community-providers/openrouter)

[Azure AI](https://ai-sdk.dev/providers/community-providers/azure-ai)

[SAP AI Core](https://ai-sdk.dev/providers/community-providers/sap-ai)

[Crosshatch](https://ai-sdk.dev/providers/community-providers/crosshatch)

[Mixedbread](https://ai-sdk.dev/providers/community-providers/mixedbread)

[Voyage AI](https://ai-sdk.dev/providers/community-providers/voyage-ai)

[Mem0](https://ai-sdk.dev/providers/community-providers/mem0)

[Letta](https://ai-sdk.dev/providers/community-providers/letta)

[Anthropic Vertex](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai)

[Spark](https://ai-sdk.dev/providers/community-providers/spark)

[Inflection AI](https://ai-sdk.dev/providers/community-providers/inflection-ai)

[LangDB](https://ai-sdk.dev/providers/community-providers/langdb)

[Zhipu AI](https://ai-sdk.dev/providers/community-providers/zhipu)

[SambaNova](https://ai-sdk.dev/providers/community-providers/sambanova)

[Dify](https://ai-sdk.dev/providers/community-providers/dify)

[Sarvam](https://ai-sdk.dev/providers/community-providers/sarvam)

[AI/ML API](https://ai-sdk.dev/providers/community-providers/aimlapi)

[Claude Code](https://ai-sdk.dev/providers/community-providers/claude-code)

[Built-in AI](https://ai-sdk.dev/providers/community-providers/built-in-ai)

[Gemini CLI](https://ai-sdk.dev/providers/community-providers/gemini-cli)

[Adapters](https://ai-sdk.dev/providers/adapters)

[LangChain](https://ai-sdk.dev/providers/adapters/langchain)

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex)

[Observability Integrations](https://ai-sdk.dev/providers/observability)

[Braintrust](https://ai-sdk.dev/providers/observability/braintrust)

[Helicone](https://ai-sdk.dev/providers/observability/helicone)

[Laminar](https://ai-sdk.dev/providers/observability/laminar)

[Langfuse](https://ai-sdk.dev/providers/observability/langfuse)

[LangSmith](https://ai-sdk.dev/providers/observability/langsmith)

[LangWatch](https://ai-sdk.dev/providers/observability/langwatch)

[Maxim](https://ai-sdk.dev/providers/observability/maxim)

[Patronus](https://ai-sdk.dev/providers/observability/patronus)

[SigNoz](https://ai-sdk.dev/providers/observability/signoz)

[Traceloop](https://ai-sdk.dev/providers/observability/traceloop)

[Weave](https://ai-sdk.dev/providers/observability/weave)

Copy markdown

# [LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex\#llamaindex)

[LlamaIndex](https://ts.llamaindex.ai/) is a framework for building LLM-powered applications. LlamaIndex helps you ingest, structure, and access private or domain-specific data. LlamaIndex.TS offers the core features of LlamaIndex for Python for popular runtimes like Node.js (official support), Vercel Edge Functions (experimental), and Deno (experimental).

## [Example: Completion](https://ai-sdk.dev/providers/adapters/llamaindex\#example-completion)

Here is a basic example that uses both AI SDK and LlamaIndex together with the [Next.js](https://nextjs.org/docs) App Router.

The AI SDK [`@ai-sdk/llamaindex` package](https://ai-sdk.dev/docs/reference/stream-helpers/llamaindex-adapter) uses the stream result from calling the `chat` method on a [LlamaIndex ChatEngine](https://ts.llamaindex.ai/modules/chat_engine) or the `query` method on a [LlamaIndex QueryEngine](https://ts.llamaindex.ai/modules/query_engines) to pipe text to the client.

app/api/completion/route.ts

```code-block_code__yIKW2

import { OpenAI, SimpleChatEngine } from 'llamaindex';

import { toDataStreamResponse } from '@ai-sdk/llamaindex';

export const maxDuration = 60;

export async function POST(req: Request) {

  const { prompt } = await req.json();

  const llm = new OpenAI({ model: 'gpt-4o' });

  const chatEngine = new SimpleChatEngine({ llm });

  const stream = await chatEngine.chat({

    message: prompt,

    stream: true,

  });

  return toDataStreamResponse(stream);

}
```

Then, we use the AI SDK's [`useCompletion`](https://ai-sdk.dev/docs/ai-sdk-ui/completion) method in the page component to handle the completion:

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useCompletion } from '@ai-sdk/react';

export default function Chat() {

  const { completion, input, handleInputChange, handleSubmit } =

    useCompletion();

  return (

    <div>

      {completion}

      <form onSubmit={handleSubmit}>

        <input value={input} onChange={handleInputChange} />

      </form>

    </div>

  );

}
```

## [More Examples](https://ai-sdk.dev/providers/adapters/llamaindex\#more-examples)

[create-llama](https://github.com/run-llama/create-llama) is the easiest way to get started with LlamaIndex. It uses the AI SDK to connect to LlamaIndex in all its generated code.

On this page

[LlamaIndex](https://ai-sdk.dev/providers/adapters/llamaindex#llamaindex)

[Example: Completion](https://ai-sdk.dev/providers/adapters/llamaindex#example-completion)

[More Examples](https://ai-sdk.dev/providers/adapters/llamaindex#more-examples)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Llama 4 Scout Overview
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)AmazonLlama 4 Scout 17B Instruct (Bedrock)
Pro

Synced

Drop Image

![](https://ai-sdk.dev/_next/image?url=%2Ficons%2Fnova.svg&w=32&q=75&dpl=dpl_2V37NZbp6GKR7Bb6HxsyJabvEfLd)

Amazon/Llama 4 Scout 17B Instruct (Bedrock)

Llama 4 Scout is the best multimodal model in the world in its class and is more powerful than our Llama 3 models, while fitting in a single H100 GPU. Additionally, Llama 4 Scout supports an industry-leading context window of up to 10M tokens.

Context

128,000 tokens

Input Pricing

$0.17 / million tokens

Output Pricing

$0.66 / million tokens

[Model Page](https://aws.amazon.com/bedrock/meta/) [Pricing](https://aws.amazon.com/bedrock/pricing/)

[Terms](https://aws.amazon.com/service-terms/) [Privacy](https://aws.amazon.com/privacy/) [Website](https://aws.amazon.com/bedrock/meta/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

## AI Reasoning Component
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

Menu

[Introduction](https://ai-sdk.dev/elements/overview)

[Setup](https://ai-sdk.dev/elements/overview/setup)

[Usage](https://ai-sdk.dev/elements/overview/usage)

[Troubleshooting](https://ai-sdk.dev/elements/overview/troubleshooting)

[Examples](https://ai-sdk.dev/elements/examples)

[Chatbot](https://ai-sdk.dev/elements/examples/chatbot)

[v0 clone](https://ai-sdk.dev/elements/examples/v0)

[Components](https://ai-sdk.dev/elements/components)

[Actions](https://ai-sdk.dev/elements/components/actions)

[Branch](https://ai-sdk.dev/elements/components/branch)

[Code Block](https://ai-sdk.dev/elements/components/code-block)

[Conversation](https://ai-sdk.dev/elements/components/conversation)

[Image](https://ai-sdk.dev/elements/components/image)

[Inline Citation](https://ai-sdk.dev/elements/components/inline-citation)

[Loader](https://ai-sdk.dev/elements/components/loader)

[Message](https://ai-sdk.dev/elements/components/message)

[Prompt Input](https://ai-sdk.dev/elements/components/prompt-input)

[Reasoning](https://ai-sdk.dev/elements/components/reasoning)

[Response](https://ai-sdk.dev/elements/components/response)

[Sources](https://ai-sdk.dev/elements/components/sources)

[Suggestion](https://ai-sdk.dev/elements/components/suggestion)

[Task](https://ai-sdk.dev/elements/components/task)

[Tool](https://ai-sdk.dev/elements/components/tool)

[Web Preview](https://ai-sdk.dev/elements/components/web-preview)

Copy markdown

# [Reasoning](https://ai-sdk.dev/elements/components/reasoning\#reasoning)

The `Reasoning` component displays AI reasoning content, automatically opening during streaming and closing when finished.

Thinking...

Let me think about this problem step by step.

First, I need to understand what the user is asking for.

They want a reasoning component that opens automatically when streaming begins and closes when streaming finishes. The component should be composable and follow existi

## [Installation](https://ai-sdk.dev/elements/components/reasoning\#installation)

ai-elementsshadcnManual

```
npx ai-elements@latest add reasoning
```

## [Usage](https://ai-sdk.dev/elements/components/reasoning\#usage)

```code-block_code__yIKW2

import {

  Reasoning,

  ReasoningContent,

  ReasoningTrigger,

} from '@/components/ai-elements/reasoning';
```

```code-block_code__yIKW2

<Reasoning className="w-full" isStreaming={false}>

  <ReasoningTrigger />

  <ReasoningContent>I need to computer the square of 2.</ReasoningContent>

</Reasoning>
```

## [Usage with AI SDK](https://ai-sdk.dev/elements/components/reasoning\#usage-with-ai-sdk)

Build a chatbot with reasoning using Deepseek R1.

Add the following component to your frontend:

app/page.tsx

```code-block_code__yIKW2

'use client';

import {

  Reasoning,

  ReasoningContent,

  ReasoningTrigger,

} from '@/components/ai-elements/reasoning';

import {

  Conversation,

  ConversationContent,

  ConversationScrollButton,

} from '@/components/ai-elements/conversation';

import {

  PromptInput,

  PromptInputTextarea,

  PromptInputSubmit,

} from '@/components/ai-elements/prompt-input';

import { Loader } from '@/components/ai-elements/loader';

import { Message, MessageContent } from '@/components/ai-elements/message';

import { useState } from 'react';

import { useChat } from '@ai-sdk/react';

import { Response } from @/components/ai-elements/response';

const ReasoningDemo = () => {

  const [input, setInput] = useState('');

  const { messages, sendMessage, status } = useChat();

  const handleSubmit = (e: React.FormEvent) => {

    e.preventDefault();

    sendMessage({ text: input });

    setInput('');

  };

  return (

    <div className="max-w-4xl mx-auto p-6 relative size-full rounded-lg border h-[600px]">

      <div className="flex flex-col h-full">

        <Conversation>

          <ConversationContent>

            {messages.map((message) => (

              <Message from={message.role} key={message.id}>

                <MessageContent>

                  {message.parts.map((part, i) => {

                    switch (part.type) {

                      case 'text':

                        return (

                          <Response key={`${message.id}-${i}`}>

                            {part.text}

                          </Response>

                        );

                      case 'reasoning':

                        return (

                          <Reasoning

                            key={`${message.id}-${i}`}

                            className="w-full"

                            isStreaming={status === 'streaming'}

                          >

                            <ReasoningTrigger />

                            <ReasoningContent>{part.text}</ReasoningContent>

                          </Reasoning>

                        );

                    }

                  })}

                </MessageContent>

              </Message>

            ))}

            {status === 'submitted' && <Loader />}

          </ConversationContent>

          <ConversationScrollButton />

        </Conversation>

        <PromptInput

          onSubmit={handleSubmit}

          className="mt-4 w-full max-w-2xl mx-auto relative"

        >

          <PromptInputTextarea

            value={input}

            placeholder="Say something..."

            onChange={(e) => setInput(e.currentTarget.value)}

            className="pr-12"

          />

          <PromptInputSubmit

            status={status === 'streaming' ? 'streaming' : 'ready'}

            disabled={!input.trim()}

            className="absolute bottom-1 right-1"

          />

        </PromptInput>

      </div>

    </div>

  );

};

export default ReasoningDemo;
```

Add the following route to your backend:

app/api/chat/route.ts

```code-block_code__yIKW2

import { streamText, UIMessage, convertToModelMessages } from 'ai';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export async function POST(req: Request) {

  const { model, messages }: { messages: UIMessage[]; model: string } =

    await req.json();

  const result = streamText({

    model: 'deepseek/deepseek-r1',

    messages: convertToModelMessages(messages),

  });

  return result.toUIMessageStreamResponse({

    sendReasoning: true,

  });

}
```

## [Features](https://ai-sdk.dev/elements/components/reasoning\#features)

- Automatically opens when streaming content and closes when finished
- Manual toggle control for user interaction
- Smooth animations and transitions powered by Radix UI
- Visual streaming indicator with pulsing animation
- Composable architecture with separate trigger and content components
- Built with accessibility in mind including keyboard navigation
- Responsive design that works across different screen sizes
- Seamlessly integrates with both light and dark themes
- Built on top of shadcn/ui Collapsible primitives
- TypeScript support with proper type definitions

## [Props](https://ai-sdk.dev/elements/components/reasoning\#props)

### [`<Reasoning />`](https://ai-sdk.dev/elements/components/reasoning\#reasoning-)

### isStreaming?:

boolean

Whether the reasoning is currently streaming (auto-opens and closes the panel).

### \[...props\]?:

React.ComponentProps<typeof Collapsible>

Any other props are spread to the underlying Collapsible component.

### [`<ReasoningTrigger />`](https://ai-sdk.dev/elements/components/reasoning\#reasoningtrigger-)

### title?:

string

Optional title to display in the trigger (default: "Reasoning").

### \[...props\]?:

React.ComponentProps<typeof CollapsibleTrigger>

Any other props are spread to the underlying CollapsibleTrigger component.

### [`<ReasoningContent />`](https://ai-sdk.dev/elements/components/reasoning\#reasoningcontent-)

### \[...props\]?:

React.ComponentProps<typeof CollapsibleContent>

Any other props are spread to the underlying CollapsibleContent component.

On this page

[Reasoning](https://ai-sdk.dev/elements/components/reasoning#reasoning)

[Installation](https://ai-sdk.dev/elements/components/reasoning#installation)

[Usage](https://ai-sdk.dev/elements/components/reasoning#usage)

[Usage with AI SDK](https://ai-sdk.dev/elements/components/reasoning#usage-with-ai-sdk)

[Features](https://ai-sdk.dev/elements/components/reasoning#features)

[Props](https://ai-sdk.dev/elements/components/reasoning#props)

[<Reasoning />](https://ai-sdk.dev/elements/components/reasoning#reasoning-)

[<ReasoningTrigger />](https://ai-sdk.dev/elements/components/reasoning#reasoningtrigger-)

[<ReasoningContent />](https://ai-sdk.dev/elements/components/reasoning#reasoningcontent-)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Stream Text Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

[Generate Text](https://ai-sdk.dev/cookbook/rsc/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/generate-text-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/rsc/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/rsc/stream-text-with-chat-prompt)

[Generate Object](https://ai-sdk.dev/cookbook/rsc/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/rsc/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/rsc/call-tools)

[Call Tools in Parallel](https://ai-sdk.dev/cookbook/rsc/call-tools-in-parallel)

[Save Messages To Database](https://ai-sdk.dev/cookbook/rsc/save-messages-to-database)

[Restore Messages From Database](https://ai-sdk.dev/cookbook/rsc/restore-messages-from-database)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/rsc/render-visual-interface-in-chat)

[Stream Updates to Visual Interfaces](https://ai-sdk.dev/cookbook/rsc/stream-updates-to-visual-interfaces)

[Record Token Usage after Streaming User Interfaces](https://ai-sdk.dev/cookbook/rsc/stream-ui-record-token-usage)

Copy markdown

# [Stream Text](https://ai-sdk.dev/cookbook/rsc/stream-text\#stream-text)

This example uses React Server Components (RSC). If you want to client side
rendering and hooks instead, check out the ["stream text" example with\\
useCompletion](https://ai-sdk.dev/examples/next-pages/basics/streaming-text-generation).

Text generation can sometimes take a long time to complete, especially when you're generating a couple of paragraphs. In such cases, it is useful to stream the text generation process to the client in real-time. This allows the client to display the generated text as it is being generated, rather than have users wait for it to complete before displaying the result.

http://localhost:3000

Answer

## [Client](https://ai-sdk.dev/cookbook/rsc/stream-text\#client)

Let's create a simple React component that will call the `generate` function when a button is clicked. The `generate` function will call the `streamText` function, which will then generate text based on the input prompt. To consume the stream of text in the client, we will use the `readStreamableValue` function from the `@ai-sdk/rsc` module.

app/page.tsx

```code-block_code__yIKW2

'use client';

import { useState } from 'react';

import { generate } from './actions';

import { readStreamableValue } from '@ai-sdk/rsc';

// Allow streaming responses up to 30 seconds

export const maxDuration = 30;

export default function Home() {

  const [generation, setGeneration] = useState<string>('');

  return (

    <div>

      <button

        onClick={async () => {

          const { output } = await generate('Why is the sky blue?');

          for await (const delta of readStreamableValue(output)) {

            setGeneration(currentGeneration => `${currentGeneration}${delta}`);

          }

        }}

      >

        Ask

      </button>

      <div>{generation}</div>

    </div>

  );

}
```

## [Server](https://ai-sdk.dev/cookbook/rsc/stream-text\#server)

On the server side, we need to implement the `generate` function, which will call the `streamText` function. The `streamText` function will generate text based on the input prompt. In order to stream the text generation to the client, we will use `createStreamableValue` that can wrap any changeable value and stream it to the client.

Using DevTools, we can see the text generation being streamed to the client in real-time.

app/actions.ts

```code-block_code__yIKW2

'use server';

import { streamText } from 'ai';

import { openai } from '@ai-sdk/openai';

import { createStreamableValue } from '@ai-sdk/rsc';

export async function generate(input: string) {

  const stream = createStreamableValue('');

  (async () => {

    const { textStream } = streamText({

      model: openai('gpt-3.5-turbo'),

      prompt: input,

    });

    for await (const delta of textStream) {

      stream.update(delta);

    }

    stream.done();

  })();

  return { output: stream.value };

}
```

On this page

[Stream Text](https://ai-sdk.dev/cookbook/rsc/stream-text#stream-text)

[Client](https://ai-sdk.dev/cookbook/rsc/stream-text#client)

[Server](https://ai-sdk.dev/cookbook/rsc/stream-text#server)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Slackbot Agent Guide
[AI SDK](https://ai-sdk.dev/)

Menu

[Guides](https://ai-sdk.dev/cookbook/guides)

[RAG Agent](https://ai-sdk.dev/cookbook/guides/rag-chatbot)

[Multi-Modal Agent](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot)

[Slackbot Agent Guide](https://ai-sdk.dev/cookbook/guides/slackbot)

[Natural Language Postgres](https://ai-sdk.dev/cookbook/guides/natural-language-postgres)

[Get started with Computer Use](https://ai-sdk.dev/cookbook/guides/computer-use)

[Get started with Gemini 2.5](https://ai-sdk.dev/cookbook/guides/gemini-2-5)

[Get started with Claude 4](https://ai-sdk.dev/cookbook/guides/claude-4)

[OpenAI Responses API](https://ai-sdk.dev/cookbook/guides/openai-responses)

[Get started with Claude 3.7 Sonnet](https://ai-sdk.dev/cookbook/guides/sonnet-3-7)

[Get started with Llama 3.1](https://ai-sdk.dev/cookbook/guides/llama-3_1)

[Get started with OpenAI o1](https://ai-sdk.dev/cookbook/guides/o1)

[Get started with OpenAI o3-mini](https://ai-sdk.dev/cookbook/guides/o3)

[Get started with DeepSeek R1](https://ai-sdk.dev/cookbook/guides/r1)

[Next.js](https://ai-sdk.dev/cookbook/next)

[Generate Text](https://ai-sdk.dev/cookbook/next/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-text-with-chat-prompt)

[Generate Image with Chat Prompt](https://ai-sdk.dev/cookbook/next/generate-image-with-chat-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/next/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-image-prompt)

[Chat with PDFs](https://ai-sdk.dev/cookbook/next/chat-with-pdf)

[streamText Multi-Step Cookbook](https://ai-sdk.dev/cookbook/next/stream-text-multistep)

[Markdown Chatbot with Memoization](https://ai-sdk.dev/cookbook/next/markdown-chatbot-with-memoization)

[Generate Object](https://ai-sdk.dev/cookbook/next/generate-object)

[Generate Object with File Prompt through Form Submission](https://ai-sdk.dev/cookbook/next/generate-object-with-file-prompt)

[Stream Object](https://ai-sdk.dev/cookbook/next/stream-object)

[Call Tools](https://ai-sdk.dev/cookbook/next/call-tools)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/next/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/next/mcp-tools)

[Human-in-the-Loop Agent with Next.js](https://ai-sdk.dev/cookbook/next/human-in-the-loop)

[Send Custom Body from useChat](https://ai-sdk.dev/cookbook/next/send-custom-body-from-use-chat)

[Render Visual Interface in Chat](https://ai-sdk.dev/cookbook/next/render-visual-interface-in-chat)

[Caching Middleware](https://ai-sdk.dev/cookbook/next/caching-middleware)

[Node](https://ai-sdk.dev/cookbook/node)

[Generate Text](https://ai-sdk.dev/cookbook/node/generate-text)

[Generate Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-chat-prompt)

[Generate Text with Image Prompt](https://ai-sdk.dev/cookbook/node/generate-text-with-image-prompt)

[Stream Text](https://ai-sdk.dev/cookbook/node/stream-text)

[Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-chat-prompt)

[Stream Text with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-image-prompt)

[Stream Text with File Prompt](https://ai-sdk.dev/cookbook/node/stream-text-with-file-prompt)

[Generate Object with a Reasoning Model](https://ai-sdk.dev/cookbook/node/generate-object-reasoning)

[Generate Object](https://ai-sdk.dev/cookbook/node/generate-object)

[Stream Object](https://ai-sdk.dev/cookbook/node/stream-object)

[Stream Object with Image Prompt](https://ai-sdk.dev/cookbook/node/stream-object-with-image-prompt)

[Record Token Usage After Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-token-usage)

[Record Final Object after Streaming Object](https://ai-sdk.dev/cookbook/node/stream-object-record-final-object)

[Call Tools](https://ai-sdk.dev/cookbook/node/call-tools)

[Call Tools with Image Prompt](https://ai-sdk.dev/cookbook/node/call-tools-with-image-prompt)

[Call Tools in Multiple Steps](https://ai-sdk.dev/cookbook/node/call-tools-multiple-steps)

[Model Context Protocol (MCP) Tools](https://ai-sdk.dev/cookbook/node/mcp-tools)

[Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)

[Web Search Agent](https://ai-sdk.dev/cookbook/node/web-search-agent)

[Embed Text](https://ai-sdk.dev/cookbook/node/embed-text)

[Embed Text in Batch](https://ai-sdk.dev/cookbook/node/embed-text-batch)

[Intercepting Fetch Requests](https://ai-sdk.dev/cookbook/node/intercept-fetch-requests)

[Local Caching Middleware](https://ai-sdk.dev/cookbook/node/local-caching-middleware)

[Retrieval Augmented Generation](https://ai-sdk.dev/cookbook/node/retrieval-augmented-generation)

[API Servers](https://ai-sdk.dev/cookbook/api-servers)

[Node.js HTTP Server](https://ai-sdk.dev/cookbook/api-servers/node-http-server)

[Express](https://ai-sdk.dev/cookbook/api-servers/express)

[Hono](https://ai-sdk.dev/cookbook/api-servers/hono)

[Fastify](https://ai-sdk.dev/cookbook/api-servers/fastify)

[Nest.js](https://ai-sdk.dev/cookbook/api-servers/nest)

[React Server Components](https://ai-sdk.dev/cookbook/rsc)

Copy markdown

# [Building an AI Agent in Slack with the AI SDK](https://ai-sdk.dev/cookbook/guides/slackbot\#building-an-ai-agent-in-slack-with-the-ai-sdk)

In this guide, you will learn how to build a Slackbot powered by the AI SDK. The bot will be able to respond to direct messages and mentions in channels using the full context of the thread.

## [Slack App Setup](https://ai-sdk.dev/cookbook/guides/slackbot\#slack-app-setup)

Before we start building, you'll need to create and configure a Slack app:

1. Go to [api.slack.com/apps](https://api.slack.com/apps)
2. Click "Create New App" and choose "From scratch"
3. Give your app a name and select your workspace
4. Under "OAuth & Permissions", add the following bot token scopes:
   - `app_mentions:read`
   - `chat:write`
   - `im:history`
   - `im:write`
   - `assistant:write`
5. Install the app to your workspace (button under "OAuth Tokens" subsection)
6. Copy the Bot User OAuth Token and Signing Secret for the next step
7. Under App Home -> Show Tabs -> Chat Tab, check "Allow users to send Slash commands and messages from the chat tab"

## [Project Setup](https://ai-sdk.dev/cookbook/guides/slackbot\#project-setup)

This project uses the following stack:

- [AI SDK by Vercel](https://ai-sdk.dev/docs)
- [Slack Web API](https://api.slack.com/web)
- [Vercel](https://vercel.com/)
- [OpenAI](https://openai.com/)

## [Getting Started](https://ai-sdk.dev/cookbook/guides/slackbot\#getting-started)

1. Clone [the repository](https://github.com/vercel-labs/ai-sdk-slackbot) and check out the `starter` branch

```
git clone https://github.com/vercel-labs/ai-sdk-slackbot.git
```

```
cd ai-sdk-slackbot
```

```
git checkout starter
```

2. Install dependencies

```
pnpm install
```

## [Project Structure](https://ai-sdk.dev/cookbook/guides/slackbot\#project-structure)

The starter repository already includes:

- Slack utilities ( `lib/slack-utils.ts`) including functions for validating incoming requests, converting Slack threads to AI SDK compatible message formats, and getting the Slackbot's user ID
- General utility functions ( `lib/utils.ts`) including initial Exa setup
- Files to handle the different types of Slack events ( `lib/handle-messages.ts` and `lib/handle-app-mention.ts`)
- An API endpoint ( `POST`) for Slack events ( `api/events.ts`)

## [Event Handler](https://ai-sdk.dev/cookbook/guides/slackbot\#event-handler)

First, let's take a look at our API route ( `api/events.ts`):

```code-block_code__yIKW2

import type { SlackEvent } from '@slack/web-api';

import {

  assistantThreadMessage,

  handleNewAssistantMessage,

} from '../lib/handle-messages';

import { waitUntil } from '@vercel/functions';

import { handleNewAppMention } from '../lib/handle-app-mention';

import { verifyRequest, getBotId } from '../lib/slack-utils';

export async function POST(request: Request) {

  const rawBody = await request.text();

  const payload = JSON.parse(rawBody);

  const requestType = payload.type as 'url_verification' | 'event_callback';

  // See https://api.slack.com/events/url_verification

  if (requestType === 'url_verification') {

    return new Response(payload.challenge, { status: 200 });

  }

  await verifyRequest({ requestType, request, rawBody });

  try {

    const botUserId = await getBotId();

    const event = payload.event as SlackEvent;

    if (event.type === 'app_mention') {

      waitUntil(handleNewAppMention(event, botUserId));

    }

    if (event.type === 'assistant_thread_started') {

      waitUntil(assistantThreadMessage(event));

    }

    if (

      event.type === 'message' &&

      !event.subtype &&

      event.channel_type === 'im' &&

      !event.bot_id &&

      !event.bot_profile &&

      event.bot_id !== botUserId

    ) {

      waitUntil(handleNewAssistantMessage(event, botUserId));

    }

    return new Response('Success!', { status: 200 });

  } catch (error) {

    console.error('Error generating response', error);

    return new Response('Error generating response', { status: 500 });

  }

}
```

This file defines a `POST` function that handles incoming requests from Slack. First, you check the request type to see if it's a URL verification request. If it is, you respond with the challenge string provided by Slack. If it's an event callback, you verify the request and then have access to the event data. This is where you can implement your event handling logic.

You then handle three types of events: `app_mention`, `assistant_thread_started`, and `message`:

- For `app_mention`, you call `handleNewAppMention` with the event and the bot user ID.
- For `assistant_thread_started`, you call `assistantThreadMessage` with the event.
- For `message`, you call `handleNewAssistantMessage` with the event and the bot user ID.

Finally, you respond with a success message to Slack. Note, each handler function is wrapped in a `waitUntil` function. Let's take a look at what this means and why it's important.

### [The waitUntil Function](https://ai-sdk.dev/cookbook/guides/slackbot\#the-waituntil-function)

Slack expects a response within 3 seconds to confirm the request is being handled. However, generating AI responses can take longer. If you don't respond to the Slack request within 3 seconds, Slack will send another request, leading to another invocation of your API route, another call to the LLM, and ultimately another response to the user. To solve this, you can use the `waitUntil` function, which allows you to run your AI logic after the response is sent, without blocking the response itself.

This means, your API endpoint will:

1. Immediately respond to Slack (within 3 seconds)
2. Continue processing the message asynchronously
3. Send the AI response when it's ready

## [Event Handlers](https://ai-sdk.dev/cookbook/guides/slackbot\#event-handlers)

Let's look at how each event type is currently handled.

### [App Mentions](https://ai-sdk.dev/cookbook/guides/slackbot\#app-mentions)

When a user mentions your bot in a channel, the `app_mention` event is triggered. The `handleNewAppMention` function in `handle-app-mention.ts` processes these mentions:

1. Checks if the message is from a bot to avoid infinite response loops
2. Creates a status updater to show the bot is "thinking"
3. If the mention is in a thread, it retrieves the thread history
4. Calls the LLM with the message content (using the `generateResponse` function which you will implement in the next section)
5. Updates the initial "thinking" message with the AI response

Here's the code for the `handleNewAppMention` function:

lib/handle-app-mention.ts

```code-block_code__yIKW2

import { AppMentionEvent } from '@slack/web-api';

import { client, getThread } from './slack-utils';

import { generateResponse } from './ai';

const updateStatusUtil = async (

  initialStatus: string,

  event: AppMentionEvent,

) => {

  const initialMessage = await client.chat.postMessage({

    channel: event.channel,

    thread_ts: event.thread_ts ?? event.ts,

    text: initialStatus,

  });

  if (!initialMessage || !initialMessage.ts)

    throw new Error('Failed to post initial message');

  const updateMessage = async (status: string) => {

    await client.chat.update({

      channel: event.channel,

      ts: initialMessage.ts as string,

      text: status,

    });

  };

  return updateMessage;

};

export async function handleNewAppMention(

  event: AppMentionEvent,

  botUserId: string,

) {

  console.log('Handling app mention');

  if (event.bot_id || event.bot_id === botUserId || event.bot_profile) {

    console.log('Skipping app mention');

    return;

  }

  const { thread_ts, channel } = event;

  const updateMessage = await updateStatusUtil('is thinking...', event);

  if (thread_ts) {

    const messages = await getThread(channel, thread_ts, botUserId);

    const result = await generateResponse(messages, updateMessage);

    updateMessage(result);

  } else {

    const result = await generateResponse(

      [{ role: 'user', content: event.text }],

      updateMessage,

    );

    updateMessage(result);

  }

}
```

Now let's see how new assistant threads and messages are handled.

### [Assistant Thread Messages](https://ai-sdk.dev/cookbook/guides/slackbot\#assistant-thread-messages)

When a user starts a thread with your assistant, the `assistant_thread_started` event is triggered. The `assistantThreadMessage` function in `handle-messages.ts` handles this:

1. Posts a welcome message to the thread
2. Sets up suggested prompts to help users get started

Here's the code for the `assistantThreadMessage` function:

lib/handle-messages.ts

```code-block_code__yIKW2

import type { AssistantThreadStartedEvent } from '@slack/web-api';

import { client } from './slack-utils';

export async function assistantThreadMessage(

  event: AssistantThreadStartedEvent,

) {

  const { channel_id, thread_ts } = event.assistant_thread;

  console.log(`Thread started: ${channel_id} ${thread_ts}`);

  console.log(JSON.stringify(event));

  await client.chat.postMessage({

    channel: channel_id,

    thread_ts: thread_ts,

    text: "Hello, I'm an AI assistant built with the AI SDK by Vercel!",

  });

  await client.assistant.threads.setSuggestedPrompts({

    channel_id: channel_id,

    thread_ts: thread_ts,

    prompts: [\
\
      {\
\
        title: 'Get the weather',\
\
        message: 'What is the current weather in London?',\
\
      },\
\
      {\
\
        title: 'Get the news',\
\
        message: 'What is the latest Premier League news from the BBC?',\
\
      },\
\
    ],

  });

}
```

### [Direct Messages](https://ai-sdk.dev/cookbook/guides/slackbot\#direct-messages)

For direct messages to your bot, the `message` event is triggered and the event is handled by the `handleNewAssistantMessage` function in `handle-messages.ts`:

1. Verifies the message isn't from a bot
2. Updates the status to show the response is being generated
3. Retrieves the conversation history
4. Calls the LLM with the conversation context
5. Posts the LLM's response to the thread

Here's the code for the `handleNewAssistantMessage` function:

lib/handle-messages.ts

```code-block_code__yIKW2

import type { GenericMessageEvent } from '@slack/web-api';

import { client, getThread } from './slack-utils';

import { generateResponse } from './ai';

export async function handleNewAssistantMessage(

  event: GenericMessageEvent,

  botUserId: string,

) {

  if (

    event.bot_id ||

    event.bot_id === botUserId ||

    event.bot_profile ||

    !event.thread_ts

  )

    return;

  const { thread_ts, channel } = event;

  const updateStatus = updateStatusUtil(channel, thread_ts);

  updateStatus('is thinking...');

  const messages = await getThread(channel, thread_ts, botUserId);

  const result = await generateResponse(messages, updateStatus);

  await client.chat.postMessage({

    channel: channel,

    thread_ts: thread_ts,

    text: result,

    unfurl_links: false,

    blocks: [\
\
      {\
\
        type: 'section',\
\
        text: {\
\
          type: 'mrkdwn',\
\
          text: result,\
\
        },\
\
      },\
\
    ],

  });

  updateStatus('');

}
```

With the event handlers in place, let's now implement the AI logic.

## [Implementing AI Logic](https://ai-sdk.dev/cookbook/guides/slackbot\#implementing-ai-logic)

The core of our application is the `generateResponse` function in `lib/generate-response.ts`, which processes messages and generates responses using the AI SDK.

Here's how to implement it:

lib/generate-response.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, ModelMessage } from 'ai';

export const generateResponse = async (

  messages: ModelMessage[],

  updateStatus?: (status: string) => void,

) => {

  const { text } = await generateText({

    model: openai('gpt-4o-mini'),

    system: `You are a Slack bot assistant. Keep your responses concise and to the point.

    - Do not tag users.

    - Current date is: ${new Date().toISOString().split('T')[0]}`,

    messages,

  });

  // Convert markdown to Slack mrkdwn format

  return text.replace(/\[(.*?)\]\((.*?)\)/g, '<$2|$1>').replace(/\*\*/g, '*');

};
```

This basic implementation:

1. Uses the AI SDK's `generateText` function to call OpenAI's `gpt-4o` model
2. Provides a system prompt to guide the model's behavior
3. Formats the response for Slack's markdown format

## [Enhancing with Tools](https://ai-sdk.dev/cookbook/guides/slackbot\#enhancing-with-tools)

The real power of the AI SDK comes from tools that enable your bot to perform actions. Let's add two useful tools:

lib/generate-response.ts

```code-block_code__yIKW2

import { openai } from '@ai-sdk/openai';

import { generateText, tool, ModelMessage, stepCountIs } from 'ai';

import { z } from 'zod';

import { exa } from './utils';

export const generateResponse = async (

  messages: ModelMessage[],

  updateStatus?: (status: string) => void,

) => {

  const { text } = await generateText({

    model: openai('gpt-4o'),

    system: `You are a Slack bot assistant. Keep your responses concise and to the point.

    - Do not tag users.

    - Current date is: ${new Date().toISOString().split('T')[0]}

    - Always include sources in your final response if you use web search.`,

    messages,

    stopWhen: stepCountIs(10),

    tools: {

      getWeather: tool({

        description: 'Get the current weather at a location',

        inputSchema: z.object({

          latitude: z.number(),

          longitude: z.number(),

          city: z.string(),

        }),

        execute: async ({ latitude, longitude, city }) => {

          updateStatus?.(`is getting weather for ${city}...`);

          const response = await fetch(

            `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,weathercode,relativehumidity_2m&timezone=auto`,

          );

          const weatherData = await response.json();

          return {

            temperature: weatherData.current.temperature_2m,

            weatherCode: weatherData.current.weathercode,

            humidity: weatherData.current.relativehumidity_2m,

            city,

          };

        },

      }),

      searchWeb: tool({

        description: 'Use this to search the web for information',

        inputSchema: z.object({

          query: z.string(),

          specificDomain: z

            .string()

            .nullable()

            .describe(

              'a domain to search if the user specifies e.g. bbc.com. Should be only the domain name without the protocol',

            ),

        }),

        execute: async ({ query, specificDomain }) => {

          updateStatus?.(`is searching the web for ${query}...`);

          const { results } = await exa.searchAndContents(query, {

            livecrawl: 'always',

            numResults: 3,

            includeDomains: specificDomain ? [specificDomain] : undefined,

          });

          return {

            results: results.map(result => ({

              title: result.title,

              url: result.url,

              snippet: result.text.slice(0, 1000),

            })),

          };

        },

      }),

    },

  });

  // Convert markdown to Slack mrkdwn format

  return text.replace(/\[(.*?)\]\((.*?)\)/g, '<$2|$1>').replace(/\*\*/g, '*');

};
```

In this updated implementation:

1. You added two tools:
   - `getWeather`: Fetches weather data for a specified location
   - `searchWeb`: Searches the web for information using the Exa API
2. You set `stopWhen: stepCountIs(10)` to enable multi-step conversations. This defines the stopping conditions of your agent, when the model generates a tool call. This will automatically send any tool results back to the LLM to trigger additional tool calls or responses as the LLM deems necessary. This turns your LLM call from a one-off operation into a multi-step agentic flow.


## [How It Works](https://ai-sdk.dev/cookbook/guides/slackbot\#how-it-works)

When a user interacts with your bot:

1. The Slack event is received and processed by your API endpoint
2. The user's message and the thread history is passed to the `generateResponse` function
3. The AI SDK processes the message and may invoke tools as needed
4. The response is formatted for Slack and sent back to the user

The tools are automatically invoked based on the user's intent. For example, if a user asks "What's the weather in London?", the AI will:

1. Recognize this as a weather query
2. Call the `getWeather` tool with London's coordinates (inferred by the LLM)
3. Process the weather data
4. Generate a final response, answering the user's question

## [Deploying the App](https://ai-sdk.dev/cookbook/guides/slackbot\#deploying-the-app)

1. Install the Vercel CLI

```
pnpm install -g vercel
```

2. Deploy the app

```
vercel deploy
```

3. Copy the deployment URL and update the Slack app's Event Subscriptions to point to your Vercel URL
4. Go to your project's deployment settings (Your project -> Settings -> Environment Variables) and add your environment variables

```code-block_code__yIKW2

SLACK_BOT_TOKEN=your_slack_bot_token

SLACK_SIGNING_SECRET=your_slack_signing_secret

OPENAI_API_KEY=your_openai_api_key

EXA_API_KEY=your_exa_api_key
```

Make sure to redeploy your app after updating environment variables.

5. Head back to the [https://api.slack.com/](https://api.slack.com/) and navigate to the "Event Subscriptions" page. Enable events and add your deployment URL.

```code-block_code__yIKW2

https://your-vercel-url.vercel.app/api/events
```

6. On the Events Subscription page, subscribe to the following events.
   - `app_mention`
   - `assistant_thread_started`
   - `message:im`

Finally, head to Slack and test the app by sending a message to the bot.

## [Next Steps](https://ai-sdk.dev/cookbook/guides/slackbot\#next-steps)

You've built a Slack chatbot powered by the AI SDK! Here are some ways you could extend it:

1. Add memory for specific users to give the LLM context of previous interactions
2. Implement more tools like database queries or knowledge base searches
3. Add support for rich message formatting with blocks
4. Add analytics to track usage patterns

In a production environment, it is recommended to implement a robust queueing
system to ensure messages are properly handled.

On this page

[Building an AI Agent in Slack with the AI SDK](https://ai-sdk.dev/cookbook/guides/slackbot#building-an-ai-agent-in-slack-with-the-ai-sdk)

[Slack App Setup](https://ai-sdk.dev/cookbook/guides/slackbot#slack-app-setup)

[Project Setup](https://ai-sdk.dev/cookbook/guides/slackbot#project-setup)

[Getting Started](https://ai-sdk.dev/cookbook/guides/slackbot#getting-started)

[Project Structure](https://ai-sdk.dev/cookbook/guides/slackbot#project-structure)

[Event Handler](https://ai-sdk.dev/cookbook/guides/slackbot#event-handler)

[The waitUntil Function](https://ai-sdk.dev/cookbook/guides/slackbot#the-waituntil-function)

[Event Handlers](https://ai-sdk.dev/cookbook/guides/slackbot#event-handlers)

[App Mentions](https://ai-sdk.dev/cookbook/guides/slackbot#app-mentions)

[Assistant Thread Messages](https://ai-sdk.dev/cookbook/guides/slackbot#assistant-thread-messages)

[Direct Messages](https://ai-sdk.dev/cookbook/guides/slackbot#direct-messages)

[Implementing AI Logic](https://ai-sdk.dev/cookbook/guides/slackbot#implementing-ai-logic)

[Enhancing with Tools](https://ai-sdk.dev/cookbook/guides/slackbot#enhancing-with-tools)

[How It Works](https://ai-sdk.dev/cookbook/guides/slackbot#how-it-works)

[Deploying the App](https://ai-sdk.dev/cookbook/guides/slackbot#deploying-the-app)

[Next Steps](https://ai-sdk.dev/cookbook/guides/slackbot#next-steps)

Elevate your AI applications with Vercel.

Trusted by OpenAI, Replicate, Suno, Pinecone, and more.

Vercel provides tools and infrastructure to deploy AI apps and features at scale.

[Talk to an expert](https://vercel.com/contact/sales?utm_source=ai_sdk&utm_medium=web&utm_campaign=contact_sales_cta&utm_content=talk_to_an_expert_sdk_docs)

## Mercury Coder Small
[AI SDK](https://ai-sdk.dev/)

v5

Search‚Ä¶
`‚åò¬†K`

Feedback

Sign in with Vercel

Sign in with Vercel

[New Chat](https://ai-sdk.dev/playground)

InceptionMercury Coder Small Beta
Hobby

Synced

Drop Image

Inception/Mercury Coder Small Beta

Mercury Coder Small is ideal for code generation, debugging, and refactoring tasks with minimal latency.

Context

32,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$1.00 / million tokens

[Model Page](https://platform.inceptionlabs.ai/docs#models) [Pricing](https://platform.inceptionlabs.ai/docs#models)

[Terms](https://www.inceptionlabs.ai/terms) [Privacy](https://www.inceptionlabs.ai/terms) [Website](https://platform.inceptionlabs.ai/)

Legal

OpenAIGPT-5 mini

Synced

Drop Image

OpenAI/GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context

400,000 tokens

Input Pricing

$0.25 / million tokens

Output Pricing

$2.00 / million tokens

[Model Page](https://platform.openai.com/docs/models) [Pricing](https://platform.openai.com/docs/pricing)

[Terms](https://openai.com/policies/terms-of-use) [Privacy](https://openai.com/policies/privacy-policy) [Website](https://openai.com/)

Legal

